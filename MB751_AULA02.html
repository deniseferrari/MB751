<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="pt" xml:lang="pt"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Prof.&nbsp;Denise Beatriz Ferrari   denise@ita.br">

<title>MB-751: Estatística Básica</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="MB751_AULA02_files/libs/clipboard/clipboard.min.js"></script>
<script src="MB751_AULA02_files/libs/quarto-html/quarto.js"></script>
<script src="MB751_AULA02_files/libs/quarto-html/popper.min.js"></script>
<script src="MB751_AULA02_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="MB751_AULA02_files/libs/quarto-html/anchor.min.js"></script>
<link href="MB751_AULA02_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="MB751_AULA02_files/libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="MB751_AULA02_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="MB751_AULA02_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="MB751_AULA02_files/libs/bootstrap/bootstrap-10daa034703793678e481cc8cee6d76f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Índice</h2>
   
  <ul>
  <li><a href="#introdução" id="toc-introdução" class="nav-link active" data-scroll-target="#introdução">Introdução</a></li>
  <li><a href="#princípios-de-teoria-de-probabilidades" id="toc-princípios-de-teoria-de-probabilidades" class="nav-link" data-scroll-target="#princípios-de-teoria-de-probabilidades">Princípios de Teoria de Probabilidades</a>
  <ul class="collapse">
  <li><a href="#interpretações-de-probabilidade" id="toc-interpretações-de-probabilidade" class="nav-link" data-scroll-target="#interpretações-de-probabilidade">Interpretações de Probabilidade</a>
  <ul class="collapse">
  <li><a href="#considerações-sobre-as-diferentes-interpretações" id="toc-considerações-sobre-as-diferentes-interpretações" class="nav-link" data-scroll-target="#considerações-sobre-as-diferentes-interpretações">Considerações sobre as Diferentes Interpretações</a></li>
  </ul></li>
  <li><a href="#definição-axiomática" id="toc-definição-axiomática" class="nav-link" data-scroll-target="#definição-axiomática">Definição Axiomática</a></li>
  </ul></li>
  <li><a href="#probabilidade-condicional-e-independência" id="toc-probabilidade-condicional-e-independência" class="nav-link" data-scroll-target="#probabilidade-condicional-e-independência">Probabilidade Condicional e Independência</a>
  <ul class="collapse">
  <li><a href="#probabilidade-condicional" id="toc-probabilidade-condicional" class="nav-link" data-scroll-target="#probabilidade-condicional">Probabilidade Condicional</a>
  <ul class="collapse">
  <li><a href="#propriedades" id="toc-propriedades" class="nav-link" data-scroll-target="#propriedades">Propriedades</a></li>
  </ul></li>
  <li><a href="#independência-de-eventos" id="toc-independência-de-eventos" class="nav-link" data-scroll-target="#independência-de-eventos">Independência de Eventos</a>
  <ul class="collapse">
  <li><a href="#propriedades-1" id="toc-propriedades-1" class="nav-link" data-scroll-target="#propriedades-1">Propriedades</a></li>
  <li><a href="#aplicação-confiabilidade-de-sistemas" id="toc-aplicação-confiabilidade-de-sistemas" class="nav-link" data-scroll-target="#aplicação-confiabilidade-de-sistemas">Aplicação: Confiabilidade de Sistemas</a></li>
  </ul></li>
  <li><a href="#teoremas-fundamentais-da-probabilidade" id="toc-teoremas-fundamentais-da-probabilidade" class="nav-link" data-scroll-target="#teoremas-fundamentais-da-probabilidade">Teoremas Fundamentais da Probabilidade</a></li>
  </ul></li>
  <li><a href="#variáveis-aleatórias-e-distribuições" id="toc-variáveis-aleatórias-e-distribuições" class="nav-link" data-scroll-target="#variáveis-aleatórias-e-distribuições">Variáveis Aleatórias e Distribuições</a>
  <ul class="collapse">
  <li><a href="#variáveis-aleatórias" id="toc-variáveis-aleatórias" class="nav-link" data-scroll-target="#variáveis-aleatórias">Variáveis Aleatórias</a>
  <ul class="collapse">
  <li><a href="#tipos-de-variáveis-aleatórias" id="toc-tipos-de-variáveis-aleatórias" class="nav-link" data-scroll-target="#tipos-de-variáveis-aleatórias">Tipos de Variáveis Aleatórias</a></li>
  </ul></li>
  <li><a href="#distribuições-de-probabilidade" id="toc-distribuições-de-probabilidade" class="nav-link" data-scroll-target="#distribuições-de-probabilidade">Distribuições de Probabilidade</a>
  <ul class="collapse">
  <li><a href="#função-distribuição-de-probabilidade-fdp-caso-discreto" id="toc-função-distribuição-de-probabilidade-fdp-caso-discreto" class="nav-link" data-scroll-target="#função-distribuição-de-probabilidade-fdp-caso-discreto">Função Distribuição de Probabilidade (FDP): caso discreto</a></li>
  <li><a href="#função-distribuição-de-probabilidade-fdp-caso-contínuo" id="toc-função-distribuição-de-probabilidade-fdp-caso-contínuo" class="nav-link" data-scroll-target="#função-distribuição-de-probabilidade-fdp-caso-contínuo">Função Distribuição de Probabilidade (FDP): caso contínuo</a></li>
  <li><a href="#função-distribuição-acumulada-fda" id="toc-função-distribuição-acumulada-fda" class="nav-link" data-scroll-target="#função-distribuição-acumulada-fda">Função Distribuição Acumulada (FDA)</a></li>
  </ul></li>
  <li><a href="#valor-esperado-e-variância" id="toc-valor-esperado-e-variância" class="nav-link" data-scroll-target="#valor-esperado-e-variância">Valor Esperado e Variância</a>
  <ul class="collapse">
  <li><a href="#valor-esperado" id="toc-valor-esperado" class="nav-link" data-scroll-target="#valor-esperado">Valor Esperado</a></li>
  <li><a href="#variância" id="toc-variância" class="nav-link" data-scroll-target="#variância">Variância</a></li>
  </ul></li>
  <li><a href="#momentos" id="toc-momentos" class="nav-link" data-scroll-target="#momentos">Momentos</a>
  <ul class="collapse">
  <li><a href="#assimetria-skewness-e-excesso-kurtosis" id="toc-assimetria-skewness-e-excesso-kurtosis" class="nav-link" data-scroll-target="#assimetria-skewness-e-excesso-kurtosis">Assimetria (<em>skewness</em>) e Excesso (<em>kurtosis</em>)</a></li>
  </ul></li>
  <li><a href="#desigualdades-de-markov-e-chebyshev" id="toc-desigualdades-de-markov-e-chebyshev" class="nav-link" data-scroll-target="#desigualdades-de-markov-e-chebyshev">Desigualdades de Markov e Chebyshev</a></li>
  </ul></li>
  <li><a href="#distribuições-notáveis" id="toc-distribuições-notáveis" class="nav-link" data-scroll-target="#distribuições-notáveis">Distribuições Notáveis</a>
  <ul class="collapse">
  <li><a href="#distribuições-associadas-a-processos-de-bernoulli" id="toc-distribuições-associadas-a-processos-de-bernoulli" class="nav-link" data-scroll-target="#distribuições-associadas-a-processos-de-bernoulli">Distribuições Associadas a Processos de Bernoulli</a>
  <ul class="collapse">
  <li><a href="#o-experimento-de-bernoulli" id="toc-o-experimento-de-bernoulli" class="nav-link" data-scroll-target="#o-experimento-de-bernoulli">O Experimento de Bernoulli</a></li>
  <li><a href="#distribuição-de-bernoulli" id="toc-distribuição-de-bernoulli" class="nav-link" data-scroll-target="#distribuição-de-bernoulli">Distribuição de Bernoulli</a></li>
  <li><a href="#distribuição-binomial" id="toc-distribuição-binomial" class="nav-link" data-scroll-target="#distribuição-binomial">Distribuição Binomial</a></li>
  </ul></li>
  <li><a href="#distribuições-associadas-a-processos-de-poisson" id="toc-distribuições-associadas-a-processos-de-poisson" class="nav-link" data-scroll-target="#distribuições-associadas-a-processos-de-poisson">Distribuições Associadas a Processos de Poisson</a>
  <ul class="collapse">
  <li><a href="#uma-aproximação-para-a-distribuição-binomial" id="toc-uma-aproximação-para-a-distribuição-binomial" class="nav-link" data-scroll-target="#uma-aproximação-para-a-distribuição-binomial">Uma aproximação para a Distribuição Binomial</a></li>
  <li><a href="#distribuição-de-poisson" id="toc-distribuição-de-poisson" class="nav-link" data-scroll-target="#distribuição-de-poisson">Distribuição de Poisson</a></li>
  <li><a href="#o-processo-de-poisson" id="toc-o-processo-de-poisson" class="nav-link" data-scroll-target="#o-processo-de-poisson">O Processo de Poisson</a></li>
  </ul></li>
  <li><a href="#distribuição-normal" id="toc-distribuição-normal" class="nav-link" data-scroll-target="#distribuição-normal">Distribuição Normal</a>
  <ul class="collapse">
  <li><a href="#mais-uma-aproximação-para-a-distribuição-binomial" id="toc-mais-uma-aproximação-para-a-distribuição-binomial" class="nav-link" data-scroll-target="#mais-uma-aproximação-para-a-distribuição-binomial">…(Mais) Uma Aproximação para a Distribuição Binomial</a></li>
  <li><a href="#cálculo-de-probabilidades" id="toc-cálculo-de-probabilidades" class="nav-link" data-scroll-target="#cálculo-de-probabilidades">Cálculo de Probabilidades</a></li>
  <li><a href="#padronização-1" id="toc-padronização-1" class="nav-link" data-scroll-target="#padronização-1">Padronização</a></li>
  <li><a href="#regra-empírica" id="toc-regra-empírica" class="nav-link" data-scroll-target="#regra-empírica">Regra Empírica</a></li>
  <li><a href="#coeficiente-de-variação" id="toc-coeficiente-de-variação" class="nav-link" data-scroll-target="#coeficiente-de-variação">Coeficiente de Variação</a></li>
  </ul></li>
  <li><a href="#aproximação-para-distribuições-discretas" id="toc-aproximação-para-distribuições-discretas" class="nav-link" data-scroll-target="#aproximação-para-distribuições-discretas">Aproximação para Distribuições Discretas</a>
  <ul class="collapse">
  <li><a href="#aproximação-para-a-distribuição-binomial" id="toc-aproximação-para-a-distribuição-binomial" class="nav-link" data-scroll-target="#aproximação-para-a-distribuição-binomial">Aproximação para a Distribuição Binomial</a></li>
  </ul></li>
  <li><a href="#métodos-descritivos-para-avaliar-normalidade" id="toc-métodos-descritivos-para-avaliar-normalidade" class="nav-link" data-scroll-target="#métodos-descritivos-para-avaliar-normalidade">Métodos Descritivos para Avaliar Normalidade</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">MB-751: Estatística Básica</h1>
<p class="subtitle lead">AULA 02 <br>Modelos Probabilísticos</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Autor</div>
    <div class="quarto-title-meta-contents">
             <p>Prof.&nbsp;Denise Beatriz Ferrari <br> <a href="mailto:denise@ita.br" class="email">denise@ita.br</a> </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Data de Publicação</div>
    <div class="quarto-title-meta-contents">
      <p class="date">1o. semestre/ 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<hr>
<section id="introdução" class="level1">
<h1>Introdução</h1>
<p>Vimos anteriormente que o método científico emprega experimentos a fim de obter informação a respeito de populações que não são perfeitamente conhecidas. Experimentos produzem evidências empíricas (dados) que, por sua vez, correspondem à matéria prima de que se utilizam os métodos estatísticos na tarefa de realizar inferência, ou seja, fazer afirmações a respeito da população sendo investigada. É fundamental notar que, por mais representativa que seja uma amostra, ela fornece apenas informação parcial a respeito da população de origem. Portanto, simplesmente não é possível fazer generalizações absolutamente certas a partir de dados amostrais. Podemos fazer generalizações <em>incertas</em> e o grau de incerteza associado pode ser medido, se os dados que compõe a amostra tiverem sido selecionados observando-se certos princípios.</p>
<p>Na linguagem estatística, uma população é representada por uma <em>distribuição</em> de uma ou mais variáveis. Tais distribuições correspondem a modelos matemáticos chamados modelos probabilísticos, que podem ser descritos através de parâmetros.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Os <strong>parâmetros</strong> são quantidades fixas (porém desconhecidas) que caracterizam uma população, modelada matematicamente por uma distribuição de probabilidade. Parâmetros são, portanto, quantidades populacionais.</p>
<p>As <strong>estatísticas</strong> correspondem a funções dos valores conhecidos (observados) em uma amostra que tenha sido obtida a partir da população de interesse. Sendo assim, uma estatística é uma quantidade amostral.</p>
<p>Note que os valores calculados para uma estatística variam de amostra para amostra e essa variabilidade deve ser levada em conta nos procedimentos de inferência realizados. A variabilidade amostral de uma estatística também pode ser descrita matematicamente em termos de uma distribuição. A distribuição de uma estatística chama-se <strong>distribuição amostral</strong>.</p>
</div>
</div>
</div>
<p>Inferência estatística consiste na atividade que utiliza estatísticas (quantidades amostrais) para fazer afirmações a respeito de distribuições populacionais. Realizamos <em>inferência estatística paramétrica</em> quando desejamos fazer afirmações a respeito de parâmetros populacionais. Se a inferência diz respeito à distribuição de probabilidade como um todo, sem fazer referência a qualquer parâmetro em particular, realizamos <em>inferência estatística não paramétrica</em>. O foco neste curso será em inferência estatística paramétrica.</p>
<p>A fim de compreender os métodos para inferência estatística, bem como a confiabilidade das inferências associadas, precisamos nos familiarizar com o conceito de incerteza. A disciplina matemática que trata da incerteza é a teoria de probabilidades.</p>
<hr>
</section>
<section id="princípios-de-teoria-de-probabilidades" class="level1">
<h1>Princípios de Teoria de Probabilidades</h1>
<p>Um modelo probabilístico consiste em uma descrição matemática de uma situação de incerteza. Isto significa que podemos utilizá-lo para:</p>
<ol type="1">
<li><p>Investigar e descobrir padrões regulares em eventos aleatórios (imprevisíveis); e também para</p></li>
<li><p>Descrever incerteza em termos matemáticos (quantificar as incertezas).</p></li>
</ol>
<p>Os modelos probabilísticos são constituídos por alguns elementos básicos, ilustrados na <a href="#fig-probabilidade-modelo" class="quarto-xref">Figura&nbsp;1</a>: temos um <strong>experimento aleatório</strong> associado a um <strong>espaço amostral</strong> (coleção de resultados possíveis) que, por sua vez, é composto por uma coleção de <strong>eventos</strong> para os quais é possível definir uma <strong>lei de probabilidade</strong>. Essa lei, por sua vez, quantifica o grau de incerteza de cada evento. Examinaremos, a seguir, cada um desses elementos.</p>
<div id="fig-probabilidade-modelo" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-probabilidade-modelo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/probabilidade-modelo.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-probabilidade-modelo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1: Elementos básicos de um modelo probabilístico
</figcaption>
</figure>
</div>
<p><strong>Experimento Aleatório</strong></p>
<p>Um <strong>experimento aleatório</strong> (E) é um processo cujo resultado é desconhecido e não pode ser previsto com certeza, mas que pode, pelo menos em teoria, ser repetido um número indefinido de vezes sob condições idênticas. Em tais experimentos, ainda que tenhamos um conjunto conhecido de resultados possíveis, não há garantia de que um determinado resultado vá ocorrer. A incerteza está, portanto, no fato de não sabermos qual dos resultados possíveis acontecerá ao realizarmos o experimento.</p>
<p>Por exemplo, considere o experimento de lançar um dado e observar o número que aparece na face superior. Conhecemos de antemão que os resultados possíveis deste experimento são 1, 2, 3, 4, 5 ou 6, mas não temos como prever exatamente qual deles ocorrerá em um lançamento específico. Além disso, poderíamos repetir esse experimento indefinidamente, supostamente nas mesmas condições. Ao realizar esse experimento apenas uma vez, apenas um dos resultados possíveis é observado.</p>
<p><strong>Espaço Amostral e Eventos</strong></p>
<p>O conjunto formado por todos os resultados elementares possíveis de um experimento aleatório é chamado <strong>espaço amostral</strong>, usualmente representado por <span class="math inline">\(\Omega\)</span>. Qualquer subconjunto de <span class="math inline">\(\Omega\)</span> recebe o nome de <strong>evento</strong> e é representado por letras maiúsculas do alfabeto latino (A, B, C, D etc.).</p>
<p>Um evento pode ser simples (quando não se decompõe em outros eventos mais elementares) ou composto (união de eventos elementares). Na prática, um evento corresponde a um conjunto de resultados de um experimento aleatório que satisfaz determinadas condições.</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-lancamento-dado" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 1</strong></span> <br></p>
<p>Considere o experimento aleatório que consiste em lançar um dado:</p>
<p>Experimento Aleatório:<br>
E = lançar um dado e observar o valor obtido</p>
<p>Eventos Elementares:<br>
<span class="math inline">\(\{1\}, \{2\}, \{3\}, \{4\}, \{5\}, \{6\}\)</span></p>
<p>Espaço Amostral:<br>
<span class="math inline">\(\Omega  = \{1, 2, 3, 4, 5, 6\}\)</span></p>
<p>Podemos definir vários outros eventos associados ao mesmo experimento:</p>
<p><span class="math inline">\(A\)</span> = resultado par = <span class="math inline">\(\{2, 4, 6\}\)</span><br>
<span class="math inline">\(B\)</span> = resultado ímpar = <span class="math inline">\(\{1, 3, 5\}\)</span><br>
<span class="math inline">\(C\)</span> = resultado maior que 3 = <span class="math inline">\(\{4, 5, 6\}\)</span><br>
<span class="math inline">\(D\)</span> = resultado igual a 1 = <span class="math inline">\(\{1\}\)</span><br>
<span class="math inline">\(G\)</span> = resultado menor que 2 e par = <span class="math inline">\(\{ \} = \varnothing\)</span> (impossível)</p>
<p>Note que <span class="math inline">\(G\)</span> é o <em>evento impossível</em>, pois não contém resultado algum.</p>
</div>
</div>
</div>
</div>
<p>Mesmo para um experimento aleatório trivial, é importante identificar corretamente os eventos simples, como mostra o exemplo a seguir:</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-lancamento-duas-moedas" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 2</strong></span> <br></p>
<p>Considere o experimento aleatório que consiste em lançar duas moedas:</p>
<p>Experimento Aleatório:<br>
E = lançar duas moedas e observar os resultados</p>
<p>Eventos Elementares:<br>
{(cara,cara)}, {(coroa, coroa)}, {(cara, coroa)} e {(coroa, cara)}</p>
<p>Espaço Amostral:<br>
<span class="math inline">\(\Omega\)</span> = {(cara,cara), (coroa, coroa), (cara, coroa), (coroa, cara)}</p>
<p>Aqui, uma análise descuidada poderia levar a crer que “obter uma cara e uma coroa” é um único evento elementar, mas na realidade há dois resultados distintos que se encaixam nessa descrição: (cara, coroa) e (coroa, cara). Assim, o espaço amostral deve distinguir essas duas situações.</p>
</div>
</div>
</div>
</div>
<p><strong>Eventos Especiais e Operações</strong></p>
<ul>
<li><strong>Evento Impossível</strong> <span class="math inline">\(\varnothing\)</span></li>
</ul>
<p>Também chamado de evento nulo, é o evento que não pode ocorrer (por exemplo, obter um resultado maior que 6 ao lançar um dado). Matematicamente, corresponde ao conjunto vazio.</p>
<ul>
<li><strong>União</strong> <span class="math inline">\(A \cup B\)</span></li>
</ul>
<p>É o conjunto dos resultados em que ocorre <span class="math inline">\(A\)</span> ou <span class="math inline">\(B\)</span>, incluindo a possibilidade de ambos ocorrerem simultaneamente.</p>
<p>Por exemplo, considere novamente o lançamento de um dado e definamos os eventos:<br>
<span class="math inline">\(A\)</span> = resultado par = <span class="math inline">\(\{2, 4, 6\}\)</span><br>
<span class="math inline">\(B\)</span> = resultado ímpar = <span class="math inline">\(\{1, 3, 5\}\)</span></p>
<p>Então {A <span class="math inline">\(\cup\)</span> B} = {1, 2, 3, 4, 5, 6} = <span class="math inline">\(\Omega\)</span></p>
<ul>
<li><strong>Interseção</strong> <span class="math inline">\(A \cap B\)</span></li>
</ul>
<p>É o conjunto dos resultados em que ocorrem <em>simultaneamente</em> os eventos <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span>.</p>
<p>Por exemplo, considere novamente o lançamento de um dado e definamos os eventos:</p>
<p><span class="math inline">\(A\)</span> = resultado par = <span class="math inline">\(\{2, 4, 6\}\)</span><br>
<span class="math inline">\(C\)</span> = resultado maior que 3 = <span class="math inline">\(\{4, 5, 6\}\)</span></p>
<p>Então <span class="math inline">\(A \cup C = \{4, 6\}\)</span></p>
<ul>
<li><strong>Eventos Mutuamente Exclusivos</strong> <span class="math inline">\(A \cap B = \varnothing\)</span></li>
</ul>
<p>Dois eventos são mutuamente exclusivos se a ocorrência de um deles impede a ocorrência do outro, de forma que é impossível observar a ocorrência simultânea dos dois. Portanto, a intersecção entre os conjuntos que o definem é o conjunto vazio.</p>
<p>No exemplo do lançamento do dado, os resultados pares (evento <span class="math inline">\(A\)</span>) e ímpares (evento <span class="math inline">\(B\)</span>) não podem ocorrer simultaneamente:</p>
<p><span class="math inline">\(A \cap B = \{2, 4, 6\} \cap \{1, 3, 5\} = \{ \} = \varnothing\)</span></p>
<ul>
<li><strong>Partição do Espaço Amostral</strong></li>
</ul>
<p>Um conjunto de eventos mutuamente exclusivos e coletivamente exaustivos (cuja união corresponde ao espaço amostral) forma uma partição de <span class="math inline">\(\Omega\)</span>. Se <span class="math inline">\(A \cap B = \varnothing\)</span> e <span class="math inline">\(A \cup B = \Omega\)</span>, dizemos que <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> formam uma partição do espaço amostral.</p>
<p>Duas definições adicionais importantes para teoria de probabilidades são idênticas àquelas correspondentes em teoria de conjuntos:</p>
<ul>
<li><strong>Evento Complementar</strong> <span class="math inline">\(A^\prime\)</span> ou <span class="math inline">\(A^C\)</span></li>
</ul>
<p>O complementar de um evento <span class="math inline">\(A\)</span> corresponde ao evento que ocorre apenas se <span class="math inline">\(A\)</span> não ocorrer.</p>
<ul>
<li><strong>Diferença entre Eventos</strong> <span class="math inline">\(A - B\)</span> ou <span class="math inline">\(A \cap B^C\)</span></li>
</ul>
<p>Descreve a ocorrência de A mas não a de B.<br>
A diferença <span class="math inline">\(A-B\)</span> pode ser representada matematicamente pela interseção entre o evento A e o complementar de B.</p>
<p>Por exemplo, considere os eventos:<br>
<span class="math inline">\(A = \{2, 4, 6\}\)</span><br>
<span class="math inline">\(B = \{1, 3, 5\}\)</span></p>
<p>Então <span class="math inline">\(\{A - B\} = A \cap B^C = \{2, 4, 6\} \cap \{2, 4, 6\} = \{2, 4, 6\}\)</span></p>
<p>Descrevemos o espaço amostral em termos da definição matemática de conjunto. Portanto, podemos manipular matematicamente os eventos utilizando álgebra de conjuntos. A tabela abaixo mostra a equivalência entre os conceitos fundamentais de teoria de conjuntos e a terminologia utilizada em teoria de probabilidades.</p>
<div id="tbl-equivalencia-teoria-conjuntos" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-equivalencia-teoria-conjuntos-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabela&nbsp;1: Resumo de conceitos fundamentais de teoria de conjuntos.
</figcaption>
<div aria-describedby="tbl-equivalencia-teoria-conjuntos-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/probabilidade-conjuntos.png" class="img-fluid figure-img">
</div>
</figure>
</div>
<p><strong>Lei de Probabilidade</strong></p>
<p>A <strong>lei de probabilidade</strong> <span class="math inline">\(P[A]\)</span> associa a cada evento no espaço amostral (<span class="math inline">\(A \subseteq \Omega\)</span>) um valor numérico não negativo que quantifica a “propensão” de <span class="math inline">\(A\)</span> ocorrer. Na ilustração da <a href="#fig-probabilidade-modelo" class="quarto-xref">Figura&nbsp;1</a>, altura de cada “barra” representa uma medida de incerteza ou a probabilidade associada à ocorrência dos eventos correspondentes.</p>
<p>A escolha de como atribuir probabilidades aos eventos é crucial. Uma vez definidas as probabilidades, cabe à teoria matemática apenas a tarefa de realizar os cálculos. Existem diversas interpretações para o conceito de probabilidade, como veremos a seguir.</p>
<section id="interpretações-de-probabilidade" class="level2">
<h2 class="anchored" data-anchor-id="interpretações-de-probabilidade">Interpretações de Probabilidade</h2>
<blockquote class="blockquote">
<p><em>“Probability is the most important concept in modern science, especially as nobody has the slightest notion what it means.”</em></p>
<p>—Bertrand Russell, 1929 Lecture</p>
</blockquote>
<p>Veremos a seguir diferentes interpretações do conceito de probabilidade que podem ser úteis para responder a diferentes tipos de pergunta que envolvem situações de incerteza.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interpretação Clássica (<em>a priori</em>): Laplace, 1812
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[P_N(A) = \frac{n_A}{N}\]</span></p>
<p>onde:</p>
<p><span class="math inline">\(n_A\)</span>: número de resultados favoráveis<br>
<span class="math inline">\(N\)</span>: número de resultados possíveis equiprováveis, mutuamente exclusivos e coletivamente exaustivos</p>
</div>
</div>
<p>A interpretação clássica (ou <em>a priori</em>) deve-se principalemente aos trabalhos de Pierre-Simon Laplace que, em 1812, propôs a primeira tentativa rigorosa de definir probabilidade. Antes dele, a teoria de probabilidades se concentrava em questões pontuaisenvolvendo jogos de azar, sem uma formulação unficada. Em seu livro “Teoria Analítica das Probabilidades”, Laplace introduziu uma grande quantidade de novas idéias e técnicas matemáticas e mostrou aplicações científicas e práticas, como teoria dos erros, mecânica estatística e ciências atuariais. Laplace foi um matemático prodigioso, que deu contribuições a todos os problemas matemáticos existentes em sua época.</p>
<p>Segundo a interpretação clássica, o primeiro passo para definir probabilidade consiste em representar o espaço amostral (o espaço de possibilidades) como um conjunto de eventos igualmente prováveis, mutuamente exclusivos e coletivamente exausivos, isto é, devemos ter uma partição do espaço amostral em eventos equiprováveis. Assim, a probabilidade de ocorrência de um evento <span class="math inline">\(A\)</span> é dada pela razão entre o número de resultados favoráveis a <span class="math inline">\(A\)</span> (<span class="math inline">\(n_A\)</span>) e o número total de resultados possíveis (<span class="math inline">\(N\)</span>). Como o espaço amostral é definido antes (ou independentemente) da realização do experimento aleatório, esta definição determina probabilidades <em>a priori</em>.</p>
<p>O que significa dizer que um resultado é “favorável”?</p>
<p>Suponhamos que um dado honesto seja lançado e que desejamos determinar a probabilidade de observar um resultado ímpar. A fim de utilizar a definição clássica de probabilidade, precisamos de uma representação do espaço amostral formada por uma partição de eventos equiprováveis:</p>
<p><span class="math inline">\(\{1, 2, 3, 4, 5, 6\}\)</span></p>
<p>Os resultados favoráveis ao evento “o resultado é ímpar” são <span class="math inline">\(\{1, 3 , 5\}\)</span> e correspondem a 3 dos 6 resultados possíveis; portanto, <span class="math inline">\(n_A = 3\)</span> e <span class="math inline">\(N = 6\)</span>, de forma que a probabilidade desejada é</p>
<p><span class="math display">\[
P_{\textsf{ímpar}} = \frac{3}{6} = \frac{1}{2}
\]</span></p>
<p>A abordagem clássica, embora conceitualmente simples, apresenta algumas limitações. Ela não pode ser aplicada para calcular a probabilidade de eventos associados a um experimento com um número infinito de resultados possíveis; não é capaz de definir a probabilidade de eventos supostamente não equiprováveis, além de ser uma definição circular: o conceito de equiprobabilidade dos resultados é baseado no conceito de probabilidade que queremos definir.</p>
<p>Além disso, a noção de “equiprovável” depende do chamado <strong>princípio da indiferença</strong>, que afirma que quando não há razão aparente para distinguir dois resultados, atribui-se a ambos a mesma probabilidade. Contudo, essa suposição pode ser frágil ou inadequada em muitos contextos, já que muitas situações do mundo real não seguem essa estrutura ou envolvem infinitas possibilidades.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interpretação Empírica ou de Frequência Relativa (<em>a posteriori</em>): Richard V. Mises, 1919
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[P_N(A) = \lim_{N\to\infty}\frac{n(A)}{N}\]</span></p>
<p>onde:<br>
<span class="math inline">\(n_A:\)</span> número de ocorrências do evento <span class="math inline">\(A\)</span><br>
<span class="math inline">\(N:\)</span> número de realizações do experimento aleatório</p>
</div>
</div>
<p>De acordo com a <strong>interpretação empírica</strong> (ou <strong>frequentista</strong>), a probabilidade de um evento A corresponde ao limite da frequência relativa de sua ocorrência conforme o onforme o número de repetições do experimento aleatório tende ao infinito.</p>
<p>Segundo esta interpretação, para determinar a probabilidade de obter resultado ímpar ao lançar um dado, bastaria repetir o experimento de lançar o dado um grande número de vezes, em condições uniformes, registrar a proporção de vezes em que o resultado sai ímpar e observar o valor ao qual essa proporção converge.</p>
<p>A definição de frequência relativa difere da definição clássica das seguintes maneiras:</p>
<ol type="i">
<li><p>Ela não se refere ao princípio da indiferença; pelo contrário, as probabilidades de ocorrência dos eventos não podem ser determinadas antes da realização do experimento, através da simples análise do espaço amostral e, por esta razão, as probabilidades nesta definição são determinadas <em>a posteriori</em>.</p></li>
<li><p>Probabilidades não podem ser definidas para uma única realização do experimento. Não existe probabilidade de obter um resultado ímpar em um único lançamento de um dado honesto.</p></li>
</ol>
<p>Esta definição se apóia no “princípio da regularidade estatística”, que determina que eventos aleatórios apresentam uma certa regularidade ao serem realizados um número muito grande de vezes. Quando um experimento aleatório é replicado, os resultados diferem de maneira imprevisível de uma realização para outra. Uma sequência de realizações constitui um caminho aleatório e diferentes caminhos aleatórios são únicos, distintos entre si, mas apresentam um comportamento estável no longo prazo. Desta forma, a frequência relativa de ocorrência de um certo evento se estabiliza quando o número total de realizações do experimento aumenta e, assim se aproxima de um limite, que define a probabilidade deste evento.</p>
<p>Von Mises acreditava que um valor numérico de probabilidade somente fazia sentido no caso de um experimento replicável. Sendo assim, para ele, a teoria de probabilidades não poderia ser aplicada para calcular a probabilidade de observar eventos únicos, tais como quando queremos saber “qual a chance de um determinado time vencer o próximo campeonato?”. No entanto, é claro que as pessoas associam valores numéricos para probabilidades na hora de fazerem suas apostas, por exemplo. Para Von Mises, porém, probabilidades desta natureza estão fora do domínio da teoria de probabilidades em um sentido estritamente frequentista.</p>
<p>E este é exatamente o tipo de situação tratada pelo conceito subjetivo de probabilidade, apresentada em seguida.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interpretação Subjetiva
</div>
</div>
<div class="callout-body-container callout-body">
<p>De acordo com a interpretação subjetiva, probabilidades correspondem a níveis de convicção ou crença que um indivíduo atribui à ocorrência de um evento, com base em suas informações e experiências pessoais. Segundo essa perspectiva, probabilidades representam um julgamento individual a respeito da chance de ocorrência do evento, embora possam ser matematicamente formalizadas sob determinadas condições de consistência.</p>
</div>
</div>
<p>Na abordagem subjetiva, probabilidades refletem julgamentos individuais sobre a chance de algo ocorrer, ainda que tais eventos não sejam replicáveis ou equiprováveis. Por exemplo, ao afirmar “acredito que há 70% de chance de chover amanhã”, um pescador embasa-se na previsão do tempo, dados históricos e na própria experiência. Outro pescador, com mais ou menos informações, pode chegar a um valor diferente (80% ou 60%, por exemplo).</p>
<p>Desse modo, eventos como “probabilidade de um candidato vencer as eleições” ou “chance de sucesso em uma cirurgia complexa” podem ser analisados sob a ótica subjetiva, visto que são fortemente influenciados por informações parciais, opiniões de especialistas e dados incompletos.</p>
<section id="considerações-sobre-as-diferentes-interpretações" class="level3">
<h3 class="anchored" data-anchor-id="considerações-sobre-as-diferentes-interpretações">Considerações sobre as Diferentes Interpretações</h3>
<p>As três interpretações de probabilidade (clássica, empírica/frequentista e subjetiva) se complementam ao permitir quantificar incertezas em cenários distintos. Cada uma responde a perguntas diferentes. A interpretação clássica é útil quando o espaço amostral é finito e equiprovável (como em jogos de azar), definindo probabilidades a priori. A interpretaçao empírica/frequentista baseia-se na repetição de experimentos e análise de frequências relativas a posteriori, sendo aplicável em problemas onde é viável coletar dados de múltiplas repetições sob condições semelhantes. A interpretação subjetiva lida com crenças individuais e incorpora informação incompleta, sendo empregada em cenários em que a repetição do experimento é inviável ou impossível, ou nos quais diferentes agentes podem ter níveis distintos de conhecimento.</p>
<p>Em última análise, a forma como atribuímos probabilidades depende tanto da natureza do problema quanto dos objetivos práticos. Qualquer que seja a interpretação adotada, a definição axiomática de Kolmogorov (descrita a seguir) garante que as propriedades matemáticas da probabilidade sejam consistentes.</p>
</section>
</section>
<section id="definição-axiomática" class="level2">
<h2 class="anchored" data-anchor-id="definição-axiomática">Definição Axiomática</h2>
<p>A formalização matemática da teoria de probabilidades deve-se a Andrey Kolmogorov (1933). Sua definição axiomática estabelece um conjunto de regras universais, que se aplicam a qualquer interpretação de probabilidade. Essa é, portanto, uma definição rigorosa, que estabelece os critérios necessários para garantir que uma função matemática qualquer seja considerada uma <strong>função probabilidade</strong>.</p>
<p>Para definir função probabilidade, é necessário definir um espaço de eventos <span class="math inline">\(\mathcal{A}\)</span>, que corresponde à coleção de todos os subconjuntos do espaço amostral <span class="math inline">\(\Omega\)</span>.</p>
<p><strong>Espaço de Eventos</strong> <span class="math inline">\(\mathcal{A}\)</span></p>
<p>Formalmente, <span class="math inline">\(\mathcal{A}\)</span> deve satisfazer as seguintes condições:</p>
<ol type="1">
<li><span class="math inline">\(\Omega \in \mathcal{A}\)</span></li>
<li>Se <span class="math inline">\(A \in \mathcal{A}\)</span> então o complementar <span class="math inline">\(A^C \in \mathcal{A}\)</span></li>
<li>Se <span class="math inline">\(A, B \in \mathcal{A}\)</span>, então <span class="math inline">\(A \cup B \in \mathcal{A}\)</span></li>
</ol>
<p>O espaço de eventos <span class="math inline">\(\mathcal{A}\)</span> não deve ser confundido com o espaço amostral <span class="math inline">\(\Omega\)</span>, pois enquanto o espaço amostral de um experimento aleatório contém todos os resultados possíveis deste experimento (isto é, a coleção de todos os eventos simples), o espaço de eventos contém todos os conjuntos de resultados do experimento, isto é, todos os subconjuntos do espaço amostral. O espaço de eventos inclui o espaço amostral <span class="math inline">\(\Omega\)</span> e é fechado para o complemento e para a união de eventos.</p>
<p><strong>Função Probabilidade</strong></p>
<p>Dada uma coleção de eventos <span class="math inline">\(\mathcal{A}\)</span> associada ao experimento aleatório, define-se a função de probabilidade como</p>
<p><span class="math inline">\(P: \mathcal{A} \longrightarrow \Re,\)</span></p>
<p>que atende aos seguintes aximomas:</p>
<ol type="i">
<li><p><span class="math inline">\(P[A] \geq 0\)</span> para todo <span class="math inline">\(A \in \mathcal{A}\)</span></p></li>
<li><p><span class="math inline">\(P[\Omega] = 1\)</span></p></li>
<li><p>Se <span class="math inline">\(\{A_i\}\)</span> é uma coleção enumerável de eventos <em>mutuamente exclusivos</em>, então<br>
<span class="math display">\[P\left[ \cup_{i=1}^\infty A_i\right] = \sum_{i=1}^{\infty} P[A_i]\]</span></p></li>
</ol>
<p>Em outras palavras, uma função real <span class="math inline">\(P\)</span> definida no espaço de eventos do experimento aleatório é função probabilidade se satisfaz as seguintes condições:</p>
<ol type="i">
<li>a probabilidade de qualquer evento é sempre um valor não negativo;<br>
</li>
<li>se um evento é certo, então sua probabilidade vale 1 (em outras palavras, toda vez que o experimento aleatório é realizado, algum dos eventos que compõem o espaço amostral necessariamente precisa ocorrer); e, finalmente,<br>
</li>
<li>existe aditividade contável para eventos que não possam ocorrer simultaneamente.</li>
</ol>
<p>Note que a definição axiomática não nos ensina como escolher a função de probabilidade; ela não nos ensina como calcular o valor de <span class="math inline">\(P\)</span> para um determinado evento conhecido <span class="math inline">\(A \in \mathcal{A}\)</span> e tampouco nos revela a natureza de processos aleatórios. A definição matemática garante, no entanto, que qualquer função que satisfaça os três axiomas terá certas propriedades que intuitivamente associamos a uma probabilidade, sob quaisquer das interpretações descritas anteriormente.</p>
<p><strong>Propriedades de Função Probabilidade</strong></p>
<p>A partir dos três axiomas que definem função probabilidade, é possível deduzir uma série de propriedades importantes:</p>
<ol type="i">
<li><p><span class="math inline">\(P[\varnothing] = 0\)</span></p></li>
<li><p>Para uma coleção finita de eventos mutuamente exclusivos <span class="math inline">\(A_1, A_2, \ldots, A_n\)</span>, vale</p></li>
</ol>
<p><span class="math display">\[P\left[\cup_{i=1}^{n}A_i\right] = \sum_{i=1}^{n} P[A_i]\quad\]</span> <span class="math inline">\(\Rightarrow \quad P[B] = P[B\cap A] + P[B\cap A^C]\)</span></p>
<ol start="3" type="i">
<li><p><span class="math inline">\(P[A] + P[A^C] = 1\)</span></p></li>
<li><p><span class="math inline">\(0 \leq P[A] \leq 1\)</span>, para qualquer evento <span class="math inline">\(A\)</span></p></li>
<li><p>Regra da Adição: <span class="math display">\[P[A \cup B] = P[A] + P[B] - P[A \cap B]\quad\]</span> Essas propriedades são coerentes com nossa intuição sobre probabilidade — por exemplo, o evento impossível (<span class="math inline">\(\varnothing\)</span>) tem probabilidade zero, e a probabilidade de um evento mais o seu complementar soma 1. No entanto, a definição axiomática, por si só, não diz como devemos atribuir o valor de <span class="math inline">\(P[A]\)</span> para cada evento <span class="math inline">\(A\)</span>. Essa escolha depende justamente das abordagens clássica, frequentista ou subjetiva (entre outras) e do contexto em que o experimento se insere.</p></li>
</ol>
<hr>
</section>
</section>
<section id="probabilidade-condicional-e-independência" class="level1">
<h1>Probabilidade Condicional e Independência</h1>
<p>Até agora, para cada experimento aleatório em análise, associamos um espaço amostral <span class="math inline">\(\Omega\)</span> e calculamos todas as probabilidades de interesse com base nesse conjunto de possíveis resultados. No entanto, em muitas situações, temos a possibilidade de <em>atualizar</em> esse espaço amostral, levando em conta novas informações ou evidências obtidas. Esse novo conhecimento leva à necessidade de recalcular as probabilidades de interesse, resultando no conceito de <em>probabilidades condicionais</em>.</p>
<p>Em outras palavras, quando sabemos que certo evento ocorreu, passamos a considerar apenas o subconjunto dos resultados compatíveis com essa nova evidência. Assim, dizemos que houve uma <em>intervenção</em> no espaço amostral, pois ele foi efetivamente modificado pela informação adicional obtida. Como consequência, as probabilidades são revistas para refletir essa condição prévia.</p>
<p>No exemplo a seguir, a parte destacada em negrito mostra o evento que constitui a informação adicional sobre o experimento, chamado <em>evento condicionante</em>. O evento condicionante restringe o espaço de possibilidades, modificando os valores das probabilidades associadas para os demais eventos do experimento aleatório.</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 3 (Lançamento de Dois Dados)</strong></span> <br>
</p>
<p>Considere o experimento aleatório que consiste em lançar um dado duas vezes e observar os dois resultados obtidos.</p>
<p>Sem informação adicional alguma, sabemos que a probabilidade de que o primeiro resultado tenha sido ‘6’ vale 1/6, desde que o dado seja honesto. Podemos visualizar o espaço amostral <span class="math inline">\(\Omega\)</span> associado a este experimento no diagrama da esquerda, abaixo, onde o eixo vertical (D1) representa os resultados possíveis para o primeiro dado e o eixo horizontal (D2) representa os resultados possíveis para o segundo dado. Veja que, de um total de 36 combinações possíveis, em seis delas o valor obtido no primeiro dado é ‘6’.</p>
<p><img src="img/pcondicional-soma-dados.png" class="img-fluid"></p>
<p>Agora, considere que a seguinte informação adicional foi obtida: <strong>a soma dos dois resultados vale ‘9’</strong>. Como o conhecimento deste fato altera a probabilidade de que o resultado do primeiro dado tenha sido ‘6’?</p>
<p>Note que a nova informação <em>restringe</em> o espaço amostral, pois agora apenas as combinações que totalizam ‘9’ continuam sendo possíveis. No novo espaço amostral <span class="math inline">\(\Omega^\prime\)</span>, do diagrama da direita, essas possibilidades estão representadas em azul. Nesse espaço modificado, em apenas uma dessas combinações o primeiro lançamento resulta em ‘6’. Assim, à luz da ova informação, a probabilidade de o prineiro resultado ter sido ‘6’ atualiza-se para 1/4. A probabilidade de que D1 = 6 é calculada com relação às ocorrências em que D1 + D2 = 9. É precisamente esse recondicionamento (restringir aos resultados cuja soma vale ‘9’) que exemplifica o conceito de probabilidade condicional.</p>
<p>O código em R, abaixo, ilustra o uso de simulação para estimar de forma empírica a probabilidade de que o primeiro resultado seja ‘6’, condicionado ao fato de que a soma dos resultados dos dois dados seja ‘9’.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100000</span>  <span class="co"># tamanho da simulação</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>lancamentos_1 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>lancamentos_2 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Filtra os casos em que a soma é igual a 9</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>filtro_soma_9 <span class="ot">&lt;-</span> (lancamentos_1 <span class="sc">+</span> lancamentos_2) <span class="sc">==</span> <span class="dv">9</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcula a proporção de vezes em que o primeiro dado é 6, </span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># sob condição desejada</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>prob_condicional <span class="ot">&lt;-</span> <span class="fu">mean</span>(lancamentos_1[filtro_soma_9] <span class="sc">==</span> <span class="dv">6</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostra o resultado</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"----</span><span class="sc">\n</span><span class="st">"</span>,</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Probabilidade de o primeiro lançamento ser 6 dado que a soma é 9:</span><span class="sc">\n</span><span class="st">"</span>,</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    prob_condicional, </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">"</span><span class="sc">\n</span><span class="st">----"</span>) </span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>----
 Probabilidade de o primeiro lançamento ser 6 dado que a soma é 9:
 0.2499775 
----</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<p>Vejamos como o conceito de probabilidade condicional pode ser aplicado a contextos práticos. Considere o caso de um radar que pode ou não detectar um avião que sobrevoa certa região. Nesse experimento aleatório, estamos interessados na probabilidade de haver um avião, <strong>dado que ocorreu detecção</strong>. Ainda que um avião possa passar e não ser detectado, também existe o risco de o radar acusar a presença de algo que não seja, de fato, um avião. Assim, a informação adicional de que houve detecção ‘filtra’ o espaço amostral para incluir apenas as situações em que o radar emitiu um sinal; consequentemente, a probabilidade de que esse objeto seja realmente um avião muda em relação à probabilidade inicial, sem detecção. Eis uma atualização típica por probabilidade condicional, pois ignoramos a possibilidade de um avião não detectado e passamos a trabalhar apenas com o conjunto de resultados compatíveis com a ocorrência de um sinal.</p>
<p>Um raciocínio muito semelhante aplica-se a um teste diagnóstico: um paciente suspeita que esteja doente e se submete a um teste laboratorial. Antes de realizar o exame, há uma probabilidade pré-teste de que esteja doente, baseada em fatores epidemiológicos. O resultado do teste é negativo. A partir de então, perguntamos: qual a probabilidade de que ele esteja doente, mesmo com o teste negativo? Se o teste não for perfeito — isto é, se puder apresentar tanto falsos positivos como falsos negativos — a probabilidade de doença precisa ser recalculada, considerando sensibilidade (capacidade de identificar corretamente a presença da doença) e especificidade (capacidade de identificar corretamente que o paciente não possui a doença) do método empregado, além da incidência (ou prevalência) da condição investigada. Novamente, o resultado negativo ‘intervém’ no espaço amostral, excluindo as possibilidades correspondentes a testes positivos e alterando a probabilidade de que o paciente efetivamente possua a doença.</p>
<p>Os exemplos anteriores mostram situações em que novas informações sobre o experimento aleatório (como “a soma dos dados foi 9”, “o radar acusou detecção” ou “o teste deu negativo”) modificaram significativamente o conjunto de possibilidades iniciais. Veremos a seguir a fundamentação formal de probabilidade condicional. A ideia-chave é que, ao sabermos que determinado evento ocorreu, nosso “universo” de resultados possíveis se contrai para o subconjunto compatível com essa evidência adicional. É essa noção de “restringir o espaço amostral” que nos leva a redefinir a probabilidade de interesse, levando em conta apenas os casos remanescentes depois da informação recebida.</p>
<section id="probabilidade-condicional" class="level2">
<h2 class="anchored" data-anchor-id="probabilidade-condicional">Probabilidade Condicional</h2>
<p>Sejam <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> dois eventos associados a um experimento aleatório <span class="math inline">\(E\)</span>, definidos em um espaço amostral <span class="math inline">\(\Omega\)</span>.</p>
<p>A <strong>probabilidade condicional do evento A ao evento B</strong> corresponde à razão entre a probabilidade da ocorrência simultânea dos eventos <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> e a probabilidade de ocorrência do evento <span class="math inline">\(B\)</span>. Formalmente, definimos:</p>
<p><span class="math display">\[P[A|B] \stackrel{\Delta}{=} \frac{P[AB]}{P[B]}, \quad \text{com}\; P[B] &gt; 0. \]</span></p>
<p>O evento <span class="math inline">\(B\)</span> é chamado <strong>evento condicionante</strong>, enquanto <span class="math inline">\(A\)</span> é chamado <strong>evento condicionado</strong>. Intuitivamente, isso significa que, uma vez que se sabe que <span class="math inline">\(B\)</span> ocorreu, somente as possibilidades compatíveis com <span class="math inline">\(B\)</span> podem se concretizar. Logo, a probabilidade de <span class="math inline">\(A\)</span>, dada essa evidência prévia, corresponde à fração de casos em que <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> ocorrem simultaneamente, em relação ao conjunto de casos em que <span class="math inline">\(B\)</span> ocorre. A expressão <span class="math inline">\(P[A|B]\)</span> lê-se probabilidade condicional de <span class="math inline">\(A\)</span>, dado <span class="math inline">\(B\)</span>.</p>
<p>Obviamente, a probabilidade de <span class="math inline">\(B\)</span> deve ser maior que zero, pois não podemos condicionar a ocorrência de um evento à ocorrência de algo que é impossível de acontecer, ou seja, que tem probabilidade zero. Temos certeza da ocorrência do evento <span class="math inline">\(B\)</span>, considerando que a informação adicional seja verdadeira. O evento <span class="math inline">\(B\)</span> passa a ser um “novo espaço amostral”, de forma que a probabilidade de observar <span class="math inline">\(B\)</span> dado que <span class="math inline">\(B\)</span> ocorreu vale 1. A probabilidade condicional é a proporção desse novo espaço amostral <span class="math inline">\(B\)</span> “ocupada” pelo evento <span class="math inline">\(A\)</span> (isso só acontece com a interseção entre <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span>). Então, a probabilidade de <span class="math inline">\(A\)</span> dado <span class="math inline">\(B\)</span> representa o quanto da chance de ocorrência de <span class="math inline">\(B\)</span> pode ser representada como a chance de ocorrência de <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span>, simultaneamente. Uma informação adicional sempre restringe o número de possibilidades do espaço amostral original. Por esse motivo, o evento condicionante também é chamado de <em>espaço amostral reduzido</em>.</p>
<p>A consequência natural dessa definição é a chamada regra do produto, obtida ao multiplicarmos ambos os lados da equação por <span class="math inline">\(P[B]\)</span>:</p>
<p><span class="math inline">\(P[AB] = P[A|B] P[B] = P[B|A] P[A] \qquad\)</span> (Regra do Produto)</p>
<p>Essa regra expressa a probabilidade de <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> ocorrerem simultaneamente em função de probabilidades condicionais, tanto de <span class="math inline">\(A\)</span> dado <span class="math inline">\(B\)</span> quanto de <span class="math inline">\(B\)</span> dado <span class="math inline">\(A\)</span>. Esta é uma ferramenta muito útil para diversos cálculos de probabilidade, pois nos permite reorganizar os termos dependendo de qual evento for considerado condicionante.</p>
<section id="propriedades" class="level3">
<h3 class="anchored" data-anchor-id="propriedades">Propriedades</h3>
<p>Probabilidade condicional é função probabilidade; isto significa que é uma medida de incerteza válida e, portanto, satisfaz os três axiomas de Kolmogorov.</p>
<p>Isso significa, em primeiro lugar, que <span class="math inline">\(P[A|B]\)</span> é um número não negativo; em segundo lugar, que a probabilidade do espaço amostral inteiro, quando condicionada a B, vale 1; e, por fim, que a soma de probabilidades de eventos mutuamente exclusivos (condicionados a <span class="math inline">\(B\)</span>) corresponde à soma das probabilidades condicionais de cada um desses eventos. Simbolicamente, temos:</p>
<ol type="1">
<li><p><span class="math inline">\(P[A|B] \geq 0\)</span></p></li>
<li><p><span class="math inline">\(P[\Omega|B] = 1\)</span></p></li>
<li><p><span class="math inline">\(A_1, A_2, \ldots\)</span> tais que <span class="math inline">\(A_i \cap A_j = \varnothing, \; \forall i\neq j \Rightarrow \; P[\cup_i A_i |B] = \sum_i P[A_i|B]\)</span></p></li>
</ol>
<p>Outras propriedades resultantes incluem as relações com complementos, uniões e interseções:</p>
<ol start="4" type="1">
<li><p><span class="math inline">\(P[A^c|B] = 1 - P[A|B]\)</span><br>
No entanto, geralmente, <span class="math inline">\(P[A|B^c] \neq 1 - P[A|B]\)</span></p></li>
<li><p><span class="math inline">\(P[A \cup B|C] = P[A|C] + P[B|C] - P[A B|C], \; P[C]&gt;0\)</span></p></li>
<li><p><span class="math inline">\(AB = \varnothing \; \Rightarrow \; P[A|B] = 0\)</span></p></li>
<li><p><span class="math inline">\(B \subset A \; \Rightarrow \; P[A|B] = 1\)</span></p></li>
</ol>
<p>É importante perceber também que não há um vínculo fixo entre as probabilidades condicionais e as probabilidades <em>a priori</em>. Assim, <span class="math inline">\(P[A|B]\)</span> pode ser maior, menor ou igual a <span class="math inline">\(P[A]\)</span>, dependendo da informação trazida pelo conhecimento de <span class="math inline">\(B\)</span>. O conceito de probabilidade condicional leva à noção de independência de eventos, conforme veremos a seguir.</p>
</section>
</section>
<section id="independência-de-eventos" class="level2">
<h2 class="anchored" data-anchor-id="independência-de-eventos">Independência de Eventos</h2>
<p>Outro conceito fundamental associado à probabilidade condicional é o de independência. Dois eventos <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> são ditos <strong>independentes</strong> quando a informação de que um deles ocorreu não altera a probabilidade do outro ocorrer. Em termos formais, isso significa que a probabilidade de <span class="math inline">\(A\)</span>, condicionada à ocorrência de <span class="math inline">\(B\)</span>, é igual à probabilidade ‘a priori’ de <span class="math inline">\(A\)</span> (e vice-versa, trocando o papel dos eventos). Como consequência imediata, a probabilidade de <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> ocorrerem simultaneamente se expressa pelo produto de suas probabilidades marginais, <span class="math inline">\(P[A]\)</span> e <span class="math inline">\(P[B]\)</span>. Assim, dois eventos <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> são independentes se, e somente se:</p>
<p><span class="math display">\[P[A|B] = P[A]\quad e \quad  P[B|A] = P[B] \qquad \Longrightarrow \qquad P[AB] = P[A] P[B]\]</span></p>
<p>Em outras palavras, quando a ocorrência de <span class="math inline">\(B\)</span> não exerce nenhuma influência na chance de <span class="math inline">\(A\)</span> acontecer (e vice-versa), temos independência de eventos. É importante salientar, contudo, que a independência deve ser pressuposta ou verificada empiricamente a partir de informações sólidas; não se trata de uma propriedade derivada de maneira automática, mas sim de uma hipótese que precisa ser cuidadosamente avaliada no contexto de cada problema.</p>
<p>Temos, a seguir, algumas propriedades associadas a eventos independentes:</p>
<section id="propriedades-1" class="level3">
<h3 class="anchored" data-anchor-id="propriedades-1">Propriedades</h3>
<p>Sejam <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> eventos quaisquer em <span class="math inline">\(\Omega\)</span>.</p>
<p>Em primeiro lugar, sem maiores considerações, notamos que qualquer conjunto <span class="math inline">\(A\)</span> é independente de <span class="math inline">\(\varnothing\)</span> e também de <span class="math inline">\(\Omega\)</span>:</p>
<ol type="1">
<li><span class="math inline">\(\forall A \subset \Omega\)</span>:<br>
</li>
</ol>
<ul>
<li><span class="math inline">\(A\)</span> e <span class="math inline">\(\varnothing\)</span> são independentes<br>
</li>
<li><span class="math inline">\(A\)</span> e <span class="math inline">\(\Omega\)</span> são independentes</li>
</ul>
<ol start="2" type="1">
<li>Se <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> são independentes:</li>
</ol>
<ul>
<li><span class="math inline">\({A^c}\)</span> e <span class="math inline">\({B^c}\)</span><br>
</li>
<li><span class="math inline">\({A}\)</span> e <span class="math inline">\({B^c}\)</span><br>
</li>
<li><span class="math inline">\({A^c}\)</span> e <span class="math inline">\({B}\)</span> … também são independentes.</li>
</ul>
<p>O fato de um par de eventos ser independente “espalha” a independência por suas complementares, preservando a condição de que o conhecimento de um evento não altera a probabilidade do outro ocorrer.</p>
<p>As condições de independência tornam-se mais complexas quando consideramos uma coleção <span class="math inline">\(A_1, A_2, \ldots A_n\)</span> de eventos.</p>
<ol start="3" type="1">
<li><strong>Independência aos Pares</strong>.<br>
Para que esses eventos sejam <em>independentes aos pares</em>, basta que cada par de eventos <span class="math inline">\((A_i, A_j)\)</span> satisfaça:</li>
</ol>
<p><span class="math display">\[{P[A_iA_j] = P[A_i]P[A_j], \quad \forall i \neq j}\]</span></p>
<p>No entanto, independência aos pares não garante que o conjunto completo de eventos seja <em>mutuamente independente</em>. Para que haja independência global, deve-se verificar que a probabilidade de interseção de qualquer subconjunto dos eventos (com tamanho variando de 2 até <span class="math inline">\(n\)</span>) seja igual ao produto das probabilidades marginais de seus integrantes.</p>
<ol start="4" type="1">
<li><strong>Independência Global</strong>.<br>
<span class="math inline">\({A_1, A_2, \ldots A_n}\)</span> são <em>globalmente independentes</em> se, e somente se,<br>
<span class="math inline">\(P[A_iA_j] = P[A_i]P[A_j], \quad i \neq j\)</span><br>
<span class="math inline">\(P[A_iA_jA_k] = P[A_i]P[A_j]P[A_k], \quad i \neq j, i \neq k, j \neq k\)</span><br>
<span class="math inline">\(\vdots\)</span><br>
<span class="math inline">\(P[\cap_{i=1}^{n}A_i] = \prod_{i=1}^{n} P[A_i]\)</span>.</li>
</ol>
<p>Assim, para garantir que essa coleção seja globalmente independente, precisamos garantir independência dois-a-dois, três-a-três e assim, sucessivamente, até n-a-n.&nbsp;Trata-se de um grande número de condições, dado que <span class="math inline">\(\sum_{k=2}^{n} = 2^n - n - 1\)</span>. Embora trabalhoso, esse cuidado é necessário para assegurar que nenhum subconjunto de eventos quebre a regra de independência.</p>
<p><strong>Independência Condicional</strong></p>
<p>Dois eventos <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> são condicionalmente independentes em relação a um terceiro evento <span class="math inline">\(C\)</span> se, sabendo que <span class="math inline">\(C\)</span> ocorreu, a probabilidade de <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> ocorrerem simultaneamente é igual ao produto das probabilidades condicionais de <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> dado <span class="math inline">\(C\)</span>, ou seja:</p>
<p><span class="math display">\[{P[AB|C] = P[A|C]P[B|C]}\]</span> Isso indica que, no “universo” reduzido por <span class="math inline">\(C\)</span>, a ocorrência de <span class="math inline">\(A\)</span> não influi na de <span class="math inline">\(B\)</span>, e vice-versa, ainda que <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> possam não ser independentes no espaço amostral original.</p>
<p><strong>Eventos Independentes x Eventos Mutuamente Exclusivos</strong></p>
<p>Por fim, vale reforçar a distinção entre eventos independentes e eventos mutuamente exclusivos (ou disjuntos). Nos eventos independentes, saber que <span class="math inline">\(B\)</span> ocorreu não modifica a probabilidade de <span class="math inline">\(A\)</span>, enquanto, nos eventos mutuamente exclusivos, a ocorrência de um impede necessariamente a ocorrência do outro. No extremo, um par de eventos mutuamente exclusivos evidencia uma dependência completa: se <span class="math inline">\(A\)</span> acontece, <span class="math inline">\(B\)</span> não pode ocorrer, e vice-versa. Essa diferença conceitual é crucial, pois muitas vezes os termos são confundidos, mas representam situações opostas em termos de interferência nas probabilidades.</p>
</section>
<section id="aplicação-confiabilidade-de-sistemas" class="level3">
<h3 class="anchored" data-anchor-id="aplicação-confiabilidade-de-sistemas">Aplicação: Confiabilidade de Sistemas</h3>
<p>Uma aplicação interessante de independência de eventos é a análise de confiabilidade de sistemas, isto é, a probabilidade de que o sistema continue a operar sem falhas. Comumente, a confiabilidade de um sistema é determinada com base na probabilidade de falha de seus componentes (ou subsistemas) e na forma como estão arranjados. Na prática, essa informação pode orientar a escolha, dentre diferentes alternativas de projeto, de soluções que atendam aos requisitos de projeto de maneira mais segura ou econômica.</p>
<p>Em análise de confiabilidade, é comum fazer a suposição de independência entre falhas de componentes, a fim de simplificar os cálculos, ainda que em situações reais, nem sempre seja válida.</p>
<p><strong>Arranjos em Série e em Paralelo</strong></p>
<p>Para fins de ilustração, considere um sistema formado por apenas dois componentes, <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span>, que podem estar dispostos dentro do sistema em série ou em paralelo.</p>
<p><img src="img/confiabilidade.png" class="img-fluid"></p>
<p>E vamos definir os seguintes eventos de interesse:</p>
<p><span class="math inline">\(A\)</span> = componente ‘A’ falha<br>
<span class="math inline">\(B\)</span> = componente ‘B’ falha</p>
<p>No <em>arranjo em série</em>, o sistema só funciona se ambos os componentes estiverem operando simultaneamente. Se pelo menos um dos componentes falhar, o sistema falha. Portanto, a probabilidade de falha do sistema com componentes em série <span class="math inline">\(P_s\)</span> é dada pela probabilidade da união dos eventos <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span>:</p>
<p><span class="math display">\[P_s = P[A \cup B] = P[A] + P[B] - P[AB]\]</span></p>
<p>No arranjo em paralelo, o sistema só falha apenas se ambos os componentes falharem simultaneamente. Nesse caso, assumindo que as falhas são independentes, a probabilidade de falha do sistema <span class="math inline">\(P_p\)</span> é o produto das probabilidades de falha individuais:</p>
<p><span class="math display">\[P_p = P[A \cup B] = P[A] \times P[B]\]</span> Sistemas em paralelo são comumente chamados _sistemas redundantes), pois a presença de mais de um componente reduz a chance de falha global.</p>
<p>Vejamos, a seguir, um exemplo simples que envolve o conceito de independência para comparar a confiabilidade dos dois tipos de aeronaves.</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 4 (Aeronaves com Duas ou Quatro Turbinas)</strong></span> <br>
</p>
<p>Considere dois tipos de aeronaves:</p>
<ul>
<li>A2: aeronave de duas turbinas</li>
<li>A4: aeronave de quatro turbinas</li>
</ul>
<p>Ambas as aeronaves voam em segurança se pelo menos a metade de seus motores estiver operando corretamente. Caso contrário, será necessário realizar um pouso forçado. Assuma que cada turbina falha ou funciona de modo independente e que cada turbina tem probabilidade <span class="math inline">\(p\)</span> de funcionar corretamente em um voo. Nosso objetivo é comparar a confiabilidade das duas aeronaves, isto é, determinar qual das duas tem menor probabilidade de pouso forçado, em função do valor do parâmetro <span class="math inline">\(p\)</span>.</p>
<p>Vamos iniciar pela solução analítica desse problema.</p>
<p><strong>Solução analítica</strong></p>
<p>Sejam os eventos:</p>
<p><span class="math inline">\(T2\)</span> = A2 faz pouso forçado<br>
<span class="math inline">\(T4\)</span> = A4 faz pouso forçado</p>
<p>Precisamos calcular <span class="math inline">\(P[T2]\)</span> e <span class="math inline">\(P[T4]\)</span>, a probabilidade de pouso forçado em cada caso.</p>
<ol type="1">
<li><em>Aeronave A2:</em> o pouso forçado acontece quando uma ou as duas turbinas falham. Em termos de eventos complementares, o sistema “funciona” quando há uma ou duas turbinas em operação. Assim, a probabilidade de pouso forçado para A2 vale:</li>
</ol>
<p><span class="math display">\[\begin{align*}
P[T2]
&amp;= 1 - P[\text{1 turbina funcionando OU 2 turbinas funcionando}]\\
&amp;= 1 - P[\text{1 turbina funcionando}] - P[\text{2 turbinas funcionando}]\\
&amp;= 1 - {{2}\choose{1}} (1-p) p + p^2\\
&amp;= 1 + p^2 - 2p
\end{align*}\]</span></p>
<p>Alternativamente, podemos perceber que a aeronave A2 falha quando nenhuma turbina funciona. Logo:</p>
<p><span class="math display">\[\begin{align*}
P[T2]
&amp;= P[\text{0 turbina funcionando}]\\
&amp;= (1-p)^2\\
&amp;= 1 + p^2 - 2p
\end{align*}\]</span></p>
<ol start="2" type="1">
<li><em>Aeronave A4:</em> o pouso forçado ocorre quando três ou quatro turbinas falham, já que neste caso haveria menos do que duas turbinas em operação. Assim, a probabilidade de pouso forçado para A4 vale:</li>
</ol>
<p><span class="math display">\[\begin{align*}
P[T4]
&amp;= 1 - P[\text{2 funcionando OU 3 funcionando OU 4  funcionando}]\\
&amp;= 1 - P[\text{2 funcionando}] - P[\text{3 funcionando}] - P[\text{4 funcionando}]\\
&amp;= 1 - {{4}\choose{2}}p^2(1-p)^2 - {{4}\choose{3}}p^3(1-p) - p^4 \\
&amp;= 1 - 6p^2 - 3p^4 + 8 p^3
\end{align*}\]</span></p>
<p>Alternativamente, podemos perceber que a aeronave A4 falha quando nenhuma turbina funciona ou quando apenas uma turbina funciona. Assim:</p>
<p><span class="math display">\[\begin{align*}
P[T4]
&amp;= P[\text{0 turbina funcionando OU 1 turbina funcionando}]\\
&amp;= P[\text{0 funcionando}] + P[\text{1 funcionando}]\\
&amp;= (1-p)^4 + {{4}\choose{1}}p(1-p)^3\\
&amp;= 1 - 6p^2 - 3p^4 + 8 p^3
\end{align*}\]</span></p>
<p>Comparando <span class="math inline">\(P[T2]\)</span> e <span class="math inline">\(P[T4]\)</span>, verifica-se que o avião de 4 turbinas é mais seguro (tem menor probabilidade de sofrer pouso forçado) que o avião de 2 turbinas sempre que <span class="math inline">\(p &gt; 2/3\)</span>. Para valores de <span class="math inline">\(p\)</span> abaixo de <span class="math inline">\(2/3\)</span>, o modelo de duas turbinas tende a apresentar maior confiabilidade. Note que este resultado se baseia na suposiçnao de que as turbinas falhem independentemente umas das outras.</p>
<p><strong>Representação Gráfica</strong></p>
<p>A seguir, temos uma representação gráfica da solução analítica (e o código em R utilizado para obtê-la), com as probabilidades teóricas de pouso forçado para cada aeronave, como função de <span class="math inline">\(p\)</span>. Note a reta tracejada indicando o ponto <span class="math inline">\(p = 2/3\)</span>, onde <span class="math inline">\(P[T2]\)</span> e <span class="math inline">\(P[T4]\)</span> se igualam.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Carrega bibliotecas</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_minimal</span>())  <span class="co"># fundo branco para os gráficos</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Funções para probabilidades teóricas</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>p4_falha <span class="ot">&lt;-</span> <span class="cf">function</span>(p) <span class="dv">1</span> <span class="sc">-</span> <span class="dv">3</span><span class="sc">*</span>p<span class="sc">^</span><span class="dv">4</span> <span class="sc">+</span> <span class="dv">8</span><span class="sc">*</span>p<span class="sc">^</span><span class="dv">3</span> <span class="sc">-</span> <span class="dv">6</span><span class="sc">*</span>p<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>p2_falha <span class="ot">&lt;-</span> <span class="cf">function</span>(p) <span class="dv">1</span> <span class="sc">+</span> p<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>p</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Vetor de valores possíveis de p</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Monta tabela com valores calculados</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>turbinas <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">p =</span> x,</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">T2 =</span> <span class="fu">p2_falha</span>(x),</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">T4 =</span> <span class="fu">p4_falha</span>(x)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Gráfico</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(turbinas, <span class="fu">aes</span>(<span class="at">x =</span> p)) <span class="sc">+</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> T2, <span class="at">color =</span> <span class="st">"2 turbinas"</span>), <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> T4, <span class="at">color =</span> <span class="st">"4 turbinas"</span>), <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">2</span><span class="sc">/</span><span class="dv">3</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Probabilidade de cada turbina funcionar (p)"</span>,</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Probabilidade de pouso forçado"</span>,</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"Modelo de Avião"</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"2 turbinas"</span> <span class="ot">=</span> <span class="st">"blue"</span>, </span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"4 turbinas"</span> <span class="ot">=</span> <span class="st">"red"</span>))</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="MB751_AULA02_files/figure-html/ch4-confiabilidade-sol-analitica-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Solução Computacional via Simulação de Monte Carlo</strong></p>
<p>Para verificar empiricamente essas expressões teóricas, podemos simular a ocorrência de falhas em sucessivos voos. Primeiro, vamos definir a função <code>simula_voos</code> para simular voos para cada uma das aeronaves. Ela recebe como argumentos a probabilidade <code>p</code> de cada turbina funcionar e o número de voos a serem simulados <code>n_voos</code>.</p>
<p>A ideia é gerar, para cada voo, um vetor que indica se cada turbina falhou (0) ou funcionou (1). Então, verificamos se o avião faz pouso forçado conforme seu critério de segurança.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>simula_voos <span class="ot">&lt;-</span> <span class="cf">function</span>(p, n_voos) {</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Para reprodutibilidade (opcional)</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># set.seed(123)</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Gera resultados de funcionamento das turbinas:</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   0: falhou</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   1: funcionou</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Os resultados são armazenados em matrizes:</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   cada linha corresponde a um voo simulado</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   cada coluna corresponde a uma turbina</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Para o avião de 2 turbinas</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  voos_2 <span class="ot">&lt;-</span> <span class="fu">matrix</span>(</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dv">2</span><span class="sc">*</span>n_voos, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">-</span>p, p)),</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">nrow =</span> n_voos, <span class="at">ncol =</span> <span class="dv">2</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Para o avião de 4 turbinas</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>  voos_4 <span class="ot">&lt;-</span> <span class="fu">matrix</span>(</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dv">4</span><span class="sc">*</span>n_voos, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">-</span>p, p)),</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">nrow =</span> n_voos, <span class="at">ncol =</span> <span class="dv">4</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Define pouso forçado para cada voo</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># A2 falha se rowSums &lt; 1</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># A4 falha se rowSums &lt; 2</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>  fail_2 <span class="ot">&lt;-</span> <span class="fu">rowSums</span>(voos_2) <span class="sc">&lt;</span> <span class="dv">1</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>  fail_4 <span class="ot">&lt;-</span> <span class="fu">rowSums</span>(voos_4) <span class="sc">&lt;</span> <span class="dv">2</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Frequência relativa cumulativa de pousos forçados</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>  frel_2 <span class="ot">&lt;-</span> <span class="fu">cumsum</span>(fail_2) <span class="sc">/</span> <span class="fu">seq_len</span>(n_voos)</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>  frel_4 <span class="ot">&lt;-</span> <span class="fu">cumsum</span>(fail_4) <span class="sc">/</span> <span class="fu">seq_len</span>(n_voos)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Retorna frequencias relativas de pousos forçados como lista</span></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>    <span class="at">frel_2 =</span> frel_2,</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">frel_4 =</span> frel_4</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><em>Simulação de várias replicações</em></p>
<p>Podemos utilizar a função <code>simula_voos</code> para simular voos e estimar a probabilidade de pousos forçados para cada um dos tipos de aeronaves. Ao utilizar essa função apenas uma vez, temos apenas uma estimativa das probabilidades desejadas, com base em um caminho aleatório de tamanho <code>n_voos</code>. A fim de construir uma distribuição aproximada de frequências relativas que estimam a probabilidade de pouso forçado, precisamos repetir esse procedimento um número <code>nRep</code> grande de vezes, para cada valor de probabilidade <code>p</code> de funcionamento das turbinas. Implementamos isso na função <code>simula_MC</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>simula_MC <span class="ot">&lt;-</span> <span class="cf">function</span>(p, nRep, n_voos) {</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Matrizes para armazenar as frequências relativas finais</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># de cada replicação</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  frel_2_store <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> nRep, <span class="at">ncol =</span> n_voos)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  frel_4_store <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> nRep, <span class="at">ncol =</span> n_voos)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="fu">seq_len</span>(nRep)) {</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    sim <span class="ot">&lt;-</span> <span class="fu">simula_voos</span>(p, n_voos)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    frel_2_store[i, ] <span class="ot">&lt;-</span> sim<span class="sc">$</span>frel_2</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    frel_4_store[i, ] <span class="ot">&lt;-</span> sim<span class="sc">$</span>frel_4</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Retorna frequencias relativas de pousos forçados como lista</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">frel_2 =</span> frel_2_store,</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">frel_4 =</span> frel_4_store</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><em>Exemplo com p = 0.5:</em></p>
<p>Podemos agora executar a simulação para um valor específico de <code>p</code>. Por exemplo, definindo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Parâmetros</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>nRep   <span class="ot">&lt;-</span> <span class="dv">100</span>    <span class="co"># número de replicações</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>n_voos <span class="ot">&lt;-</span> <span class="dv">2000</span>   <span class="co"># número de voos por replicação</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>p      <span class="ot">&lt;-</span> <span class="fl">0.5</span>    <span class="co"># probabilidade de cada turbina funcionar</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Execução da simulação</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>sim_data <span class="ot">&lt;-</span> <span class="fu">simula_MC</span>(p, nRep, n_voos)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Frequências relativas de pousos forçados</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>frel_2 <span class="ot">&lt;-</span> sim_data<span class="sc">$</span>frel_2  <span class="co"># avião de 2 turbinas</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>frel_4 <span class="ot">&lt;-</span> sim_data<span class="sc">$</span>frel_4  <span class="co"># avião de 4 turbinas</span></span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Nessa simulação, <code>frel_2[i, ]</code> e <code>frel_4[i, ]</code> mostram, para a i-ésima replicação, como a frequência relativa de pousos forçados evolui ao longo dos voos simulados. Para analisar o resultado, podemos plotar (1) os “caminhos aleatórios” (<em>sample paths</em>) de cada replicação, comparando-as aos valores teóricos, e (2) histogramas das frequências relativas finais (no último voo) de cada replicação. Eis um exemplo de como gerar esses gráficos:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Gráfico 1: caminhos aleatórios</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cn">NULL</span>, <span class="at">type =</span> <span class="st">"n"</span>,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">1</span>, n_voos), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Número de voos simulados"</span>,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Frequência relativa de pousos forçados"</span>,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="fu">paste</span>(<span class="st">"Caminhos Aleatórios para p ="</span>, p))</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Desenha as linhas para o avião de 2 turbinas (azul)</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="fu">seq_len</span>(nRep)) {</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="dv">1</span><span class="sc">:</span>n_voos, frel_2[i, ], <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lwd =</span> <span class="fl">0.5</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Desenha as linhas para o avião de 4 turbinas (vermelho)</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="fu">seq_len</span>(nRep)) {</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="dv">1</span><span class="sc">:</span>n_voos, frel_4[i, ], <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="fl">0.5</span>)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Probabilidades teóricas (linhas horizontais)</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>p2_teo <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">+</span> p<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>p</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>p4_teo <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> <span class="dv">3</span><span class="sc">*</span>p<span class="sc">^</span><span class="dv">4</span> <span class="sc">+</span> <span class="dv">8</span><span class="sc">*</span>p<span class="sc">^</span><span class="dv">3</span> <span class="sc">-</span> <span class="dv">6</span><span class="sc">*</span>p<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> p2_teo, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lty =</span> <span class="st">"dashed"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> p4_teo, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lty =</span> <span class="st">"dashed"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topright"</span>,</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">"2 turbinas"</span>, <span class="st">"4 turbinas"</span>, <span class="st">"Teórico 2T"</span>, <span class="st">"Teórico 4T"</span>),</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"red"</span>, <span class="st">"blue"</span>, <span class="st">"red"</span>),</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>       <span class="at">lty =</span> <span class="fu">c</span>(<span class="st">"solid"</span>,<span class="st">"solid"</span>,<span class="st">"dashed"</span>,<span class="st">"dashed"</span>),</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>       <span class="at">bty =</span> <span class="st">"n"</span>)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="MB751_AULA02_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>O gráfico acima mostra os 100 caminhos aleatórios que foram percorridos para os 2000 voos simulados. Em azul temos a evolução dos valores calculados para as frequências relativas de pousos forçados para o avião de 2 turbinas e em vermelho, para o avião de 4 turbinas. Como era de se esperar, a frequência de pousos forcados é maior para o avião de 4 turbinas. As retas horizontais tracejadas correspondem aos valores teóricos.</p>
<p>Outra forma interessante de avaliar a convergência dos valores estimados é através da análise da distribuição dos valores finais das frequências relativas de pousos forçados (após o último voo, <code>n_voos</code>), como mostra o gráfico abaixo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Gráfico 2: histogramas das frequências relativas finais</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(frel_2[, n_voos],</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="at">col =</span> <span class="fu">rgb</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.5</span>),</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="fu">paste</span>(<span class="st">"Distribuição de freqs. relativas finais (p ="</span>, p, <span class="st">")"</span>),</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Frequência relativa de pousos forçados"</span>,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">border =</span> <span class="st">"white"</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(frel_4[, n_voos],</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="at">col =</span> <span class="fu">rgb</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.5</span>),</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>     <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">border =</span> <span class="st">"white"</span>)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> p2_teo, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="st">"dashed"</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> p4_teo, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="st">"dashed"</span>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topright"</span>,</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">"2 turbinas"</span>, <span class="st">"4 turbinas"</span>,</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>                  <span class="st">"Teórico 2T"</span>, <span class="st">"Teórico 4T"</span>),</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"red"</span>,<span class="st">"blue"</span>,<span class="st">"red"</span>),</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">15</span>, <span class="at">lty =</span> <span class="fu">c</span>(<span class="cn">NA</span>,<span class="cn">NA</span>,<span class="dv">2</span>,<span class="dv">2</span>),</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>       <span class="at">bty =</span> <span class="st">"n"</span>)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="MB751_AULA02_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>As linhas tracejadas em azul e vermelho representam as probabilidades teóricas. Se as turbinas são mesmo independentes e o número de replicações é suficientemente grande, os valores empíricos tenderão a se aproximar das previsões analíticas.</p>
<p>O mesmo procedimento pode ser repetido para outros valores de <span class="math inline">\(p\)</span>. Em particular, verificar <span class="math inline">\(p = 2/3\)</span>, <span class="math inline">\(p = 0.8\)</span> ou <span class="math inline">\(p = 0.9\)</span> confirma que a aeronave de 4 turbinas gradualmente se torna mais confiável à medida que <span class="math inline">\(p\)</span> ultrapassa <span class="math inline">\(2/3\)</span>, em acordo com a análise teórica.</p>
</div>
</div>
</div>
</div>
<p>Quando consideramos eventos simples como o do exemplo, em que consideramos apenas dois modelos de aeronaves, com poucas turbinas, é relativamente fácil comparar resultados analíticos e simulações de Monte Carlo. Assim, obtemos <em>insights</em> sobre quais valores de <code>p</code> (probabilidade de cada turbina funcionar) tornam um determinado projeto mais seguro que outro. Em contextos mais complexos, que incluem falhas correlacionadas ou numerosos componentes em rede, por exemplo, o mesmo tipo de análise pode ser adaptado, embora o modelo fique mais elaborado.</p>
<p>No exemplo, vimos como a informação de que um componente falhou (ou funcionou) afeta a probabilidade de falha do sistema completo. Quando componentes são realmente independentes, a probabilidade de falha simultânea é apenas o produto das probabilidades individuais. Em aplicações reais, porém, pode haver fatores de dependência (por exemplo, sobrecarga de uma turbina levando à falha de outras), o que exigiria modelos específicos para capturar essas interações.</p>
</section>
</section>
<section id="teoremas-fundamentais-da-probabilidade" class="level2">
<h2 class="anchored" data-anchor-id="teoremas-fundamentais-da-probabilidade">Teoremas Fundamentais da Probabilidade</h2>
<p>Combinando a definição de probabilidade condicional, o conceito de independência e os resultados a seguir, podemos resolver problemas de probabilidade consideravelmente complexos. Esses <strong>teoremas fundamentais da probabilidade</strong> se apoiam na construção de uma partição do espaço amostral adequada, cuja configuração simplifica o cálculo das probabilidades envolvidas.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Partição do Espaço Amostral
</div>
</div>
<div class="callout-body-container callout-body">
<p><br>
Uma partição de <span class="math inline">\({\Omega}\)</span> é uma coleção de eventos <span class="math inline">\({A_1, A_2, \ldots}\)</span> que satisfaz:</p>
<ol type="i">
<li><span class="math inline">\({P[A_i] &gt; 0, \quad \forall i}\)</span></li>
<li><span class="math inline">\({A_1, A_2, \ldots}\)</span> são mutuamente exclusivos (<span class="math inline">\({A_i \cap A_j = \varnothing, \; \forall i\neq j}\)</span>)</li>
<li><span class="math inline">\({A_1, A_2, \ldots}\)</span> são coletivamente exaustivos (<span class="math inline">\({\cup_{i} A_i = \Omega}\)</span>)</li>
</ol>
</div>
</div>
<p>Em outras palavras: (i) cada um dos eventos que compõe a partição do espaço amostral deve ter probabilidade não nula; (ii) nenhum par de eventos pode ocorrer simultaneamente; e, finalmente, (iii) a união de todos eles cobre completamente o espaço amostral.</p>
<p>A figura abaixo ilustra exemplos de partições possíveis. A primeira consiste em uma partição do espaço amostral em apenas dois eventos (neste caso, a partição é formada por um evento e o seu complementar); no segundo exemplo, temos uma partição finita e no terceiro, temos uma partição infinita.</p>
<div id="fig-particao" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-particao-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/particao.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-particao-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;2: Exemplos de partições do espaço amostral.
</figcaption>
</figure>
</div>
<p>O <strong>Teorema da Probabilidade Total (TPT)</strong> permite simplificar o cálculo de probabilidades, “quebrando” eventos complexos em pedaços mais manejáveis, aproveitando uma partição bem escolhida do espaço amostral. Essa ideia é ilustrada pela figura a seguir, onde a probabilidade associada ao evento <span class="math inline">\(B\)</span> (em destaque) é de difícil avaliação direta, mas torna-se mais fácil ao particionar <span class="math inline">\(\Omega\)</span> nos eventos <span class="math inline">\(A_1, A_2, \ldots, A_5\)</span>.</p>
<div id="fig-TPT" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-TPT-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/TPT.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-TPT-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3: Ilustração do Teorema da Probabilidade Total.
</figcaption>
</figure>
</div>
<p>Suponha que desejamos calcular a probabilidade de um evento <span class="math inline">\(B\)</span>, mas que seja complexo fazê-lo a partir da análise direta do espaço amostral (representado pela caixa retangular). O teorema da probabilidade total permite calcular a probabilidade desejada através da escolha de uma partição do espaço amostral, formada pela coleção de eventos <span class="math inline">\(A_1, A_2, A_3, \ldots, A_k\)</span>, cujas probabilidades podem ser facilmente determinadas.</p>
<p>Observe que podemos representar o evento <span class="math inline">\(B\)</span> em termos dessa partição:</p>
<p><span class="math display">\[
\begin{align*}
B = B\cap \Omega = B \cap (\cup_i A_i)
&amp;= \cup_i (A_iB)
\end{align*}
\]</span></p>
<p>Como os eventos <span class="math inline">\(A_i\)</span> que formam a partição são mutuamente exclusivos, os termos <span class="math inline">\(A_iB\)</span> também o serão. Logo, a probabilidade do evento <span class="math inline">\(B\)</span> pode ser calculada da seguinte maneira:</p>
<p><span class="math display">\[P[B] = P[\cup_{i=1}^k (A_iB)]= \sum_{i=1}^{k} P[A_iB]\]</span></p>
<p>Usando a regra do produto, chegamos à forma clássica do teorema da probabilidade total, enunciada a seguir.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Teorema da Probabilidade Total: dividir para conquistar
</div>
</div>
<div class="callout-body-container callout-body">
<p><br>
Se <span class="math inline">\(A_1, A_2, \ldots, A_k\)</span> formam uma partição de <span class="math inline">\(\Omega\)</span> e <span class="math inline">\(P[A_i] &gt;0\)</span>, então:</p>
<p><span class="math display">\[P[B] = \sum_{i=1}^{k} P [B\cap A_i] = \sum_{i=1}^{k} P[B|A_i] P[A_i]\]</span></p>
</div>
</div>
<p>A ideia central do teorema da probabilidade total é que podemos escolher uma partição do espaço amostral que torne mais fácil o cálculo das das quantidades <span class="math inline">\(P[B | A_i]\)</span> e <span class="math inline">\(P[A_i]\)</span>, a fim de simplificar a determinação da probabilidade do evento <span class="math inline">\(B\)</span>.</p>
<p>O teorema de Bayes é outra ferramenta fundamental, frequentemente descrita como um método de “atualizar crenças” diante de novas evidências. Ele se baseia na mesma ideia de construir uma partição do espaço amostral conveniente, combinada à definição de probabilidade condicional.</p>
<div id="fig-TBayes" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-TBayes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/TBayes.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-TBayes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;4: Ilustração do Teorema de Bayes.
</figcaption>
</figure>
</div>
<p>Suponha que um <strong>efeito</strong> <span class="math inline">\(B\)</span> tenha sido observado (por exemplo, um teste positivo ou a ocorrência de uma certa anomalia) e que suspeitamos de várias <strong>causas</strong> possíveis <span class="math inline">\(A_1, A_2, \ldots, A_k\)</span> que, por sua vez, formam uma partição do espaço amostral. Cada causa <span class="math inline">\(A_i\)</span> tem probabilidade <em>a priori</em> <span class="math inline">\(P[A_i]\)</span>. Queremos, então, descobrir a probabilidade de cada causa, dado que <span class="math inline">\(B\)</span> ocorreu.</p>
<p>A observação do efeito <span class="math inline">\(B\)</span> consiste em uma informação adicional. Assim, é necessário atualizar a crença a respeito das possíveis causas à luz dessa nova evidência. Isto se dá através do cálculo das probabilidades <em>a posteriori</em> (que nada mais são do que probabilidades condicionais) de cada uma das possíveis causas, dado que o efeito <span class="math inline">\(B\)</span> foi observado, <span class="math inline">\(P[A_i | B]\)</span>, conforme enunciado no quadro abaixo:</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Teorema de Bayes: aprendendo pela experiência
</div>
</div>
<div class="callout-body-container callout-body">
<p><br>
Se <span class="math inline">\(A_1, A_2, \ldots, A_k\)</span> formam uma partição de <span class="math inline">\(\Omega\)</span> e <span class="math inline">\(P[B] &gt;0\)</span>, então: <span class="math display">\[ P[A_j|B] = \frac{P[A_jB]}{P[B]} =\frac{P[B|A_j]P[A_j]}{\sum_{i=1}^{k} P[B|A_i] P[A_i]},  \qquad \forall \; j= 1, \ldots, k\]</span></p>
<p>onde:</p>
<p><span class="math inline">\(P[A_i]\)</span> é a probabilidade <em>a priori</em> de cada causa;<br>
<span class="math inline">\(P[B|A_i]\)</span> é a probabilidade de observar o efeito <span class="math inline">\(B\)</span> quando a causa <span class="math inline">\({A_i}\)</span> está presente;<br>
<span class="math inline">\(P[A_j|B]\)</span> é a probabilidade <em>a posteriori</em> de que a causa <span class="math inline">\({A_j}\)</span> esteja presente, dado que o efeito <span class="math inline">\({B}\)</span> foi observado.</p>
</div>
</div>
<p>No teorema de Bayes, a probabilidade conjunta do numerador <span class="math inline">\(P[A_jB]\)</span> foi reescrita com o auxílio da regra do produto; no denominador, a probabilidade de <span class="math inline">\(B\)</span> foi reescrita na forma do teorema da probabilidade total, ou seja, em termos da partição do espaço amostral dada em função das possíveis causas.</p>
<p>O Teorema de Bayes encapsula o processo de <strong>atualização</strong> das probabilidades: começamos com crenças iniciais, representadas pelas probabilidades <em>a priori</em> <span class="math inline">\(P[A_i]\)</span>, obtemos uma evidência nova (ocorrência de <span class="math inline">\(B\)</span>) e, então, recalculamos as probabilidades à luz dessa evidência, resultando em crenças atualizadas, representadas pelas probabilidades <em>a posteriori</em> <span class="math inline">\(P[A_j |B]\)</span>.</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 5 (Diagnóstico em Raio-X)</strong></span> <br>
Suponha que o exame de raio-X de um paciente tenha revelado uma mancha. Esta evidência é o efeito que foi observado, que corresponde ao evento <span class="math inline">\(B\)</span>.</p>
<p>Há diversas causas possíveis para a presença da mancha no raio-X, mas precisamos escolher aquelas que sejam de nosso interesse. Queremos determinar as chances de que essa mancha seja explicada por uma das potenciais causas apresentadas abaixo, que formam uma partição do espaço amostral (assumimos que as causas não possam ocorrer simultaneamente):</p>
<ul>
<li>Causa A1: o paciente tem COVID-19<br>
</li>
<li>Causa A2: o paciente tem tuberculose<br>
</li>
<li>Causa A3: outra causa (qualquer motivo não listado antes)</li>
</ul>
<p>Note que, ao considerar esta partição do espaço amostral, estamos preocupados em identificar se a mancha foi provocada por COVID-19 ou tuberculose; não estamos preocupados com as outras inúmeras possíveis explicações para a ocorrência de uma mancha num exame de raio-x. Não nos interessa se o paciente está com pneumonia, se o paciente aspirou algum corpo estranho ou se o aparelho de raio-x está com defeito. Por esse motivo, a partição foi escolhida desta maneira.</p>
<p>Considerando a história médica do paciente e, com base apenas no conhecimento da incidência dessas doenças na população, sabe-se que:</p>
<p><span class="math display">\[{P[A1] = 0,02;  \quad  P[A2] = 0,01;  \quad  P[A3] = 0,97},\]</span> onde cada valor representa uma probabilidade <em>a priori</em> de o paciente apresentar COVID-19, tuberculose ou alguma outra condição.</p>
<p>Além disso, sabemos que avaliação do exame de raio-X nem sempre é perfeita e, por este motivo, nem sempre é possível chegar à conclusão correta. Tem-se as seguintes probabilidades de observar uma mancha no exame, dado que está presente cada uma das causas consideradas:</p>
<p><span class="math display">\[{P[B|A1] = 0,90;  \quad  P[B|A2] = 0,95;  \quad  P[B|A3] = 0,07}\]</span></p>
<p>Queremos calcular: <strong>qual a probabilidade de o paciente ter COVID-19, dado qu a mancha foi observada?</strong></p>
<p>Formalmente, desejamos calcular a probabilidade <em>a posteriori</em> da causa <span class="math inline">\(A1\)</span>, dado que observamos uma mancha no exame de raio-X (evento <span class="math inline">\(B\)</span>). Essa é a probabilidade <span class="math inline">\(P[A1|B]\)</span> e pode ser calculada utilizando o teorema de Bayes.</p>
<p>O primeiro passo consiste em representar no espaço amostral a partição considerada, composta pelos eventos <span class="math inline">\(A1\)</span>, <span class="math inline">\(A2\)</span> e <span class="math inline">\(A3\)</span> e também o evento <span class="math inline">\(B\)</span>. As interseções entre os eventos que formam a partição do espaço amostral e o evento <span class="math inline">\(B\)</span> formam uma partição de <span class="math inline">\(B\)</span>. Para, assim, podermos reescrever o evento <span class="math inline">\(B\)</span> em termos dessa partição.</p>
<p>Espaço amostral: <span class="math inline">\(\Omega\)</span></p>
<p><img src="img/raio-x-venn.png" class="img-fluid"> Temos que:</p>
<ul>
<li><span class="math inline">\(A1\)</span>, <span class="math inline">\(A2\)</span>, <span class="math inline">\(A3\)</span> formam uma partição de <span class="math inline">\({\Omega}\)</span><br>
</li>
<li><span class="math inline">\(A1B\)</span>, <span class="math inline">\(A2B\)</span>, <span class="math inline">\(A3B\)</span> formam uma partição de <span class="math inline">\(B\)</span>: <span class="math inline">\(A1B \cup A2B \cup A3B = B\)</span></li>
</ul>
<p>Usando a definição de probabilidade condicional, a probabilidade de que o paciente tenha COVID-19, dado que a mancha foi observada é dada pela razão da probabilidade da ocorrência simultânea de COVID-19 e de uma mancha no raio-X e a probabilidade de haver uma mancha no exame de raio-X.</p>
<p><span class="math display">\[P[A_1 | B] = \frac{P[A_1B]}{P[B]}\]</span></p>
<p>Com o auxílio da regra do produto, o numerador é reescrito em termos da probabilidade condicional de observar uma mancha no exame de raio-X, quando o paciente está acometido de COVID-19 e da probabilidade de o paciente ter COVID-19, enquanto o denominador pode ser calculado através do teorema da probabilidade total, com base na partição do espaço amostral considerada. Assim:</p>
<p><span class="math display">\[\begin{align*}
P[B]
&amp;= P[A1B ∪ A2B ∪ A3B]\\
&amp;= P[A1B] + P[A2B] + P[A3B]\\
&amp;= P[B|A1] P[A1] + P[B|A2] P[A2] + P[B|A3] P[A3]\\
&amp;= 0,9 \times 0,02 + 0,95 \times 0,01 + 0,07 \times 0,97 \approx 0,0954
\end{align*}\]</span></p>
<p>e</p>
<p><span class="math display">\[P[A1|B] = \frac{P[B|A1] P[A1]}{P[B]} = \frac{0,90 \times 0,02}{0,0954} \approx 0,1887.\]</span></p>
<p>Note que, <em>antes do exame de raio-X</em>, a chance de o paciente ter COVID-19 era de 2%. Ao observar a mancha, essa chance sobe para aproximadamente 19%. O teorema de Bayes capta exatamente essa ideia de “aprender com a evidência”: a probabilidade <em>a posteriori</em> de cada causa (COVID, tuberculose ou outra) sofre uma atualização baseada em quão provável seria a ocorrência da mancha sob cada hipótese.</p>
<p>Por fim, cálculos análogos para as outras causas, mostram que <span class="math inline">\(P[A2|B] \approx 0,0996\)</span> (cerca de 10%) e <span class="math inline">\(P[A3|B] \approx 0,7117\)</span> (aproximadamente 71%). Caso o médico deseje ter mais certeza da causa que provocou a mancha no exame, a fim de prescrever o tratamento adequado, deve buscar novas evidências, por meio de exames adicionais. E, assim, à luz dos novos resultados, poderá recalcular via Teorema de Bayes as probabilidades de cada causa.</p>
</div>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="variáveis-aleatórias-e-distribuições" class="level1">
<h1>Variáveis Aleatórias e Distribuições</h1>
<p>A partir deste ponto, nosso estudo de teoria de probabilidades torna-se mais rico com a introdução do conceito de variáveis aleatórias, que nos permitirá analisar situações de incerteza mais complexas do que as discutidas até então.</p>
<p>Antes de avançar, vale relembrar alguns fundamentos. Para um experimento aleatório <span class="math inline">\(E\)</span>, determinamos o espaço amostral <span class="math inline">\(\Omega\)</span> (conjunto de todos os resultados possíveis) e definimos uma função de probabilidade <span class="math inline">\(P\)</span>, que expressa uma medida da propensão de ocorrência de cada evento em <span class="math inline">\(\Omega\)</span>. Essa abordagem fornece uma <strong>descrição probabilística completa</strong> da situação de incerteza representada pelo experimento em questão.</p>
<p>Por exemplo, considere o experimento de lançar uma moeda honesta e observar o resultado obtido. A descrição completa dessa situação é dada pelo espaço amostral <span class="math inline">\(\Omega = \{cara, coroa\}\)</span> e pela lei de probabilidade que atribui chances iguais para os dois resultados: <span class="math inline">\(P[cara] = 1/2\)</span> e <span class="math inline">\(P[coroa] = 1/2\)</span>.</p>
<p>Imagine agora uma situação mais complexa: uma pesquisa de opinião para avaliar o apoio de um grupo a uma determinada causa. Suponha que uma amostra de 50 pessoas desse grupo tenha sido selecionada para ser entrevistada, de forma que cada um desses indivíduos deve manifestar sua opinião, respondendo “sou favorável” ou “não sou favorável” à causa em análise. Para representar cada resposta, podemos associar o valor “1” a uma resposta positiva e “0” a uma resposta negativa. Assim, o espaço amostral é constituído por todas as possíveis 50-uplas de 0s e 1s que representam todas as combinações de respostas que as 50 pessoas entrevistadas podem produzir:</p>
<p><span class="math display">\[
\Omega = \{ (0, 0, \ldots, 0), (1, 0, \ldots, 0), \ldots, (0, 0, \ldots, 1), (1, 1, \ldots, 0), \ldots, (1, 1, \ldots, 1)\}
\]</span></p>
<p>Cada elemento em <span class="math inline">\(\Omega\)</span> (cada sequência de 50 respostas) terá uma chance de ocorrer, atribuída conforme a lei probabilidade. Desta forma, temos uma descrição completa da situação que permite calcular qualquer probabilidade de interesse. A dificuldade surge, porém, quando percebemos que este espaço amostral tem <span class="math inline">\(2^{50}\)</span> elementos; definir um valor de probabilidade para cada um deles seria inviável na prática.</p>
<p>Assim, precisamos considerar a questão que de fato importa: Será que é realmente imprescindível descrever <em>completamente</em> esse experimento aleatório, ou podemos analisar apenas os <em>aspectos</em> de interesse? Se quisermos saber, por exemplo, <em>“Qual a probabilidade de que no mínimo 26 das 50 pessoas apoiem a causa?”</em>, talvez não seja necessário analisar cada uma das sequências de respostas possíveis. Em vez disso, podemos considerar apenas o número total de respostas favoráveis.</p>
<p>Para isso, podemos definir uma variável que captura a essência do problema:</p>
<p><span class="math display">\[
X = \textsf{número de pessoas que apoiam a causa, dentre as 50 entrevistadas}
\]</span></p>
<p>Ao fazer isto, o experimento passa, então, a ser: entrevistar 50 pessoas e registrar unicamente o número de respostas favoráveis. O espaço amostral <span class="math inline">\(\Omega^\prime\)</span> deste “novo” experimento resume-se a:</p>
<p><span class="math display">\[
\Omega^\prime = \{0, 1, 2, \ldots, 50\},
\]</span></p>
<p>um conjunto de apenas 51 elementos, bem mais simples de lidar do que as <span class="math inline">\(2^50\)</span> possibilidades originais. Podemos atribuir probabilidades a cada valor que <span class="math inline">\(X\)</span> assume e, assim, responder a perguntas sobre o apoio à causa de interesse, sem a necessidade de examinar cada configuração individual de respostas.</p>
<p>Concluímos, assim, que a escolha do espaço amostral associado a uma situação de incerteza <strong>não é única</strong>, mas depende diretamente de quais informações são relevantes para analisar o problema. Ao definir a quantidade <span class="math inline">\(X\)</span>, chamada <strong>variável aleatória</strong>, estabelecemos um mapeamento do espaço amostral original para um novo espaço mais simplificado, que retém apenas os aspectos relevantes do experimento.</p>
<section id="variáveis-aleatórias" class="level2">
<h2 class="anchored" data-anchor-id="variáveis-aleatórias">Variáveis Aleatórias</h2>
<p>Uma variável aleatória (v.a.) é uma <strong>função</strong> que associa cada elemento do espaço amostral <span class="math inline">\(\Omega\)</span> (descrito em termos de eventos) a um número real. Em outras palavras, embora seja chamda “variável”, ela funciona como um mapeamento que associa a cada elemento <span class="math inline">\(s \in \Omega\)</span> um número real <span class="math inline">\(x = X(s)\)</span>. Dessa forma, uma variável aleatória é uma <strong>representação numérica</strong> dos possíveis resultados de um experimento aleatório.</p>
<div id="fig-va-definição" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-va-definição-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/va.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-va-definição-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;5: Variável aleatória: função que associa um valor numérico a cada resultado possível do experimento aleatório.
</figcaption>
</figure>
</div>
<p>Costuma-se adotar a seguinte notação:</p>
<ul>
<li><span class="math inline">\(X(\cdot)\)</span> (maiúsculo) para a <strong>variável aleatória</strong> (isto é, a função),<br>
</li>
<li><span class="math inline">\(x\)</span> (minúsculo) para o <strong>valor</strong> que esta variável pode assumir (a realização observada do experimento).</li>
</ul>
<p>Como <span class="math inline">\(X\)</span> é definida no espaço amostral, a probabilidade de ocorrer um evento <span class="math inline">\(s\)</span> em <span class="math inline">\(\Omega\)</span> equivale à probabilidade de <span class="math inline">\(X\)</span> assumir determinado valor <span class="math inline">\(x\)</span>, ou seja, <span class="math inline">\(X(s) = x\)</span>. Representado essa probabilidade por <span class="math inline">\(P[X(s) = x]\)</span>, denotamos por <span class="math inline">\(p(x)\)</span> a função que associa a cada valor de <span class="math inline">\(x\)</span> a probabilidade correspondente. Naturalmente, <span class="math inline">\(p(x)\)</span> deve satisfazer os axiomas de Kolmogorov para constituir uma função probabilidade válida.</p>
<section id="tipos-de-variáveis-aleatórias" class="level3">
<h3 class="anchored" data-anchor-id="tipos-de-variáveis-aleatórias">Tipos de Variáveis Aleatórias</h3>
<p>Neste curso, trataremos principalmente de variáveis aleatórias <strong>quantitativas</strong>, que podem ser classificadas como sendo <strong>discretas</strong> ou <strong>contínuas</strong>. Temos uma v.a. discreta quando os valores possíveis formam um conjunto finito ou enumerável (podem ser listados). Já em uma v.a. contínua, os valores formam um conjunto infinito não-enumerável, como um intervalo real.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Variáveis Aleatórias Discretas</strong></p>
<p>Uma v.a. <span class="math inline">\(X\)</span> é chamada <strong>discreta</strong> quando está associada a um espaço amostral enumerável, podendo ser finito ou infinito. Isto quer dizer que <span class="math inline">\(X\)</span> pode assumir um número <strong>finito</strong> ou <strong>infinito e enumerável</strong> de valores reais distintos <span class="math inline">\(x_1, x_2, \ldots, x_n, \ldots\)</span>.</p>
<p>Este tipo de situação costuma ocorrer em experimentos aleatórios que envolvem <strong>contagem</strong>, como o número de caras em 10 lançamentos de uma moeda honesta, o número de tentativas até acertar o alvo, o número de pessoas que chegaram a uma agência bancária em determinado intervalo de tempo.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Variáveis Aleatórias Contínuas</strong></p>
<p>Uma v.a. <span class="math inline">\(X\)</span> é chamada <strong>contínua</strong> quando está associada a um espaço amostral <strong>não-enumerável</strong>, pois pode assumir uma quantidade infinita de valores possíveis em um intervalo ou união de intervalos reais. A probabilidade de ocorrer exatamente um valor em particular é nula.</p>
<p>Este é o caso quando estamos diante de uma situação em que o resultado do experimento aleatório é uma <strong>medição</strong> como o tempo de duração de um atendimento médico, o comprimento de uma peça produzido por um determinado processo industrial, o tempo de vida de um equipamento eletrônico e, assim por diante.</p>
</div>
</div>
</div>
<p>Vejamos alguns exemplos de variáveis aleatórias discretas e contínuas:</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-va-discreta-defeituosos-vs-nao-defeituosos" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 6 (Componentes Eletrônicos: Defeituosos ou Não)</strong></span> <br></p>
<p>Considere a situação em que componentes eletrônicos fabricados em uma linha de produção são submetidos a inspeção. Cada componente é classificado “defeituoso” (<span class="math inline">\(D\)</span>) ou “não-defeituoso” (<span class="math inline">\(N\)</span>) e a probabilidade de defeito vale 0,1.</p>
<p>O espaço amostral associado a esse experimento <span class="math inline">\({\Omega = \{D, N\}}\)</span> tem apenas dois resultados possíveis e, portanto, constitui um conjunto finito e enumerável.</p>
<p>Podemos definir, abaixo, a variável aleatória <span class="math inline">\(X\)</span> que mapeia cada elemento do espaço amostral a um número real:</p>
<p><span class="math display">\[
{X = \left\{
      \begin{array}{ll}
      0, &amp; \textsf{ se o componente é defeituoso}\\
      1, &amp; \textsf{ se o componente é não-defeituoso}
      \end{array} \right.}
\]</span></p>
<p>Como <span class="math inline">\(\Omega\)</span> é finito, temos uma v.a. discreta que representa numericamente o estado de cada componente. Podemos representar as probabilidades dos eventos do espaço amostral em termos da variável aleatória definida:</p>
<p><span class="math inline">\(P[D] = P[X = 0] = 0,1\)</span> e<br>
<span class="math inline">\(P[N] = P[X = 1] = 0,9\)</span>.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-va-discreta-primeiro-defeituoso" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 7 (Número de Itens até o Primeiro Defeituoso)</strong></span> <br></p>
<p>Em outra variação do mesmo contexto, suponha agora que estejamos interessados no número de componentes produzidos até observar o primeiro defeito. Podemos ter “D” (o primeiro item já é defeituoso), “ND” (o primeiro não-defeituoso, segundo defeituoso), “NND” (dois não-defeituosos antes do primeiro defeito) e, assim por diante. O espaço amostral <span class="math inline">\({\Omega = \{D, ND, NND, NNND, \ldots\}}\)</span> é infinito, mas enumerável. Definindo</p>
<p><span class="math inline">\(X\)</span> = o número de itens produzidos até o primeiro defeituoso,</p>
<p>temos também uma v.a. discreta, pois cada possibilidade corresponde a um número inteiro de itens.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-va-continua-email" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 8 (Tempo de Chegada de Emails)</strong></span> <br></p>
<p>Seja <span class="math inline">\(X\)</span> o tempo (em segundos) até que duas mensagens cheguem a uma caixa de email. Assumindo um relógio com precisão ilimitada, qualquer valor <span class="math inline">\(x \geq 0\)</span> é possível. Portanto, <span class="math inline">\(X\)</span> é definida no espaço amostral <span class="math inline">\({\Omega = \{ x \in \Re: x \geq0\}}\)</span>, infinito e não enumerável, e constitui uma v.a. contínua.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-va-continua-suco" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 9 (Volume de Suco Envasado)</strong></span> <br></p>
<p>Suponha que uma máquina de envase de suco de laranja preencha frascos com volumes entre 900mL e 1100mL (isto é, entre 0,9L e 1,1L). Seja <span class="math inline">\(X\)</span> a variável aleatória que registra o volume efetivamente envasado em cada recipiente. Se considerarmos que o mecanismo de medição da máquina tem precisão praticamente ilimitada (podendo distinguir frações mínimas de mililitros), qualquer valor dentro desse intervalo é possível. Dessa forma, o espaço amostral é um conjunto não enumerável:</p>
<p><span class="math display">\[{\Omega = \{ x \in \Re: 900 &lt; x &lt; 1100 \}}.\]</span> Como não é viável listar cada valor real nesse intervalo, dizemos que <span class="math inline">\(X\)</span> é uma variável aleatória contínua. Nesse cenário, a probabilidade de <span class="math inline">\(X\)</span> ser exatamente 956,78 mL é nula, porém podemos calcular a probabilidade de <span class="math inline">\(X\)</span> se encontrar em um intervalo específico (por exemplo, entre 950 mL e 960 mL), como veremos adiante.</p>
</div>
</div>
</div>
</div>
<p>Observamos que variáveis aleatórias permitem <strong>transformar</strong> um espaço amostral complexo em outro mais conveniente para os propósitos da investigação de interesse. Em outras palavras, elas reduzem a complexidade do experimento aleatório original, fornecendo uma descrição matemática mais sucinta, focada nos aspectos relevantes desse experimento.</p>
<p>Contudo, ao criar esse “artifício” matemático para simplificar os cálculos de probabilidade, há um preço a ser pago: passamos a precisar de uma nova função, a <strong>distribuição de probabilidade</strong> de <span class="math inline">\(X\)</span>,que resume todas as informações necessárias para descrever a incerteza em a respeito da variável aleatória. Veremos agora como isso é formalizado para v.a.’s discretas e v.a.’s contínuas.</p>
</section>
</section>
<section id="distribuições-de-probabilidade" class="level2">
<h2 class="anchored" data-anchor-id="distribuições-de-probabilidade">Distribuições de Probabilidade</h2>
<section id="função-distribuição-de-probabilidade-fdp-caso-discreto" class="level3">
<h3 class="anchored" data-anchor-id="função-distribuição-de-probabilidade-fdp-caso-discreto">Função Distribuição de Probabilidade (FDP): caso discreto</h3>
<p>Uma vez definida a variável aleatória <span class="math inline">\(X\)</span>, o espaço amostral <span class="math inline">\(\Omega\)</span> deixa de ser essencial na descrição do seu comportamento probabilístico pois, para isso basta identificar todos os valores <span class="math inline">\(x_1, x_2, \ldots\)</span>, que <span class="math inline">\(X\)</span> pode assumir e os respectivos valores de probabilidade. Essas informações são reunidas na <strong>função distribuição de probabilidade</strong> (FDP) de <span class="math inline">\(X\)</span>:</p>
<p><span class="math display">\[\begin{align*}
  f_X(\cdot): \Re \rightarrow [0,1] \quad \textsf{tal que} \quad {f_X(x)} =
  \left\{
  \begin{array}{ll}
    P[X=x_j], &amp; \text{ se } x = x_j, \\
    0, &amp; \text{ se } x \neq x_j
  \end{array}
  \right.
  \quad \textsf{para} \quad j = 1, 2, \ldots
\end{align*}\]</span></p>
<p>Observe que, embora o <strong>domínio</strong> de <span class="math inline">\(f_X\)</span> seja o conjunto dos número reais (porque o contradomínio de <span class="math inline">\(X\)</span> é <span class="math inline">\(\Re\)</span>, a <strong>imagem</strong> de <span class="math inline">\(f_X\)</span> está no intervalo <span class="math inline">\([0,1]\)</span>. No caso discreto, cada valor <span class="math inline">\(x_j\)</span> que a v.a. <span class="math inline">\(X\)</span> pode assumir recebe um valor de probabilidade positivo, ao passo que valores fora desse conjunto têm probabilidade zero – ou seja, a probabilidade de um resultado impossível é 0.</p>
<p>A FDP descreve como a probabilidade total (1) se distribui entre os valores possíveis de <span class="math inline">\(X\)</span>. Para variáveis aleatórias discretas, tais pontos são comumente chamados de <strong>pontos de massa</strong>, razão pela qual também se usa o termo <strong>função massa de probabilidade</strong> para referir-se à FDP.</p>
<p>Para que a FDP seja função probabilidade, deve satisfazer os axiomas de Kolmogorov:</p>
<ol type="1">
<li><span class="math inline">\({f_X(x_j) \geq 0}\)</span> para <span class="math inline">\({j = 1, 2, \ldots}\)</span></li>
<li><span class="math inline">\({f_X(x_j) = 0}\)</span> sempre que <span class="math inline">\(x \neq x_j\)</span></li>
<li><span class="math inline">\({\sum_j f_X(x_j) = 1}\)</span></li>
</ol>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-computadores-FDP" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 10 (Computadores Defeituosos)</strong></span> <br></p>
<p>Um lote de 8 computadores em uma loja contém 3 defeituosos. Um cliente seleciona 2 destes computadores ao acaso para comprar. Queremos determinar a distribuição de probabilidade para o número de computadores defeituosos comprados.</p>
<p><strong>Solução:</strong></p>
<p>Em primeiro lugar, precisamos identificar qual é a v.a. de interesse e que valores ela pode assumir. Às vezes, essa tarefa se torna mais fácil identificando o espaço amostral associado ao experimento aleatório em questão. Note que a pergunta já orienta a identificação da variável aleatória envolvida.</p>
<p>Defina <span class="math inline">\(X\)</span> como o número de computadores defeituosos comprados pelo cliente. Os valores possíveis de <span class="math inline">\(X\)</span> são 0, 1 ou 2, representando, respectivamente, “nenhum defeituoso”, “exatamente um defeituoso” ou “dois defeituosos”. Assim, o espaço amostral associado a este experimento é <span class="math inline">\({\Omega = \{0,1,2\}}\)</span>.</p>
<p>Para determinar a FDP de <span class="math inline">\(X\)</span>, precisamos calcular os valores das probabilidades para todos os elementos do espaço amostral, <span class="math inline">\(f_X(k) = P[X = k]\)</span>. Para isso, podemos recorrer à análise combinatória:</p>
<p><span class="math display">\[\begin{align*}
&amp; f_X(0) = P[X=0] = \frac{\binom{3}{0}\binom{5}{2}}{\binom{8}{2}} = \frac{10}{28}\\
&amp; f_X(1) = P[X=1] = \frac{\binom{3}{1}\binom{5}{1}}{\binom{8}{2}} = \frac{15}{28}\\
&amp; f_X(2) = P[X=2] = \frac{\binom{3}{2}\binom{5}{0}}{\binom{8}{2}} = \frac{3}{28}
\end{align*}\]</span></p>
<p>No denominador, consideramos todas as formas de escolher 2 dentre os 8 computadores disponíveis, dadas por <span class="math inline">\(\binom{8}{2}\)</span>; no numerador, contamos as maneiras de selecionar a quantidade exata de computadores defeituosos e não-defeituosos para cada caso. Por exemplo, no caso de <span class="math inline">\(X=0\)</span>, o cliente selecionou dois computadores não-defeituosos. Isso significa que, dos 3 defeituosos disponíveis, nenhum foi selecionado (esta quantidade é determinada por <span class="math inline">\(\binom{3}{0}\)</span>); os dois computadores comprados foram selecionados do grupo restante. É possível escolher um conjunto de 3 a partir de um total de 5 de <span class="math inline">\(\binom{5}{2}\)</span> maneiras. Os outros casos seguem um raciocínio análogo.</p>
<p>Esses valores podem ser exibidos em uma tabela ou em um gráfico de barras, ilustrando claramenteda distribuição de probabilidade de <span class="math inline">\(X\)</span>.</p>
<div id="fig-fdp-ex-computadores" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fdp-ex-computadores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row quarto-layout-valign-bottom">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-fdp-ex-computadores" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-comp-tabela" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-comp-tabela-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/comp-fdp.png" class="img-fluid figure-img" style="width:50.0%" data-ref-parent="fig-fdp-ex-computadores">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-comp-tabela-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Tabela de Frequências
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-fdp-ex-computadores" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-comp-barplot" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-comp-barplot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/comp.png" class="img-fluid figure-img" style="width:50.0%" data-ref-parent="fig-fdp-ex-computadores">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-comp-barplot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Gráfico de Barras
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fdp-ex-computadores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;6: Função distribuição de probabilidade do número de computadores defeituosos comprados.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
<p>Seguindo agora para o caso contínuo, convém lembrar que variáveis aleatórias contínuas estão associadas a processos aleatórios que descrevem algum tipo de medição. Na prática, nenhuma medição tem precisão infinita, de modo que tudo <em>poderia</em> ser modelado de forma discreta. Porém, por vezes, v.a.’s contínuas podem ser uma abstração matemática útil para simplificar os cálculos.</p>
<p>Suponha que <span class="math inline">\(X\)</span> seja uma v.a. discreta e assuma o valor 3,5 (com precisão de uma casa decimal) com probabilidade <span class="math inline">\(p\)</span>. Se conseguirmos melhorar nosso processo de medição, de tal forma que agora é possível obter o valor de duas casas decimais, isso significa que o valor de probabilidade <span class="math inline">\(p\)</span> associado ao valor 3,5 terá que ser distribuído entre todos os valores entre 3,50 e 3,59, obtidos a partir do refinamento. Assumindo que cada um desses valores ocorra com probabilidade <span class="math inline">\(p_i\)</span>, temos:</p>
<p><span class="math display">\[{p = P[X = 3,50] + P[X = 3,51] + ... + P[X = 3,59] = \sum_{i=1}^{10} p_i}\]</span></p>
<p>Se o processo de medição passar por um novo aprimoramento, de forma que uma casa decimal adicional seja obtida, teremos para cada <span class="math inline">\(p_i\)</span> um refinamento equivalente, ou seja, o valor de cada probabilidade <span class="math inline">\(p_i\)</span> deverá ser redistribuído entre os valores correspondentes. Perceba que repetindo indefinidamente esse refinamento, cada probabilidade pontual <span class="math inline">\(p_i\)</span> tende a zero, mas a probabilidade de <span class="math inline">\(X\)</span> estar em um intervalo como <span class="math inline">\([3,50, 3,59]\)</span> se estabiliza. Esse raciocínio motiva a definição de <strong>função distribuição de probabilidade</strong> para variáveis contínuas.</p>
</section>
<section id="função-distribuição-de-probabilidade-fdp-caso-contínuo" class="level3">
<h3 class="anchored" data-anchor-id="função-distribuição-de-probabilidade-fdp-caso-contínuo">Função Distribuição de Probabilidade (FDP): caso contínuo</h3>
<p>Seja <span class="math inline">\(X\)</span> uma v.a. contínua. A FDP de <span class="math inline">\(X\)</span> é a função:</p>
<p><span class="math display">\[
{f_X(\cdot): \Re \rightarrow [0,\infty)}
\]</span></p>
<p>tal que, para quaisquer <span class="math inline">\({a \leq b}\)</span></p>
<p><span class="math display">\[
P[a \leq X \leq b] =\int_{a}^{b} f_X(u) du
\]</span></p>
<p>Note que, diferentemente do caso discreto, <span class="math inline">\(f_X(x)\)</span> não é a probabilidade de <span class="math inline">\(X=x\)</span> pois, em um espaço amostral contínuo, <span class="math inline">\(P[X = x] = 0\)</span>. Em vez disso, decorre da definição que a probabilidade de <span class="math inline">\(X\)</span> se encontrar no intervalo <span class="math inline">\([a,b]\)</span> é dada pela área sob <span class="math inline">\(f_X\)</span> no intervalo <span class="math inline">\([a,b]\)</span>, como ilustra a figura abaixo:</p>
<div id="fig-fdp-cont" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fdp-cont-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/fdp-cont.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fdp-cont-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;7: Representação de uma FDP contínua. A probabilidade de <span class="math inline">\(X\)</span> assumir um valor no intervalo <span class="math inline">\([a,b]\)</span> corresponde à área sombreada.
</figcaption>
</figure>
</div>
<p>As condições para que <span class="math inline">\(f_X\)</span> seja uma função probabilidade legítima também decorrem da definição axiomática de Kolmogorov:</p>
<ol type="1">
<li><span class="math inline">\(f_X(x) \geq 0\)</span>, para todo <span class="math inline">\(x \in \Re\)</span></li>
<li><span class="math inline">\({\int_{-\infty}^{\infty} f_X(x) dx= 1}\)</span></li>
<li><span class="math inline">\(P[X=c] = 0\)</span>, para todo <span class="math inline">\(c \in \Re\)</span></li>
</ol>
<p>Veja que a probabilidade de que <span class="math inline">\(X\)</span> assuma um valor fixo igual à constante real <span class="math inline">\(c\)</span> é nula (isso significa que, num espaço amostral infinito, a probabilidade de observar <strong>exatamente</strong> um valor real <span class="math inline">\(c\)</span> vale zero). Como consequência dessa definição, também há diferença entre intervalos abertas ou fechadas. Portanto, para quaisquer números <span class="math inline">\(\mathsf{a &lt; b}\)</span>:</p>
<p><span class="math display">\[
P[a \leq X \leq b] = P[a &lt; X \leq b] = P[a \leq X &lt; b] = P[a &lt; X &lt; b]
\]</span></p>
<p>Para compreender por que <span class="math inline">\(f_X(x)\)</span> não fornece uma probabilidade pontual associada a um evento em particular, considere um intervalo <span class="math inline">\([a-\epsilon, a+\epsilon]\)</span>, com <span class="math inline">\(\epsilon \rightarrow 0\)</span>. À medida que estreitamos o intervalo em torno de <span class="math inline">\(a\)</span>, a probabilidade tende a zero, ainda que a densidade de <span class="math inline">\(X\)</span> (valor de <span class="math inline">\(f_X\)</span> no ponto) possa assumir um valor arbitrariamente grande para <span class="math inline">\(X=a\)</span>.</p>
<p><span class="math display">\[
P[a - \epsilon \leq X \leq a+ \epsilon] = \int_{a-\epsilon}^{a+\epsilon} f_X(u) du \stackrel{\epsilon \rightarrow 0}{\approx} 2 \epsilon f_X(a)
\]</span></p>
<p>Sendo assim, a FDP de <span class="math inline">\(X\)</span> em <span class="math inline">\(a\)</span> pode ser entendida como uma medida relativa da chance de que <span class="math inline">\(X\)</span> se encontre em uma <em>vizinhança</em> de <span class="math inline">\(a\)</span>, ou como uma “massa de probabilidade por unidade de comprimento” na vizinhança de <span class="math inline">\(a\)</span>.</p>
<div id="fig-fdp-cont" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fdp-cont-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/fdp-cont-2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fdp-cont-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;8: Interpretação da FDP contínua como “massa de probabilidade por unidade de comprimento”. Quando <span class="math inline">\(\epsilon \rightarrow 0\)</span>, a probabilidade de que <span class="math inline">\(X\)</span> se encontre em uma vizinhança de <span class="math inline">\(a\)</span> corresponde à área sombreada e vale, aproximadamente, <span class="math inline">\(2 \epsilon f_X(a)\)</span>.
</figcaption>
</figure>
</div>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-projetil-FDP" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 11 (Lançamento de um Projétil em um Alvo Circular)</strong></span> <br> Um projétil atinge um disco de raio <span class="math inline">\(r\)</span> de maneira completamente arbitrária. Qualquer ponto do disco é igualmente provável e o projétil não pode cair fora dele. Defina <span class="math inline">\(X\)</span> como a distância do ponto atingido pelo projétil ao centro do disco (o alvo). A FDP de <span class="math inline">\(X\)</span> é dada por:</p>
<p><span class="math display">\[\begin{align*}
  f_X(x) =
  \left\{
  \begin{array}{ll}
    \frac{2x}{r^2}, &amp; 0 \leq x \leq r \\
    0, &amp; \textsf{caso contrário}
  \end{array}
  \right.
\end{align*}\]</span></p>
<ol type="1">
<li>Verifique que <span class="math inline">\({\int_{-\infty}^{\infty} f_X(x) dx= 1}\)</span>.</li>
<li>Calcule <span class="math inline">\(P[0 &lt; X \leq r/2]\)</span>.</li>
</ol>
<p><strong>Solução:</strong></p>
<ol type="1">
<li></li>
</ol>
<p><span class="math display">\[
\int_{-\infty}^{\infty} f_X(x) dx = \int_{0}^{r} \frac{2x}{r^2} dx = \frac{2}{r^2}\left[\frac{1}{2}x^2\right]_{0}^{r} = \frac{1}{r^2} [r^2 - 0] = 1
\]</span></p>
<ol start="2" type="1">
<li>Para determinar a probabilidade de que a distância máxima do projétil ao alvo seja igual à metade do raio do disco, vamos calcular a integral de zero a <span class="math inline">\(r/2\)</span> da FDP de <span class="math inline">\(X\)</span>:</li>
</ol>
<p><span class="math display">\[
P[0 &lt; X \leq r/2] =  \int_{0}^{r/2} \frac{2x}{r^2} dx = \frac{2}{r^2}\left[\frac{x^2}{2}\right]_{0}^{r/2} = \frac{1}{r^2}\left[\frac{r^2}{4} - 0 \right] = \frac{1}{4}
\]</span></p>
<p>Notavelmente, a probabilidade encontrada independe do raio <span class="math inline">\(r\)</span> do disco.</p>
</div>
</div>
</div>
</div>
<p>Muitas vezes pode ser útil expressar a distribuição de uma v.a. por meio da <strong>função distribuição acumulada</strong> (FDA), que se aplica tanto a variáveis discretas quanto contínuas. Diferentemente da FDP, a FDA é <strong>unicamente determinada</strong> para cada v.a. e pode ser utilizada para calcular probabilidades associadas a essa v.a.</p>
</section>
<section id="função-distribuição-acumulada-fda" class="level3">
<h3 class="anchored" data-anchor-id="função-distribuição-acumulada-fda">Função Distribuição Acumulada (FDA)</h3>
<p>A FDA de uma v.a. <span class="math inline">\(X\)</span>, representada por <span class="math inline">\({F_X(\cdot)}\)</span> é a função:</p>
<p><span class="math display">\[\begin{align*}
  {F_X(\cdot): \Re \rightarrow [0, 1]\quad \textsf{tal que} \quad
      F_X(x) = P[X \leq x], \quad -\infty &lt; x &lt; \infty}
\end{align*}\]</span></p>
<p>A fim de que seja uma função probabilidade legítima, a FDA de uma v.a. <span class="math inline">\(X\)</span> deve satisfazer:</p>
<ol type="1">
<li><p><span class="math inline">\({F_X(\cdot)}\)</span> é monotônica não-descrescente: <span class="math inline">\(\;{F_X(x_1) &lt; F_X(x_2), \; x_1 &lt; x_2}\)</span></p></li>
<li><p><span class="math inline">\({F_X(-\infty) = \lim_{x \rightarrow -\infty}F_X(x) = 0}\)</span> e<br>
<span class="math inline">\({F_X(+\infty)  = \lim_{x \rightarrow +\infty}F_X(x) = 1}\)</span></p></li>
<li><p><span class="math inline">\({F_X(\cdot)}\)</span> é contínua pela direita: <span class="math inline">\({F_X(x) = \lim_{0&lt;h \rightarrow 0} F_X(x+h)}\)</span></p></li>
</ol>
<p>A FDA precisa ser uma função monotônica não decrescente, de forma que, dados dois números reais <span class="math inline">\(x_1\)</span> estritamente menor que <span class="math inline">\(x_2\)</span>, então a função em <span class="math inline">\(x_1\)</span> tem de ser estritamente menor que a função em <span class="math inline">\(x_2\)</span>. Como a FDA representa uma probabilidade acumulada, <span class="math inline">\(F_X(-\infty) = 0\)</span> significa que em <span class="math inline">\(-\infty\)</span> nenhum valor de probabilidade foi acumulado (a probabilidade de observar um valor menor ou igual a menos infinito é zero); por outro lado, quando vamos para a outra extremidade da reta real, representada por <span class="math inline">\(\infty\)</span>, todo o domínio foi varrido e todos os valores de probabilidade já foram acumulados, portanto <span class="math inline">\(F_X(\infty) = 1\)</span>. Além disto, a FDA é uma função contínua pela direita.</p>
<p>Para variáveis discretas, a FDA tem forma de “degraus”, pois acumula nos pontos de massa de probabilidade; para variáveis contínuas, é uma função contínua cuja derivada (quando existe) é a propria densidade <span class="math inline">\(f_X(x)\)</span>.</p>
<p>Seguem algumas consequências dessas condições:</p>
<ul>
<li><p>Dado <span class="math inline">\({x}\)</span> qualquer, <span class="math display">\[{P[X &gt; x] = 1- F_X(x)}\]</span></p></li>
<li><p>Dados <span class="math inline">\({x_1}\)</span> e <span class="math inline">\({x_2}\)</span> tais que <span class="math inline">\({x_1 &lt; x_2}\)</span>,</p></li>
</ul>
<p><span class="math display">\[{P[x_1&lt; X \leq x_2] = P[X \leq x_2] - P[X \leq x_1]}\]</span></p>
<p>Esta situação é ilustrada na figura pela área em vermelho menos a área em azul, que corresponde à área sob a FDP entre <span class="math inline">\(x_1\)</span> e <span class="math inline">\(x_2\)</span>.</p>
<div id="fig-fda" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fda-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/FDA.png" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fda-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;9: A probabilidade de que <span class="math inline">\(X\)</span> se encontre no intervalo <span class="math inline">\((x_1, x_2]\)</span> pode ser determinada pela diferença da FDA nos dois pontos: <span class="math inline">\(P[x_1&lt; X \leq x_2] = F_X(x_2) - F_X(x_1)\)</span>.
</figcaption>
</figure>
</div>
<p>A seguir, destacamos como encontrar a FDA a partir de <span class="math inline">\({f_X(\cdot)}\)</span> e vice-versa. É necessário fazer a distinção entre o caso discreto e o caso contínuo:</p>
<p><strong>Caso Discreto:</strong></p>
<ol type="i">
<li><p>Dada <span class="math inline">\({f_X(\cdot)}\)</span>,<br>
<span class="math inline">\({F_X(x) = P[X \leq x] = \sum_{x_j &lt;x}f_X(x_j)}\)</span></p></li>
<li><p>Dada <span class="math inline">\({F_X(\cdot)}\)</span>,<br>
<span class="math inline">\({f_X(x_j) = F_X(x_j) - \lim_{0&lt;h \rightarrow 0} F_X(x_j - h)}\)</span></p></li>
</ol>
<p>Para o caso discreto, para obter a FDA a partir da FDP, basta somar as probabilidades nos valores que satisfazem a condição desejada. Para obter a FDP a partir da FDA, basta utilizar a diferença dos valores de FDA em <span class="math inline">\(x_j\)</span> e o valor da FDA em <span class="math inline">\(X\)</span> imediatamente inferior a <span class="math inline">\(x_j\)</span>.</p>
<p><strong>Caso Contínuo:</strong></p>
<ol type="i">
<li><p>Dada <span class="math inline">\({f_X(\cdot)}\)</span>,<br>
<span class="math inline">\({F_X(x) = P[X \leq x] = \int_{-\infty}^{x} f_X(u) du}\)</span></p></li>
<li><p>Dada <span class="math inline">\({F_X(\cdot)}\)</span>,<br>
<span class="math inline">\({f_X(x) = \frac{dF_X(x)}{dx}}\)</span></p></li>
</ol>
<p>Para o caso contínuo, dada a FDP, a FDA em <span class="math inline">\(x\)</span> é dada pela integral de <span class="math inline">\(-\infty\)</span> e o valor de <span class="math inline">\(x\)</span> desejado. Para obter a FDP a partir da FDA, basta tomar a derivada da FDA com relação a <span class="math inline">\(x\)</span>.</p>
<p>A seguir, são apresentados alguns exemplos de aplicação imediata desses conceitos.</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-computadores-FDA" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 12 (Computadores defeituosos, continuação)</strong></span> <br></p>
<ol type="a">
<li>Determine a FDA para <span class="math inline">\(X\)</span>, o número de computadores defeituosos comprados pelo cliente.</li>
<li>Usando <span class="math inline">\(F_X(x)\)</span>, verifique que <span class="math inline">\(f_X(2) = 3/28\)</span>.</li>
</ol>
<p><strong>Solução:</strong></p>
<ol type="a">
<li>FDA de <span class="math inline">\(X\)</span>:</li>
</ol>
<p><span class="math display">\[\begin{align*}
&amp; F_X(0) = P[X \leq 0] = P[X=0] = \frac{10}{28}\\
&amp; F_X(1) = P[X \leq 1] = P[X=0] + P[X=1] = \frac{10}{28} + \frac{15}{28} = \frac{25}{28}\\
&amp; F_X(2) = P[X \leq 2] =  1 - P[X&gt;2] = 1 - 0 = 1 \phantom{\frac{10}{28}}\\
\end{align*}\]</span></p>
<p>Portanto,</p>
<p><span class="math display">\[\begin{align*}
  {F_X(x)} =
  \begin{cases}
    0,       &amp; \mathsf{x &lt; 0}\\
    10/28,   &amp; \mathsf{0 \leq x &lt; 1}\\
    25/28,   &amp; \mathsf{1 \leq x &lt; 2}\\
    1,       &amp; \mathsf{x \geq 2}\\
  \end{cases}
\end{align*}\]</span></p>
<ol start="2" type="a">
<li>Para confirmar <span class="math inline">\(f_X(2)\)</span>, basta notar que <span class="math display">\[f_X(2) = F_X(2) - F_X(1) = 1 - \frac{25}{28} = \frac{3}{28}\]</span></li>
</ol>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-projetil-FDA" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 13 (Lançamento de um Projétil em um Alvo Circular, continuação)</strong></span> <br></p>
<ol type="a">
<li>Determine a FDA para <span class="math inline">\(X\)</span>, a distância do projétil ao alvo</li>
<li>Calcule <span class="math inline">\({P[r/2 &lt; X \leq r]}\)</span>, usando <span class="math inline">\(F_X(x)\)</span></li>
</ol>
<p><strong>Solução:</strong></p>
<ol type="a">
<li>FDA de <span class="math inline">\(X\)</span>:</li>
</ol>
<p>Sabendo que <span class="math inline">\(f_X(x) = \frac{2x}{r^2}\)</span> para <span class="math inline">\(0 \leq x \leq r\)</span> e zero, caso contrário, obtemos:</p>
<p><span class="math display">\[
F_X(x) = P[X\leq x] = \int_{-\infty}^{x} f(u)du =
  \begin{cases}
    0, &amp; \phantom{0 \leq \;} x \leq 0\\
    \int_{0}^{x} \frac{2u} {r^2} du  
    = \frac{2}{r^2} \left[ \frac{u^2}{2} \right]_{0}^{x}
    = \frac{x^2}{r^2}, &amp; 0 &lt; x &lt; r \\
    1, &amp; \phantom{0 \leq \;} x \geq r\\
  \end{cases}
\]</span></p>
<ol start="2" type="a">
<li><span class="math display">\[
P[r/2 &lt; X \leq r] = F_X(r) - F_X(r/2) = \frac{r^2}{r^2} - \frac{r^2}{4r^2} = 1 - \frac{1}{4} = \frac{3}{4}
\]</span></li>
</ol>
<p>Veja que essa probabilidade também independe do raio do disco.</p>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="valor-esperado-e-variância" class="level2">
<h2 class="anchored" data-anchor-id="valor-esperado-e-variância">Valor Esperado e Variância</h2>
<p>Até agora, vimos que a distribuição de probabilidade de uma v.a. pode ser representada de várias formas: pela função distribuição de probabilidade (FDP), pela função distribuição acumulada (FDA), por representações gráficas ou por valores tabulados.</p>
<p>Tanto a FDP quanto a FDA são modelos construídos com a finalidade de <strong>resumir</strong> ou representar matematicamente fenômenos aleatórios. Dependendo da complexidade do problema, especificar essas funções de maneira completa pode ser extremamente trabalhoso ou inviável. Novamente, surge a questão se é realmente necessário construir uma descrição completa do problema, ou se é suficiente observar algumas características importantes da distribuição, que capturem a essência da incerteza.</p>
<p>Neste sentido, dois conceitos importantes em teoria de probabilidades tornam-se muito úteis: <strong>valor esperado</strong> e <strong>variância</strong>. O valor esperado, por exemplo, indica a <em>localização</em> do centro da distribuição, descrevendo quais são os valores típicos da v.a. em questão. A variância, por sua vez, nos dá uma medida da <em>dispersão</em> ou do nível de espalhamento dos valores assumidos pela v.a. em torno de seu centro. Embora sozinhos não forneçam uma descrição completa da distribuição, muitas vezes, conhecer o valor esperado e a variância podem ser suficientes para auxiliar o processo de tomada de decisão, pois resumem características importantes da distribuição.</p>
<section id="valor-esperado" class="level3">
<h3 class="anchored" data-anchor-id="valor-esperado">Valor Esperado</h3>
<p>Seja <span class="math inline">\(X\)</span> uma variável aleatória. O valor esperado de <span class="math inline">\(X\)</span>, representado por <span class="math inline">\({\mu_X}\)</span> ou <span class="math inline">\({E[X]}\)</span>, é definido da seguinte forma:</p>
<p><strong>Caso Discreto:</strong><br>
<span class="math display">\[
{E[X] = \sum_x x\cdot f_X(x)},\]</span></p>
<p>onde a soma é realizada em todos os valores <span class="math inline">\({x}\)</span> que <span class="math inline">\({X}\)</span> pode assumir.</p>
<p><strong>Caso Contínuo:</strong><br>
<span class="math display">\[
{E[X] = \int_{-\infty}^\infty x\cdot f_X(x) d(x)},\]</span></p>
<p>onde <span class="math inline">\({f_X(x)}\)</span> é a FDP de <span class="math inline">\({X}\)</span>.</p>
<p>Para que <span class="math inline">\(E[X]\)</span> exista, é necessário que <span class="math inline">\({\sum_x |x|f_X(x) &lt; \infty}\)</span> (no caso discreto) ou <span class="math inline">\({\int_{-\infty}^{\infty} |x|f_X(x)dx &lt; \infty}\)</span> (no caso contínuo) sejam finitos. Há distribuições, como algumas de caudas pesadas, para as quais não existe valor esperado.</p>
<p>Vejamos, a seguir, alguns exemplos.</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-computadores-Esperança" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 14 (Computadores Defeituosos, continuação)</strong></span> <br> Retomemos o exemplo dos computadores defeituosos. De um total de 8 computadores (3 defeituosos e 5 não-defeituosos), um cliente seleciona 2 ao acaso. Defina <span class="math inline">\(X\)</span> como o número de computadores defeituosos comprados pelo cliente. Qual o número de computadores defeituosos que se espera observar na compra do cliente?</p>
<p><strong>Solução:</strong></p>
<p>Temos:<br>
<span class="math inline">\(X\)</span> = no. de computadores defeituosos comprados pelo cliente. A FDP dessa v.a. foi determinada anteriormente, no <a href="#exm-computadores-FDP" class="quarto-xref">Exemplo&nbsp;10</a>, de forma que o valor esperado de <span class="math inline">\(X\)</span> pode ser calculado através da soma ponderada de cada valor que <span class="math inline">\(X\)</span> pode assumir, em que os pesos correspondem às probabilidades de observar cada um dos valores assumidos pela v.a.:</p>
<p><span class="math display">\[\begin{align*}
\mu = {E[X]} &amp;= {\sum_x x \cdot f_X(x)}\\
    &amp;= {0\cdot f_X(0) + 1\cdot f_X(1) + 2\cdot f_X(2)}\\
    &amp;= {0 \cdot \frac{10}{28} + 1 \cdot\frac{15}{28} + 2 \cdot \frac{3}{28} = \frac{21}{28}} = \text{0,75}
\end{align*}\]</span></p>
<p>Este resultado indica que, se repetirmos inúmeras vezes o procedimento de selecionar 2 computadores a partir de um lote de tamanho 8 em que 3 são defeituosos, o <strong>número médio</strong> de computadores defeituosos por compra tende a 0,75. Note que o valor esperado não precisa necessariamente ser igual a um dos valores possíveis para <span class="math inline">\(X\)</span>. Para uma única compra, <span class="math inline">\(X\)</span> só pode ser 0, 1 ou 2, mas a média dos resultados ao longo de muitas repetições converge para 0,75.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-projetil-Esperança" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 15 (Lançamento de um Projétil em um Alvo Circular, continuação)</strong></span> <br> Seja <span class="math inline">\(X\)</span> a distância do ponto onde um projétil atinge um disco de raio <span class="math inline">\(r\)</span> ao centro do disco. Determinamos anteriormente que <span class="math inline">\(f_X(x) = \frac{2x}{r^2}\)</span>, para <span class="math inline">\(0&lt;x&lt;r\)</span>. Para determinar o valor esperado <span class="math inline">\(E[X]\)</span>, integramos o produto <span class="math inline">\(xf_X(x)\)</span> em todo o domínio:</p>
<p><strong>Solução:</strong></p>
<p><span class="math display">\[\begin{align*}
\mu = {E[X]} &amp;= {\int_{-\infty}^{\infty} x \cdot f_X(x) dx}
    = {\int_{0}^{r} x \frac{2x}{r^2} dx} = {\left.\frac{2}{r^2}\frac{x^3}{3}\right|_{0}^{r}}
    = {\frac{2}{3}r}
\end{align*}\]</span></p>
<p>Portanto, espera-se que o projétil atinja, em média, um ponto a uma distância de 2/3 do raio do disco a partir de seu centro.</p>
</div>
</div>
</div>
</div>
<p><strong>Propriedades do Valor Esperado</strong></p>
<ul>
<li><p>Se existir uma constante <span class="math inline">\(a\)</span> tal que <span class="math inline">\(P[X\geq a] = 1\)</span>, então <span class="math inline">\(E[X] \geq a\)</span>.<br>
Se existir uma constante <span class="math inline">\(b\)</span> tal que <span class="math inline">\(P[X\leq b] = 1\)</span>, então <span class="math inline">\(E[X] \leq b\)</span>.<br>
Em ambos os casos, se é certo que <span class="math inline">\(X\)</span> assume apenas valores maiores (ou menores) que uma dada constante, o valor esperado da v.a. também precisa ser maior (menor) que essa constante.</p></li>
<li><p>Se a distribuição de <span class="math inline">\(X\)</span> é simétrica em torno de um ponto (<span class="math inline">\(\mu\)</span>), o ponto de simetria corresponde ao valor esperado, desde que ele exista: <span class="math display">\[
f_X(x) = \varphi(x-\mu) = \varphi(\mu-x) \quad \Longrightarrow \quad E[X] = \mu
\]</span></p></li>
<li><p><span class="math inline">\({E[c] = c}\)</span>, para <span class="math inline">\({c}\)</span> constante.<br>
Obviamente, o valor esperado de uma constante é a própria constante. Neste caso, estamos diante de uma variável que não é aleatória, portanto, o valor esperado dessa variável é igual ao único valor que pode assumir.</p></li>
<li><p>O valor esperado é um operador linear, ou seja, para constantes <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span>, vale:</p></li>
</ul>
<p><span class="math display">\[
E[aX + b] = a E[X] + b
\]</span></p>
<ul>
<li>De maneira geral, o valor esperado de uma função <span class="math inline">\(g(X)\)</span> pode ser obtido sem que seja necessário determinar a distribuição de <span class="math inline">\(g(X)\)</span>:</li>
</ul>
<p><span class="math display">\[\begin{align*}
  &amp;E[g(X)] = \sum_x g(x) f_X(x) &amp;&amp;\textsf{(caso discreto)}\\
  &amp;E[g(X)] = \int_{-\infty}^{\infty} g(x) f_X(x) dx &amp;&amp;\textsf{(caso contínuo)}
\end{align*}\]</span></p>
<ul>
<li>Em situações multidimensionais, se <span class="math inline">\({X_1, \ldots, X_n}\)</span> são v.a.’s para as quais existe o valor esperado <span class="math inline">\(E[X_i]\)</span>, <span class="math inline">\(i = 1, \ldots, n\)</span>, então, para as constantes <span class="math inline">\(a_1, \ldots, a_n, b\)</span>: <span class="math display">\[
E[a_1 X_1 + \ldots + a_n X_n + b] = a_1 E[X_1] + \ldots + a_n E[X_n] + b
\]</span></li>
</ul>
<div class="callout callout-style-simple callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
O Problema dos Pontos e a Aposta de Pascal
</div>
</div>
<div class="callout-body-container callout-body">
<p>Blaise Pascal (1623-1662) foi o primeiro a descrever formalmente como obter o valor esperado de uma aposta. Um dos problemas que impulsionou seu raciocíncio foi o “Problema dos Pontos”, proposto pelo Chevalier de Méré. Este problema envolvia a partilha justa do prêmio de um jogo de apostas interrompido antes de ser concluído, entre dois jogadores. Em sua troca de correspondências com Fermat, Pascal desenvolveu três argumentos para chegar à solução matemática deste problema. Em sua carta de 29 de julho de 1654 a Pierre de Fermat, Pascal desenvolveu a ideia de igualar o valor do jogo à sua <strong>“esperança matemática”</strong>, que poderia ser calculada como o produto da probabilidade de vencer pelo valor da aposta. Assim, ele sugeria que o prêmio deveria ser dividido de acordo com a expectativa de vitória de cada jogador no momento da interrupção. Com isso, Pascal concebeu o conceito moderno de <strong>valor esperado</strong>. Jakob Bernoulli I viria a denominar o valor esperado de o “princípio fundamental da arte” em seu trabalho <em>Ars Conjectandi</em> (1713).</p>
<p>Posteriormente, Pascal utilizou seu conceito de esperança matemática em sua famosa “Aposta” que, provavelmente, é o primeiro problema moderno de análise de decisão. Pascal argumenta que, na ausência de provas definitivas sobre a existência de Deus, seria <strong>racional</strong> viver como se Deus existisse. Seu argumento é muito simples: segundo ele, se alguém aposta pela não-existência de Deus (decidindo viver, assim, uma vida pautada por más ações) e erra, o custo do erro de decisão seria a “condenação eterna”. Por outro lado, caso apostasse na existência de Deus e errasse, as perdas seriam mínimas em comparação. Portanto, em vez de tentar provar a existência de Deus, ele argumenta que uma pessoa racional deveria pautar sua vida e suas ações com sobriedade e correção, mesmo que a verdade a respeito da existência de Deus não pudesse ser conhecida de fato.</p>
<p>É interessante notar que esse raciocínio continua relevante e que pode ser estendido para outras situações em que provas definitivas são difíceis de obter, mas em que as consequências de uma decisão equivocada podem ser graves. Um exemplo atual é a questão sobre o aquecimento global e as mudanças climáticas. O argumento é tão simples quanto aquele apresentado por Pascal: se a atividade humana provoca mudanças climáticas e as pessoas decidem apostar que este não é o caso, as consequências do erro de decisão podem ser catastróficas (incluindo aumento no nível dos mares e oceanos, secas, fome, conflitos e, possivelmente a extinção de nossa espécie); por outro lado, se a atividade humana nada tem a ver com o processo de aquecimento global e mudanças climáticas, então o erro de decisão (que implicaria em levar uma vida mais sustentável) não teria um custo tão elevado, se comparado à aniquilação total. Portanto, na ausência de provas definitivas e irrefutáveis de que a ação humana é responsável pelo aquecimento global e as mudanças climáticas, concluímos que é racional agir de forma preventiva, pois errar ao subestimar o problema pode gerar consequências desastrosas e irremediáveis.</p>
</div>
</div>
<p>Embora o valor esperado descreva a tendência central, ou seja, o ponto em torno do qual os valores da v.a. se distribuem, ele nada informa sobre sua <strong>dispersão</strong> em torno do centro. Uma maneira de medir a variabilidade de uma v.a. é considerando o quanto ela se afasta de sua média.</p>
</section>
<section id="variância" class="level3">
<h3 class="anchored" data-anchor-id="variância">Variância</h3>
<p>Para mensurar o espalhamento dos valores de <span class="math inline">\(X\)</span> em torno do centro da distribuição <span class="math inline">\(\mu_X = E[X]\)</span>, definimos a <strong>variância</strong> <span class="math inline">\({Var[X]}\)</span> (ou <span class="math inline">\({\sigma_X^2}\)</span>):</p>
<p><strong>Caso Discreto:</strong> <span class="math display">\[
{Var[X] = E[(X-\mu_x)^2] = \sum_x (x-\mu_x)^2 \cdot f_X(x)},
\]</span></p>
<p>onde a soma é realizada para os pontos em que <span class="math inline">\(X\)</span> é definida.</p>
<p><strong>Caso Contínuo:</strong> <span class="math display">\[
{Var[X] = E[(X-\mu_x)^2] = \int_{-\infty}^{\infty} (x-\mu_x)^2 \cdot f_X(x)},
\]</span><br>
onde <span class="math inline">\(f_X(x)\)</span> é a FDP de <span class="math inline">\(X\)</span>.</p>
<p><strong>Propriedades da Variância</strong></p>
<ul>
<li><p>A variância corresponde à esperança de uma função quadrática, portanto não pode assumir valores negativos:&nbsp; <span class="math inline">\({Var[X] \geq 0}\)</span></p></li>
<li><p>Se a variância é nula, isso implica que a variável em questão não é aleatória, assumindo apenas um valor constante <span class="math inline">\(c\)</span> e vice-versa: <span class="math display">\[Var[X] = 0 \iff \exists \, c= \textsf{ constante,  tal que } P[X=c]=1\]</span></p></li>
<li><p>Uma forma prática de calcular a variância emprega a expressão: <span class="math display">\[{Var[X] = E[X^2] -\big(E[X]\big)^2}\]</span></p></li>
<li><p>Para constantes <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> <span class="math display">\[Y = aX+b \quad \Longrightarrow \quad Var[Y] = a^2 Var[X]\]</span></p></li>
<li><p>Para a variância de uma função <span class="math inline">\(g(\cdot)\)</span> de <span class="math inline">\(X\)</span>, basta utilizar a definição de valor esperado aplicada ao quadrado da diferença entre <span class="math inline">\(g(X)\)</span> e o valor esperado de <span class="math inline">\(g(X)\)</span>, denotado por <span class="math inline">\(\mu_{g(X)}\)</span>:</p></li>
</ul>
<p><span class="math display">\[\begin{align*}
  &amp; Var[g(X)] = E\{[g(X) - \mu_{g(x)}]^2\}:\\
  \\
  &amp;Var[g(X)] = \sum_x [g(X) - \mu_{g(x)}]^2 \cdot f_X(x) &amp;&amp;\textsf{(caso discreto)}\\
  &amp;Var [g(X)] = \int_{-\infty}^{\infty} [g(X) - \mu_{g(x)}]^2 \cdot f_X(x) dx &amp;&amp;\textsf{(caso contínuo)}
\end{align*}\]</span></p>
<ul>
<li>Outra medida de dispersão de uma v.a. é o <strong>desvio-padrão</strong>: <span class="math display">\[{\sigma_x = +\sqrt{Var[X]}}\]</span> O desvio-padrão é dado nas mesmas unidades da v.a., o que torna seu uso preferível à variância em muitas aplicações.</li>
</ul>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Padronização
</div>
</div>
<div class="callout-body-container callout-body">
<p><br> A padronização é uma transformação de escala e localização. A variável aleatória é centralizada com relação à sua média, e re-escalada de forma a tornar seu valor esperado nulo e variância unitária:</p>
<p>Se <span class="math inline">\(X\)</span> é uma v.a. com <span class="math inline">\({E[X] = \mu_x}\)</span> e <span class="math inline">\({Var[X] = \sigma^2_x}\)</span>, então<br>
<span class="math display">\[{Y = \frac{X - \mu_x}{\sigma_x}}\]</span> é uma v.a. <strong>padronizada</strong>, isto é, <span class="math inline">\({E[Y] = 0}\)</span> e <span class="math inline">\({Var[Y] = 1}\)</span>.</p>
</div>
</div>
</section>
</section>
<section id="momentos" class="level2">
<h2 class="anchored" data-anchor-id="momentos">Momentos</h2>
<p>Além das medidas de localização e dispersão apresentadas anteriormente, existem outras medidas que descrevem diferentes características de uma distribuição.</p>
<p>Os vários <strong>momentos</strong> de uma variável aleatória representam uma classe importante de esperanças que podem ser utilizadas para descrever completamente uma distribuição de probabilidade.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Momento de ordem <span class="math inline">\(k\)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p><br> O momento de ordem <span class="math inline">\({k \in \mathcal{Z}_+}\)</span> de <span class="math inline">\(X\)</span> existe se, e somente se, <span class="math display">\[{E[|X|^k] &lt; \infty}\]</span></p>
<p>e, neste caso, é dado por:</p>
<p><span class="math display">\[{\mu_k^\prime = E[X^k]}\]</span></p>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Momento central de ordem <span class="math inline">\(k\)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p><br> O momento central de ordem k de <span class="math inline">\(X\)</span> é dado por:</p>
<p><span class="math display">\[{\mu_k^{} = E[(X - \mu)^k]}\]</span> O momento central de ordem <span class="math inline">\(k\)</span>, corresponde ao <span class="math inline">\(k\)</span>-ésimo momento da v.a. tomado com relação a sua média.</p>
</div>
</div>
<p>Já vimos dois momentos importantes: a média (que corresponde ao primeiro momento de uma variável aleatória e descreve a localização do centro de sua distribuição) e a variância (que corresponde ao segundo momento central e descreve o espalhamento ou dispersão dos valores assumidos pela variável aleatória em torno de seu centro).</p>
<p>No século XIX, era uma prática comum entre os estatísticos tratar qualquer distribuição de frequência como sendo normal ou Gaussiana, isto é, tendo forma de sino: histogramas multimodais (aqueles com múltiplos picos) eram ajustados com misturas de gaussianas, assimetrias eram removidas através de transformações que garantissem a normalidade da distribuição e simetria era vista como uma evidência irrefutável da normalidade da população.</p>
<p>Foi neste contexto que Karl Pearson propôs (1894) um sistema de curvas (de distribuições) com diversas formas possíveis, de modo a permitir uma representação mais acurada dos dados observados, utilizando para isso momentos de ordens mais elevadas. Esse sistema de curvas era completamente determinado por quantidades associadas ao terceiro e quarto momentos centrais de uma variável aleatória.</p>
<section id="assimetria-skewness-e-excesso-kurtosis" class="level3">
<h3 class="anchored" data-anchor-id="assimetria-skewness-e-excesso-kurtosis">Assimetria (<em>skewness</em>) e Excesso (<em>kurtosis</em>)</h3>
<p>Os momentos centrais de 3a. e 4a. ordem estão associados aos conceitos de assimetria e excesso (ou curtose).</p>
<p>As medidas de assimetria indicam a diferença da distribuição das observações, se comparadas à distribuição normal (que tem forma de sino e é simétrica). Em uma distribuição simétrica, os valores de média, mediana e moda são idênticos.</p>
<p>Para distribuições unimodais com assimetria negativa, o valor da moda é maior que a média e a mediana se encontra entre a média e a moda; a distribuição apresenta cauda inferior (à esquerda) longa, de forma que a média é deslocada para baixo. Por outro lado, para distribuições unimodais com assimetria positiva, a média é maior que moda e a mediana se encontra entre a moda e a média. Distribuições com assimetria positiva admitem valores muito maiores que a maior parte das observações, de forma que a cauda à direita é mais longa e a média é deslocada para cima.</p>
<p>Distribuições assimétricas surgem em diversas situações como, por exemplo, quando a variável aleatória de interesse é renda, preço de imóveis, duração ou vida de um produto, idade no instante da aposentadoria entre outras.</p>
<p>A curtose é uma propriedade de distribuições simétricas e se refere ao nível de achatamento da distribuição, com relação à distribuição normal.</p>
<p>Distribuições mais espalhadas e achatadas que a distribuição normal são chamadas platicúrticas e apresentam valores negativos de curtose; distribuições mais concentradas em torno da média, isto é, que apresentam um pico mais elevado, são chamadas leptocúrticas e apresentam valor de curtose elevado. A distribuição normal, utilizada como referência, é chamada mesocúrtica. Valores elevados para a curtose podem estar associados à presença de observações extremas (<em>outliers</em>).</p>
<div id="fig-assimetria-curtose" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-assimetria-curtose-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="MB751_AULA02_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-assimetria-curtose-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;10: Ilustração da comparação de distribuições com características de assimetria e curtose distintas. As curvas em preto representam uma distribuição normal (simétrica e mesocúrtica). Painéis (a) e (b): as curvas coloridas são assimétricas. Painel (c): a curva azul tem curtose negativa (platicúrtica); a curva vermelha tem curtose positiva (leptocúrtica).
</figcaption>
</figure>
</div>
</section>
</section>
<section id="desigualdades-de-markov-e-chebyshev" class="level2">
<h2 class="anchored" data-anchor-id="desigualdades-de-markov-e-chebyshev">Desigualdades de Markov e Chebyshev</h2>
<p>Até agora, vimos que a fim de calcular probabilidades, precisamos conhecer a distribuição de probabilidade associada a uma determinada variável aleatória. Entretanto, é comum nos depararmos com a situação em que é muito difícil ou inviável obter a FDP ou FDA e possuímos apenas informações parciais sobre a v.a., como valor esperado e/ou a variância. Nesses casos, embora não possível calcular com exatidão certas probabilidades, ainda é possível estabelecer limites para elas.</p>
<p>Por exemplo, nossa intuição nos diz que deve ser raro observar uma v.a. se desviar demasiadamente de seu valor esperado, ou seja, não esperamos observar a ocorrência de eventos extremos com muita frequência. Mas qual a probabilidade de observar um valor atípico de uma variável aleatória? Em outras palavras, qual a probabilidade de que ela assuma um valor maior que uma certa quantidade?</p>
<p>Veremos a seguir como dois resultados simples e universais, as desigualdades de Markov e Chebyshev, fornecem argumentos matemáticos sólidos para confirmar tais conjecturas e responder a perguntas como essas.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-desigualdade-markov" class="theorem">
<p><span class="theorem-title"><strong>Teorema 1 (Desigualdade de Markov)</strong></span> <br></p>
<p>A desigualdade de Markov diz que, para <span class="math inline">\(X \geq 0\)</span> e <span class="math inline">\(k&gt;0\)</span> <span class="math display">\[{P[g(X) \geq k] \leq \frac{E[g(X)]}{k}}\]</span> <strong>Demonstração:</strong></p>
<p>Considere <span class="math inline">\(X\)</span> uma v.a. contínua com FDP <span class="math inline">\(f_X(x)\)</span>. Então</p>
<p><span class="math display">\[\begin{align*}
  E[g(X)]
  &amp;= \int_{-\infty}^\infty g(x)f_X(x)dx \\
  &amp;= \int_{\{x: g(x) \geq k\}} g(x)f_X(x)dx + \int_{\{x: g(x) &lt;k\}} g(x)f_X(x)dx\\
  &amp;\geq \int_{\{x: g(x) \geq k\}} g(x)f_X(x)dx\\
  &amp;\geq \int_{\{x: g(x) \geq k\}} kf_X(x)dx = kP[g(X)\geq k]
\end{align*}\]</span></p>
<p>Dividindo os dois lados da desigualdade por <span class="math inline">\(k\)</span>, leva ao resultado. Um raciocínio semelhante se aplica ao caso discreto.</p>
</div>
</div>
</div>
</div>
<p>A desigualdade de Markov é mais comumente enunciada na forma do corolário abaixo.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="cor-desigualdade-markov" class="theorem corollary">
<p><span class="theorem-title"><strong>Corolário 1</strong></span> <br> Nas condições do <a href="#thm-desigualdade-markov" class="quarto-xref">Teorema&nbsp;1</a>, para <span class="math inline">\(g(X) = X\)</span>:</p>
<p><span class="math display">\[P[X \geq k] \leq \frac{E[X]}{k}.\]</span></p>
</div>
</div>
</div>
</div>
<p>A desigualdade de Markov nos dá um limite superior para a probabilidade de uma variável aleatória não-negativa ser maior ou igual a uma constante positiva <span class="math inline">\(k\)</span>. Note que este limite superior é <strong>universalmente</strong> válido, ou seja, independe da distribuição de <span class="math inline">\(X\)</span>. Veja que se o valor esperado é pequeno, a probabilidade de que a v.a. assuma um valor elevado também é pequena.</p>
<p>Estamos especialmente interessados em valores elevados de <span class="math inline">\(k\)</span>. Quando <span class="math inline">\(k\)</span> é menor ou igual ao valor esperado de <span class="math inline">\(X\)</span>, a desigualdade não nos dá nenhuma informação, pois sabemos de antemão que essa probabilidade deve ser menor ou igual a 1.</p>
<p>Utilizando a desigualdade de Markov, podemos verificar resultados interessantes: por exemplo, para qualquer variável aleatória não-negativa <span class="math inline">\(X\)</span>, cuja média vale 1, o maior valor possível para a probabilidade de que <span class="math inline">\(X\)</span> seja maior ou igual a 100, é 0,01.</p>
<p>Uma consequência da desigualdade de Markov é a desigualdade de Chebyshev, que veremos a seguir. Essa desigualdade recebe o nome do matemático russo Pafnuty Chebyshev, que a enunciou pela primeira vez (sem demonstrá-la) em 1874. Dez anos depois, Andrey Markov (aluno de Chebyshev), demonstrou a desigualdade em sua tese de Doutorado.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-desigualdade-chebyshev" class="theorem">
<p><span class="theorem-title"><strong>Teorema 2 (Desigualdade de Chebyshev)</strong></span> <br></p>
<p>Vamos considerar que valem as condições da desigualdade de Markov dadas no <a href="#thm-desigualdade-markov" class="quarto-xref">Teorema&nbsp;1</a>, mas que, além do valor esperado da variável aleatória, também conhecemos sua variância e <span class="math inline">\(\mu_X = E[X]\)</span> e <span class="math inline">\(\sigma^2_X = Var[X]\)</span> são finitos. Fazendo</p>
<p><span class="math display">\[
{g(X) = (X - \mu_X)^2} \quad \textsf{e} \quad {k = \theta^2 \sigma^2_X},
\]</span> para <span class="math inline">\(\theta &gt; 0\)</span>, temos:</p>
<p><span class="math display">\[
{P[|X-\mu_X|\geq \theta\sigma_X] \leq \frac{1}{\theta^2}}
\]</span></p>
<p>ou, equivalentemente: <span class="math display">\[
{P[\mu_X - \theta\sigma_X &lt; X &lt; \mu_X + \theta\sigma_X] \geq 1 - \frac{1}{\theta^2}}
\]</span></p>
<p><strong>Demonstração:</strong></p>
<p>Aplicar <span class="math inline">\(g(X) = (X - \mu_X)^2\)</span> e <span class="math inline">\({k = \theta^2 \sigma^2_X}\)</span> na desigualdade de Markov (<a href="#thm-desigualdade-markov" class="quarto-xref">Teorema&nbsp;1</a>).</p>
</div>
</div>
</div>
</div>
<p>A desigualdade de Chebyshev nos diz que a probabilidade de <span class="math inline">\(X\)</span> se afastar pelo menos <span class="math inline">\(\theta\)</span> desvios-padrão de sua média é, no máximo, <span class="math inline">\(1/\theta^2\)</span>. Alternativamente, a probabilidade de que <span class="math inline">\(X\)</span> esteja a uma distância de sua média menor que <span class="math inline">\(\theta\)</span> desvios é de pelo menos <span class="math inline">\(1 - 1/\theta^2\)</span>.</p>
<p>Assim, a desigualdade de Chebyshev nos diz, em particular, que para qualquer conjunto de dados, independentemente da distribuição de probabilidade associada à v.a. em análise, pelo menos 75% das observações se encontram a uma distância máxima de dois desvios de sua média (para <span class="math inline">\(\theta = 2\)</span>); e pelo menos 89% de todas as observações se encontram a uma distância máxima de três desvios de sua média (para <span class="math inline">\(\theta = 3\)</span>).</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-estoque-markov" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 16 (Planejamento de Estoque)</strong></span> <br></p>
<p>Suponha que a demanda diária por um certo item <span class="math inline">\(X\)</span> tenha distribuição desconhecida, com média de 28 unidades e variância 16. Se quisermos garantir pelo menos 90% de atendimento para a demanda, podemos utilizar as Desigualdades de Markov e Chebyshev para determinar a quantidade de itens que devem ser disponibilizados diariamente.</p>
<p><strong>Solução:</strong></p>
<p>Seja a v.a. <span class="math inline">\(X\)</span> = demanda diária, tal que <span class="math inline">\({\mu = E[X] = 28}\)</span> e <span class="math inline">\({\sigma^2 = Var[X] = 16}\)</span>. Queremos <span class="math inline">\(k\)</span> tal que <span class="math inline">\({P[X \leq k] \geq 0.90}\)</span>, que equivale a <span class="math inline">\({P[X \geq k] \leq 0.10}\)</span>.</p>
<p><em>Pela Desigualdade de Markov:</em></p>
<p><span class="math display">\[\begin{align*}
{P[X \geq k] \leq \frac{E[X]}{k} = \frac{28}{k} = 0.1 \quad \therefore k = 280 \quad \Rightarrow P[X \geq 280] \leq 0.1}
\end{align*}\]</span></p>
<p>Ou seja, chegamos à conclusão de que são necessários 280 itens a fim de que a demanda seja satisfeita em pelo menos 90% das vezes. Note que esse é um limite bastante conservador. Ora, a demanda média diária é de 28 itens e a desigualdade nos pede para disponibilizar uma quantidade 10 vezes maior de itens. No entanto, ela se baseia numa quantidade muito pequena de informação: utilizamos apenas a demanda média, sem nenhuma informação a respeito da variabilidade ou da distribuição dessa variável aleatória.</p>
<p>Já a desigualdade de Chebyshev utiliza a informação da média e da variância. Vejamos, então, como essa informação adicional contribui para uma melhor estimativa da quantidade de itens necessários diariamente.</p>
<p><em>Pela Desigualdade de Chebyshev:</em></p>
<p><span class="math display">\[\begin{align*}
{P[|X -28|\geq m] \leq \frac{Var[X]}{m^2} = \frac{16}{m^2} = 0.1 \quad \therefore m = 4\sqrt{10} \approx 13}\\
{\Rightarrow |X -28| \geq 13 \quad \Rightarrow X \geq 41}.
\end{align*}\]</span></p>
<p>Portanto, chegamos à conclusão de que é necessário disponibilizar pelo menos 41 itens diariamente a fim de atender à demanda em pelo menos 90% das vezes.</p>
<p>Note que a quantidade de itens necessários encontrada é consideravelmente menor que aquela obtida através da desigualdade de Markov. Essa quantidade de 41 itens é suficiente para satisfazer a probabilidade desejada de 90%, independentemente da distribuição da variável aleatória. Se informação adicional a respeito da distribuição puder ser obtida, é de se esperar chegar à conclusão de que um número ainda menor de itens seja suficiente para atender à demanda nas condições consideradas.</p>
</div>
</div>
</div>
</div>
<p>Em síntese, as desigualdades de Markov e Chebyshev nos permitem fazer afirmações probabilísticas quando temos muito pouca informação a respeito de uma variável aleatória. Com essas desigualdades, podemos calcular limites para probabilidades quando conhecemos apenas a média (e também variância, no caso de Chebyshev) de uma v.a.. Embora esses limites sejam amplos ou conservadores, são universalmente válidos, independentemente de suposições específicas a respeito da distribuição da variável aleatória em questão.</p>
<hr>
</section>
</section>
<section id="distribuições-notáveis" class="level1">
<h1>Distribuições Notáveis</h1>
<p>Consideraremos alguns modelos probabilísticos que merecem uma atenção especial. Algumas distribuições aparecem frequentemente em aplicações, por dois motivos:</p>
<ol type="1">
<li><p>ou porque o mecanismo probabilístico que define o problema em análise é tal que uma dessas distribuições é, de fato, a distribuição que descreve a situação de interesse; ou,</p></li>
<li><p>o problema em análise é tal que pode ser adequadamente modelado por uma dessas distribuições (neste caso, o modelo matemático nos dá uma boa aproximação da situação em questão).</p></li>
</ol>
<p>Iniciaremos estudando algumas distribuições associadas aos chamados processos de Bernoulli, que talvez sejam um dos processos aleatórios mais simples.</p>
<section id="distribuições-associadas-a-processos-de-bernoulli" class="level2">
<h2 class="anchored" data-anchor-id="distribuições-associadas-a-processos-de-bernoulli">Distribuições Associadas a Processos de Bernoulli</h2>
<section id="o-experimento-de-bernoulli" class="level3">
<h3 class="anchored" data-anchor-id="o-experimento-de-bernoulli">O Experimento de Bernoulli</h3>
<p>Os processos de Bernoulli são construídos com base em experimentos de Bernoulli. Já encontramos esses experimentos e processos anteriormente, mas ainda não tínhamos dado um nome a eles.</p>
<p>Um experimento de Bernoulli consiste em um experimento aleatório que tem apenas dois resultados possíveis que, por conveniência rotulamos de “sucesso” ou “fracasso”. Como eles são mutuamente exclusivos e coletivamente exaustivos, formam uma partição do espaço amostral. Sucesso ocorre com probabilidade <span class="math inline">\(p\)</span> e, portanto, fracasso (o complementar de sucesso) ocorre com probabilidade <span class="math inline">\(1-p\)</span>.</p>
<p><strong>Experimento de Bernoulli:</strong></p>
<ul>
<li><p>Dois possíveis resultados (mutuamente exclusivos):<br>
<span class="math inline">\(S =\)</span> “sucesso” e <span class="math inline">\(F=\)</span> “fracasso”<br>
Espaço amostral: <span class="math inline">\(\Omega = \{ S, F\}\)</span></p></li>
<li><p>Define-se: <span class="math inline">\(P[S] = p\)</span>, <span class="math inline">\(P[F]= 1-p\)</span></p></li>
</ul>
<p>Obviamente, os rótulos “sucesso” e “fracasso” não necessariamente estão associados a acontecimentos bons ou ruins; temos um sucesso quando observamos a ocorrência do evento de interesse.</p>
<p>O lançamento de uma moeda é um exemplo: posso considerar sucesso, a ocorrência do resultado “cara”. A administração de uma vacina a um paciente é outro exemplo: sucesso pode denotar a imunização do paciente.</p>
<ul>
<li><p>Lançamento de uma moeda:<br>
<span class="math inline">\(S =\)</span> cara, <span class="math inline">\(F =\)</span> coroa</p></li>
<li><p>Administração de uma vacina:<br>
<span class="math inline">\(S =\)</span> paciente imunizado, <span class="math inline">\(F =\)</span> paciente não imunizado</p></li>
</ul>
</section>
<section id="distribuição-de-bernoulli" class="level3">
<h3 class="anchored" data-anchor-id="distribuição-de-bernoulli">Distribuição de Bernoulli</h3>
<p>Em vez de utilizar a notação de eventos, que emprega os rótulos “sucesso” e “fracasso” para representar os resultados do experimento de Bernoulli, podemos utilizar uma variável aleatória para modelar essa situação. A v.a. resultante, então, terá distribuição de Bernoulli.</p>
<p>Uma v.a. <span class="math inline">\(X\)</span> tem distribuição de Bernoulli com parâmetro <span class="math inline">\(p\)</span> se assumir valores 0 ou 1, com probabilidade dada pela fdp <span class="math inline">\(f_X(x)\)</span> abaixo.</p>
<p>Seja a v.a. <span class="math inline">\(X \sim Ber(p)\)</span>:</p>
<p><span class="math inline">\(X =\)</span> resultado do experimento de Bernoulli</p>
<p><span class="math display">\[\begin{align*}
  &amp;{} f_{X}(x) = \left\{
  \begin{array}{rl}
    p^x q^{1-x}, &amp; x=0, 1\\
    0,           &amp; c.c.
  \end{array}\right.
  \quad 0 \leq p \leq 1; \quad q=1-p\\
  \\
  &amp;{} E[X] = p \qquad Var[X] = pq
\end{align*}\]</span></p>
<p>Note que quando <span class="math inline">\(x=0\)</span>, <span class="math inline">\(f_X(x) = q = 1-p\)</span>; e, quando <span class="math inline">\(x=1\)</span>, <span class="math inline">\(f_X(x)= p\)</span>, em que <span class="math inline">\(p\)</span> é a probabilidade de sucesso e assume qualquer valor real entre 0 e 1; e <span class="math inline">\(q\)</span> é probabilidade de fracasso.</p>
<p>É possível mostrar que o valor esperado desta v.a. é <span class="math inline">\(p\)</span> e que a variância vale <span class="math inline">\(pq\)</span>.</p>
<ul>
<li>Muitos modelos probabilísticos importantes são baseados na regra de Bernoulli.</li>
<li>Uma sequência de experimentos de Bernoulli independentes constituem um <strong>Processo de Bernoulli</strong>.</li>
</ul>
<p>Apesar de sua simplicidade, processos de Bernoulli podem ser utilizados para representar processos aleatórios interessantes, como veremos a seguir.</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 17</strong></span> <br></p>
<p>Um aluno realizará um teste que consiste em 10 questões de múltipla escolha, cada uma com 4 opções, das quais apenas uma é correta. O aluno é aprovado no curso se responder pelo menos 6 questões corretamente.</p>
<p>Só que tem um problema: o aluno esqueceu que tinha de fazer esta prova e está completamente despreparado para o exame e decide apelar para a sorte, ou seja, vai escolher as respostas de maneira completamente aleatória, de forma que a resposta escolhida a uma determinada questão não tem relação com as demais.</p>
<p>Se o aluno adotar essa estratégia desesperada, qual a probabilidade de que ele passe no curso?</p>
<p><em>Solução</em></p>
<p>Em primeiro lugar, precisamos identificar a variável aleatória associada a este experimento. Note que a resposta a cada questão consiste em um experimento de Bernoulli, já que o aluno pode marcar a resposta certa (o que equivale a obter sucesso) ou a resposta errada (obtendo, assim, um fracasso). Desta forma, resposta a cada questão pode ser, então modelada por uma v.a. <span class="math inline">\(X_i\)</span>, que tem distribuição de Bernoulli. <span class="math inline">\(X_i\)</span> assume valor 1, se a resposta à questão <span class="math inline">\(i\)</span> é correta; e 0, se a resposta à questão <span class="math inline">\(i\)</span> é errada. A probabilidade de o aluno acertar a resposta de cada uma das questões é sempre a mesma e vale 1/4.</p>
<p>A resposta a cada uma das questões corresponde a um experimento de Bernoulli. Então, para <span class="math inline">\(i = 1, 2, \ldots, 10\)</span>, sejam as v.a.’s:</p>
<p><span class="math display">\[\begin{align*}
X_i = \left\{
  \begin{array}{rl}
    1, &amp; \text{se a i-ésima resposta está correta}\\
    0, &amp; \text{se a i-ésima resposta está errada}
  \end{array}\right.
\end{align*}\]</span></p>
<p>Ainda: <span class="math inline">\(P[X_i = 1] = p = 1/4\)</span>, para <span class="math inline">\(i = 1, 2, \ldots, 10\)</span>.</p>
<p>Mas não estamos interessados em saber se o aluno acertou ou errou cada uma das questões. Estamos interessados no resultado acumulado dos acertos; ou seja, no total de respostas corretas. Portanto, precisamos definir a v.a. que equivale ao total de respostas corretas:</p>
<p><span class="math inline">\(X =\)</span> total de respostas corretas<br>
<span class="math display">\[X = \sum_{i=1}^{10}X_i = k, \quad k = 0, 1, 2, \ldots, 10\]</span></p>
<p>Então, <span class="math inline">\(X\)</span> é igual à soma dos resultados de cada uma das v.a.’s <span class="math inline">\(X_i\)</span>. E esta soma pode assumir um valor <span class="math inline">\(k\)</span> igual a zero, ou 1 ou 2, e assim por diante até 10, correspondendo ao número de acertos no total das 10 questões.</p>
<p>Queremos calcular a probabilidade de que o número de acertos no teste seja maior ou igual a 6: <span class="math inline">\(P[X \geq 6]\)</span></p>
<p>Para calcular esta probabilidade, precisamos seguir o procedimento usual que consiste em calcular a probabilidade de obter cada um dos valores possíveis para a v.a. <span class="math inline">\(X\)</span> (isto é, vamos construir a fdp de <span class="math inline">\(X\)</span>) e, a partir, daí, calcularemos a probabilidade do evento de interesse.</p>
<p>A probabilidade de nenhum acerto corresponde à probabilidade de que a v.a. <span class="math inline">\(X\)</span> assuma valor igual a zero. Isso significa que o aluno errou conjuntamente todas as questões; então cada uma das v.a.’s <span class="math inline">\(X_i\)</span> vai assumir valor zero. Como as respostas para cada questão são dadas de maneira independente, a probabilidade conjunta é igual ao produto das probabilidades individuais. A probabilidade de responder incorretamente a uma questão qualquer é a probabilidade de fracasso, que vale <span class="math inline">\(1-p\)</span>. E assim, chega-se à conclusão de que a probabilidade de o aluno errar todas as questões vale <span class="math inline">\((1-p)^{10}\)</span> que é igual a <span class="math inline">\((3/4)^{10}\)</span>:</p>
<p><span class="math display">\[\begin{align*}
P[X=0]   &amp;= \text{probabilidade de nenhuma resposta correta}\\
         &amp;= P[X_1 = 0, X_2 = 0, \ldots, X_{10}=0],  &amp; \textsf{(sob indep.)} \\
         &amp;= P[X_1 = 0]\cdot P[X_2 = 0]\cdot \ldots \cdot P[X_{10} = 0]\\
         &amp;= (1-p)^{10} = \left(3/4\right)^{10}
\end{align*}\]</span></p>
<p>Vamos calcular agora a probabilidade de marcar apenas uma resposta correta. Precisamos enumerar todas as maneiras de acertar apenas uma resposta, ao responder a 10 questões. Isso significa que ou o aluno acertou apenas a resposta da primeira questão (e errou todas as outras), ou acertou apenas a resposta da segunda questão, e assim por diante, até a última situação possível que corresponde ao aluno ter errado todas as questões, exceto a última. Para cada uma dessas situações, temos um sucesso e 9 fracasso, portanto, cada situação acontece com probabilidade <span class="math inline">\(p \times (1-p)^9\)</span>.</p>
<p>Como existem 10 situações em que apenas um sucesso ocorre, a probabilidade de apenas um acerto em 10 tentativas vale <span class="math inline">\(p \times (1-p)^9 \times 10\)</span>.</p>
<p><span class="math display">\[\begin{align*}
P[X=1]   &amp;= \textsf{probabilidade de apenas uma resposta correta}\\
         &amp;= P[X_1 = 1]\cdot P[X_2 = 0]\cdot \ldots \cdot P[X_{10} = 0]\\
         &amp;+ P[X_1 = 0]\cdot P[X_2 = 1]\cdot \ldots \cdot P[X_{10} = 0]\\
         &amp; \vdots\\
         &amp;+ P[X_1 = 0]\cdot P[X_2 = 0]\cdot \ldots \cdot P[X_{10} = 1]\\
         &amp;= p \cdot (1-p)^9 \cdot 10 = (1/4)\left(3/4\right)^{9}\cdot 10
\end{align*}\]</span></p>
<p>Vamos aplicar o mesmo procedimento para 2 acertos, 3 acertos e assim, sucessivamente.</p>
<p>Sendo assim, a probabilidade de um total de ‘k’ respostas corretas, é dada pela expressão a seguir:</p>
<p><span class="math display">\[\begin{align*}
P[X=k] &amp;= \textsf{probabilidade de exatamente k respostas corretas}\\
       &amp;= {\binom{10}{k}}p^k (1-p)^{10-k}
\end{align*}\]</span></p>
<p>Há diversas maneiras de acertar apenas <span class="math inline">\(k\)</span> questões de um total de 10. Em todas as situações temos <span class="math inline">\(k\)</span> sucessos e <span class="math inline">\(10-k\)</span> fracassos; portanto, a probabilidade de observar cada uma dessas situações vale <span class="math inline">\(p^k \times (1-p)^{10-k}\)</span>; e o número de situações em que <span class="math inline">\(k\)</span> acertos ocorrem em 10 tentativas é dado pela combinação de 10 k-a-k.</p>
<p>Calculando para <span class="math inline">\(k \geq 6\)</span>, precisamos somar as probabilidades de obter ou 6 ou 7 ou 8 ou 9 ou 10 acertos. Essa probabilidade vale:</p>
<p><span class="math display">\[\begin{align*}
P[X\geq 6] &amp;= \textsf{probabilidade de pelo menos 6 respostas corretas}\\
           &amp;= \sum_{k=6}^{10}{\binom{10}{k}}(1/4)^k\left(3/4\right)^{10-k}\\
         &amp;= 0,0197 \quad \approx 2\% \;!!!
\end{align*}\]</span></p>
<p>Então, para a infelicidade deste aluno, chegamos à triste conclusão de que ele tem um pouco menos que 2% de chance de passar no curso, se responder de maneira aleatória a cada uma das questões! Não parece ser uma boa estratégia deixar o resultado da avaliação nas mãos do acaso!</p>
</div>
</div>
</div>
</div>
<p>Um processo de Bernoulli consiste em uma sequência finita ou infinita de experimentos de Bernoulli tal que cada experimento produz um sucesso com probabilidade <span class="math inline">\(p\)</span> e fracasso, com probabilidade <span class="math inline">\(1-p\)</span>’, independentemente do que ocorre nas outras repetições do experimento.</p>
<p>Então, basicamente temos usa sequência de resultados binários aleatórios independentes e estacionários.</p>
<ul>
<li><p>Um experimento de Bernoulli é repetido um certo número de vezes</p></li>
<li><p>Dois resultados possíveis em cada repetição:<br>
S = “sucesso” F = “fracasso”</p></li>
<li><p>Hipótese de Independência</p></li>
<li><p>Hipótese de Estacionariedade<br>
<span class="math inline">\(P[S]= p =\)</span> constante para todos os experimentos</p></li>
</ul>
<p>Podemos estar interessados em diferentes aspectos associados a um processo aleatório de Bernoulli. Cada aspecto pode ser analisado através da definição de uma v.a. aleatória que represente a situação de interesse. Por exemplo, podemos querer responder à pergunta de quantos sucessos serão observados em um determinado número de repetições do experimento de Bernoulli; ou, podemos querer determinar quantos experimentos são necessários a fim de obter um sucesso; ou <span class="math inline">\(k\)</span> sucessos; ou, ainda, podemos estar interessados em determinadas probabilidades condicionais que ocorrem em um processo de Bernoulli. A partir daí, podemos generalizar para situações em que o experimento aleatório tem mais do que dois resultados possíveis.</p>
</section>
<section id="distribuição-binomial" class="level3">
<h3 class="anchored" data-anchor-id="distribuição-binomial">Distribuição Binomial</h3>
<p>A distribuição binomial é, sem dúvida, uma das distribuições discretas mais importantes.</p>
<p>A v.a. <span class="math inline">\(X\)</span> tem distribuição binomial com parâmetros <span class="math inline">\(n\)</span> e <span class="math inline">\(p\)</span> se representa o número de sucessos em <span class="math inline">\(n\)</span> replicações de um experimento de Bernoulli, em que a probabilidade de observar sucesso em cada experimento vale <span class="math inline">\(p\)</span>.</p>
<p>A fdp da v.a. <span class="math inline">\(X\)</span> é dada pela expressão abaixo. A validade desta função para respresentar a probabilidade desejada pode ser verificada notando-se que cada sequência de resultados com <span class="math inline">\(x\)</span> sucessos no total de <span class="math inline">\(n\)</span> tentativas independentes ocorre com probabilidade <span class="math inline">\(p^x \times q^{n-x}\)</span>; esse valor de probabilidade é multiplicado pelo número de tais sequências possíveis, dado pela combinação de <span class="math inline">\(n\)</span> x-a-x.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Seja a v.a. <span class="math inline">\(X \sim \mathit{Bin} (n,p)\)</span>:</p>
<p><span class="math inline">\(X =\)</span> número de sucessos em um processo de Bernoulli</p>
<p><span class="math display">\[\begin{align*}
  &amp;{} f_{X}(x) = \left\{
  \begin{array}{rl}
    \binom{n}{x}p^x q^{n-x}, &amp; x = 0, 1, \ldots, n\\
    0,           &amp; c.c.
  \end{array}\right.
  \quad 0 \leq p \leq 1; \quad q=1-p \\
  \\ \\
  &amp;{} E[X] = np \qquad Var[X] = npq
\end{align*}\]</span></p>
</div>
</div>
</div>
<p>A v.a. <span class="math inline">\(X\)</span> pode assumir qualquer valor inteiro de 0 até o número de experimentos de Bernoulli, <span class="math inline">\(n\)</span>. Como a fdp de uma v.a. Binomial depende apenas dos valores assumidos pelos parâmetros <span class="math inline">\(n\)</span> e <span class="math inline">\(p\)</span>, é de se esperar que sua média e variância também dependam apenas dos valores que esses parâmetros assumem. De fato, o valor esperado de <span class="math inline">\(X\)</span> é dado <span class="math inline">\(np\)</span>, isto é, o número esperado de sucessos esperados em <span class="math inline">\(n\)</span> experimentos de Bernoulli independentes, quando cada sucesso ocorre com probabilidade <span class="math inline">\(p\)</span> é igual a <span class="math inline">\(np\)</span>. A variância de <span class="math inline">\(X\)</span> vale <span class="math inline">\(npq\)</span>.</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 18</strong></span> <br> Se a probabilidade de um paciente se recuperar de uma doença grave for de 40% e tivermos o conhecimento de 15 pacientes portadores dessa doença, podemos estar interessados em obter algumas respostas, tais como:</p>
<ol type="a">
<li>qual a probabilidade de que exatamente 5 dos 15 pacientes sejam curados; ou</li>
<li>qual a probabilidade de que pelo menos 10 deles sobrevivam; ou</li>
<li>qual a probabilidade de que de 2 a 10 pacientes se recuperem.</li>
</ol>
<p>Note que, se pudermos assumir que a resposta de cada paciente ao tratamento da doença seja independente dos demais e que a probabilidade de recuperação seja a mesma para todos os pacientes, estamos diante de um processo de Bernoulli com parâmetros <span class="math inline">\(n = 15\)</span> e <span class="math inline">\(p = 0,4\)</span>.</p>
<p>Podemos então utilizar a distribuição Binomial para calcular essas probabilidades de maneira exata. E vamos comparar este resultado exato com aquele que seria obtido de maneira aproximada utilizando a desigualdade de Chebyshev.</p>
<p><em>Solução:</em></p>
<p>Temos: <span class="math inline">\(X \sim \textsf{Bin}(n,p)\)</span>, onde n = 15 (pacientes); p = 0,4 (probabilidade de cura).</p>
<ol type="a">
<li>P[exatamente 5 pacientes serem curados]:</li>
</ol>
<p>Para responder à primeira questão, basta calcular o valor da fdp de <span class="math inline">\(X\)</span> no ponto <span class="math inline">\(X = 5\)</span>:</p>
<p><span class="math display">\[\begin{align*}
  P[X = 5] = \textsf{Bin}(5; 15; 0,4)  = \binom{15}{5}0,4^5 0,6^{10} = 0,1859
\end{align*}\]</span></p>
<p>Sendo assim, a probabilidade de que exatamente 5 dos 15 pacientes sejam curados vale aproximadamente 19%.</p>
<p>Esse valor de probabilidade pode ser facilmente calculado no R, utilizando o comando dado abaixo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">5</span>, <span class="dv">15</span>, <span class="fl">0.4</span>)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1859378</code></pre>
</div>
</div>
<ol start="2" type="a">
<li>P[pelo menos 10 pacientes sobreviverem]:</li>
</ol>
<p>Para a segunda questão, queremos a probabilidade de observar pelo menos 10 pacientes recuperados. Essa probabilidade pode ser obtida calculando a soma das probabilidades de observar de 10 a 15 sucessos ou, alternativamente, utilizando a noção de complementar, como 1 - probabilidade de observar menos que 10 recuperações, que corresponde à soma das probabilidades de observar apenas de 0 a 9 sucessos. A probabilidade desejada é de aproximadamente 3%:</p>
<p><span class="math display">\[\begin{align*}
  P[X \geq 10] &amp;= 1 - P[X &lt; 10] \\
               &amp;= \sum_{x=10}^{15}\textsf{Bin}(x; 15, 0,4) = 1 - \sum_{x=0}^{9}\textsf{Bin}(x; 15, 0,4) \\
               &amp;= 1 - 0,9662 = 0,0338
\end{align*}\]</span></p>
<p>No R, essa probabilidade pode ser obtida utilizando os seguintes comandos:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pbinom</span>(<span class="dv">9</span>, <span class="dv">15</span>, <span class="fl">0.4</span>)  </span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0338333</code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">dbinom</span>(<span class="dv">10</span><span class="sc">:</span><span class="dv">15</span>, <span class="dv">15</span>, <span class="fl">0.4</span>))</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0338333</code></pre>
</div>
</div>
<ol start="3" type="a">
<li>P[2 a 10 pacientes se recuperarem]:</li>
</ol>
<p>Finalmente, a terceira pergunta envolve o cálculo da probabilidade de que a v.a. <span class="math inline">\(X\)</span> assuma um valor de 2 a 10. Novamente, podemos calcular essa probabilidade como sendo a soma das probabilidades de observar <span class="math inline">\(X\)</span> assumindo valores de 2 a 10, ou podemos utilizar a definição de FDA e calcular essa probabilidade como sendo a diferença entre o valor da FDA para <span class="math inline">\(X=10\)</span> e o valor da FDA para <span class="math inline">\(X=1\)</span>. A probabilidade desejada vale aproximadamente 99%:</p>
<p><span class="math display">\[\begin{align*}
  P[2 \leq X \leq 10]
  &amp;= \sum_{x=2}^{10}\textsf{Bin}(x; 15, 0,4)
   = \sum_{x=0}^{10}\textsf{Bin}(x; 15, 0,4) - \sum_{x=0}^{1}\textsf{Bin}(x; 15, 0,4)\\
  &amp;= 0,9907 - 0,0052 = 0,9855
\end{align*}\]</span></p>
<p>Os comandos utilizados para obter esse valor de probabilidade no R são disponibilizados abaixo.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">dbinom</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">10</span>, <span class="dv">15</span>, <span class="fl">0.4</span>))</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9854803</code></pre>
</div>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pbinom</span>(<span class="dv">10</span>, <span class="dv">15</span>, <span class="fl">0.4</span>) <span class="sc">-</span> <span class="fu">pbinom</span>(<span class="dv">1</span>, <span class="dv">15</span>, <span class="fl">0.4</span>)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9854803</code></pre>
</div>
</div>
<p>Agora, vamos comparar o valor de probabilidade para a última pergunta que foi obtido de maneira exata utilizando a distribuição binomial com o limite que seria definido pela desigualdade de Chebyshev, se não fosse possível utilizar a informação da distribuição da v.a. considerada.</p>
<p>A desigualdade de Chebyshev faz uso do valor esperado e da variância da v.a. Sendo assim, utilizando as propriedades da distribuição binomial o valor esperado de <span class="math inline">\(X\)</span> é dado por <span class="math inline">\(np = 6\)</span>; e a variância vale <span class="math inline">\(npq = 3,6\)</span>. Um intervalo de largura igual a 4 desvios em torno da média, nos dá de 2 a 10 pacientes (já que a v.a. em questão é discreta). Assim, para <span class="math inline">\(X\)</span> a uma distância máxima de dois desvios de sua média, a desigualdade de Chebyshev nos dá o limite inferior de 75% de chance de observar de 2 a 10 pacientes recuperados:</p>
<p><span class="math inline">\(\mu = np =  15 \cdot 0,4 = 6\)</span>;<br>
<span class="math inline">\(\sigma^2 = npq = 15 \cdot 0,4 \cdot 0,6 = 3,6 \Rightarrow \sigma = 1,897\)</span></p>
<p>Consideremos o intervalo: <span class="math inline">\(\mu \pm 2\sigma\)</span> = <span class="math inline">\((2.206, 9.794) \rightarrow (2, 10)\)</span> : dados discretos.</p>
<p><strong>Pela Desigualdade de Chebyshev:</strong></p>
<p>A desigualdade de Chebyshev garante que há pelo menos 75% (3/4) de chance de que 2 a 10 dos 15 pacientes sobrevivam.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Um Problema de Tomada de Decisão
</div>
</div>
<div class="callout-body-container callout-body">
<p>Em geral, usamos distribuições de probabilidade para decidir se uma determinada hipótese é ou não plausível. Nós retornaremos a este assunto mais formalmente em inferência estatística, mas por hora, vejamos um outro exemplo, em que os valores de probabilidade calculados a partir da distribuição binomial são utilizados para auxiliar o processo de tomada de decisão.</p>
<p>Vamos supor que exista uma vacina para um determinado vírus, cuja eficácia seja de apenas 25%. Porém dada a alta transmissibilidade da doença, essa eficácia é insuficiente para conter uma epidemia. Uma nova vacina é oferecida ao Ministério da Saúde (MS) e é preciso decidir se vale a pena comprar a nova vacina. Vamos assumir ainda que, segundo recomendações técnicas, se a vacina tiver eficácia de pelo menos 30%, pode comprar a nova vacina; e, se ela tiver eficácia maior ou igual a 50%, não pode perder a oportunidade de adquirir a nova vacina.</p>
<p>Portanto, antes de mais nada, precisamos determinar se a nova vacina é mais eficaz contra o mesmo vírus que a vacina disponível. Para isso, precisamos coletar evidências empíricas, ou seja, precisamos de dados.</p>
<p>Uma amostra aleatória de <span class="math inline">\(n = 20\)</span> voluntários é selecionada e são observados quantos deles não contraem a doença após o período de avaliação. Claro que esse número de pessoas testadas é completamente irreal e, de maneira alguma, um estudo científico para determinar a eficácia de uma vacina com base em uma amostra tão pequena teria qualquer validade. Usamos esse número tão somente com a finalidade de simplificar os cálculos e ilustrar os procedimentos utilizados no problema de análise de decisão.</p>
<p>Sendo assim, esses voluntários são monitorados de forma que se saiba, ao final do período de avaliação, quantos deles contraíram a doença. Com base na quantidade de indivíduos imunizados, podemos tomar uma decisão mais informada se vale ou não a pena adquirir a nova vacina.</p>
<p>Se assumirmos que a resposta de cada indivíduo é independente da do outro, e que a eficácia das vacinas não varie de indivíduo para indivíduo, estamos diante de um processo de Bernoulli de tamanho 20. Diante disso, espera-se que a vacina atual seja capaz de imunizar em média 25% do total, ou seja 5 indivíduos.</p>
<p>A questão agora é determinar que regra de decisão será utilizada para definir se a vacina nova é melhor ou não que a atual.</p>
<p>Supondo que uma amostra de tamanho 20 seja suficiente para tirarmos conclusões estatisticamente significativas, o que devemos decidir se:</p>
<ul>
<li>20 dos 20 voluntários forem imunizados?<br>
Nesta situação, parece haver evidências de que a vacina nova tem eficácia superior que a atual;</li>
<li>se nenhum dos voluntários tiver sido imunizado e, ao final do período de avaliação, todos tiverem contraído a doença?<br>
Neste caso, as evidências sugerem que a vacina nova seja pior que a atual.</li>
</ul>
<p>Ambas as situações representam casos extremos, em que não é tão difícil assim tomar uma decisão. Há situações, no entanto, em que o processo de tomada de decisão pode assumir um caráter bem mais dramático.</p>
<p>A fim de estruturar o problema com clareza para que possamos calcular os riscos associados às decisões que serão tomadas, precisamos confrontar nossos medos e avaliar <strong>o que se teme mais</strong>:</p>
<ol type="1">
<li>comprar a nova vacina acreditando que ela é mais eficaz que a atual e acabar descobrindo com o tempo que isso não é verdade, ou seja, que a eficácia da vacina é menor que 30%?</li>
</ol>
<p>ou</p>
<ol start="2" type="1">
<li>perder a oportunidade de comprar a vacina mais eficaz e sujeitar a população ao risco de uma grave epidemia?</li>
</ol>
<p>A partir de quantos indivíduos imunizados na amostra, podemos decidir que a nova vacina é mais eficaz que a atual e que, assim, podemos decidir comprá-la?</p>
<p>Vamos considerar algumas decisões possíveis:</p>
<p>D1: Compra se observar pelo menos 8 indivíduos imunizados<br>
D2: Compra se observar pelo menos 9 indivíduos imunizados<br>
D3: Compra se observar pelo menos 10 indivíduos imunizados</p>
<p>A decisão D1 consiste em comprar se pelo menos 8 voluntários da amostra tiverem sido imunizados; a decisão D2 é um pouco mais rigorosa e nos leva a comprar a nova vacina se pelo menos 9 voluntários tiverem sido imunizados e, por fim, a decisão D3 que recomenda a compra apenas se pelo menos a metade dos indivíduos da amostra tiver sido imunizada.</p>
<p>Suponha que o decisor tenha optado por D2. Podemos errar ao tomar essa decisão de 2 maneiras e os erros de decisão são chamados <strong>erro do tipo I</strong> e <strong>erro tipo II</strong>.</p>
<p>No erro tipo I, somos levados a crer, a partir das evidências empíricas, que a nova vacina é mais eficaz que a atual, quando ela de fato, não o é. Ou seja, segundo a regra de decisão D2, observamos um número maior que 8 indivíduos imunizados na amostra, mas esse resultado deveu-se meramente ao acaso, pois a vacina administrada não era mais eficaz que a atual.</p>
<p>Já no erro tipo II, temos uma perda de oportunidade, isto é, a vacina é, na realidade melhor que a atual, mas não tivemos evidência disso na amostra coletada, pois apenas um número menor ou igual a 8 dos voluntários foi imunizado.</p>
<p><strong>Resumo:</strong></p>
<p><img src="img/vaccine-decision-table.png" class="img-fluid" style="width:80.0%"></p>
<p>Temos o estado real da natureza: ou a nova vacina não é suficientemente boa (o que quer dizer que sua eficácia é menor ou igual a 30%), ou ela é melhor que a atual (isto é, sua eficácia é maior que 50%). No entanto, esse estado real da natureza é desconhecido e precisaremos tomar uma decisão com base nas evidências que conseguirmos obter a partir da observação de uma amostra. A decisão será por não comprar a nova vacina, se não tivermos evidências de uma eficácia superior; e a decisão será por comprar a nova vacina, se formos levados a crer que a nova vacina é mais eficaz que a atual. Erramos quando as evidências empíricas não apontam para o estado real da natureza. Sendo assim, erramos quando decidimos comprar a vacina nova e ela não é mais eficaz que a atual (por que as evidências empírica nos levaram a acreditar que a vacina era boa) e erramos quando decidimos não comprar a nova vacina e ela é, de fato, melhor que a atual (por que não fomos capazes de perceber este fato empiricamente).</p>
<p>Os erros do tipo I e II normalmente não são simétricos. Sempre há um que é mais temido que o outro. Formulamos o problema de decisão associando o erro tipo I ao erro mais grave, ou seja, aquele que trará as piores consequências.</p>
<p>Vamos, então, calcular as probabilidades de cometer cada um desses erros.</p>
<p>Cometemos erro tipo I se decidimos compra a vacina nova quando não deveríamos. Então, utilizando a regra de decisão D2, o erro tipo I vai acontecer quando observarmos na amostra um número maior que 8 indivíduos imunizados, quando a eficácia da vacina nova é, na melhor das hipóteses igual a 30%. Portanto, a probabilidade de cometer erro tipo I é dada pela probabilidade condicional de observar <span class="math inline">\(X &gt; 8\)</span> dado que <span class="math inline">\(p = 0,3\)</span>.</p>
<p>Utilizando a distribuição binomial com parâmetros <span class="math inline">\(n = 20\)</span> e <span class="math inline">\(p = 0,3\)</span>, calculamos o risco de cometer erro tipo I, que é da ordem de 11%:</p>
<p><span class="math display">\[\begin{align*}
  P[\text{Erro Tipo I}]
    &amp;= P[\text{comprar quando não deveria}] \\
    &amp;= P [X &gt; 8 | p \leq 0,30]\\
    &amp;= P [X &gt; 8 | p  = 0,30] &amp;: \text{pior caso}\\
    &amp;= 1 - \sum_{x=0}^{8} \binom{20}{x} p^x (1-p)^{(20-x)}\\
    &amp;= 1 - 0,8867 = 0,1133
\end{align*}\]</span></p>
<p>Isso significa que, toda vez que decidirmos comprar a nova vacina, em aproximadamente 11% das vezes estaremos fazendo a coisa errada.</p>
<p>Por outro lado, cometemos erro tipo II se decidimos não comprar a vacina nova quando deveríamos. Isso ocorre quando os resultados empíricos não nos dão evidências da superioridade da eficácia da nova vacina, e observamos na amostra um número menor ou igual a 8 indivíduos imunizados, quando na verdade a eficácia da vacina nova era, no pior caso, igual a 50%. A probabilidade de cometer erro tipo II é dada pela probabilidade condicional de observar <span class="math inline">\(X \leq 8\)</span> dado que <span class="math inline">\(p = 0,5\)</span>. Utilizando a distribuição binomial com parâmetros <span class="math inline">\(n=20\)</span> e <span class="math inline">\(p=0,5\)</span>, chegamos à conclusão de que o risco de cometer erro tipo II é da ordem de 25%.</p>
<p><span class="math display">\[\begin{align*}
  P[\textsf{Erro Tipo II}]
    &amp;= P [\text{não comprar quando deveria}] \\
    &amp;= P [X \leq 8 | p &gt; p_o]\\
    &amp;= P [X \leq 8 | p  = 0,5] &amp;: \text{pior caso}\\
    &amp;= \sum_{x=0}^{8} \binom{20}{x} p^x (1-p)^{(20-x)}\\
    &amp;= 0,2517
\end{align*}\]</span></p>
<p>Neste caso, em cerca de 25% das vezes que recusarmos a nova vacina, estaremos rejeitando um produto melhor que o atual.</p>
<p>Esses riscos calculados estão associados à regra de decisão adotada. Estamos dispostos a correr esses riscos?</p>
<p>Vejamos como variam os riscos de cometer erros do tipo I e do tipo II, se optarmos por outras regras de decisão.</p>
<p>Procedendo de maneira análoga para as decisões D1 e D3, podemos completar a seguinte tabela que mostra os riscos associados a cada uma das decisões:</p>
<p><img src="img/vaccine-decisoes.png" class="img-fluid" style="width:60.0%"></p>
<p>Note que ao tomar uma decisão mais rigorosa, ou seja, quando decidimos comprar a vacina nova apenas com evidências mais contundentes, como no caso da regra de decisão D3, nosso risco de comprar uma vacina de eficácia duvidosa cai de 11% para um pouco menos de 5%. No entanto, o rigor também tem seu preço. Ao utilizar essa regra de decisão, o risco de perder uma boa oportunidade aumenta de 25% para cerca de 41%.</p>
<p>Por outro lado, se nos permitimos convencer da eficácia da vacina nova com base em evidências menos robustas, o risco de cometer erro tipo I aumenta de 11% para quase 23%, enquanto o risco de cometer erro tipo II cai de 25% para aproximadamente 13%.</p>
<p>Algumas lições importantes que devemos levar deste exemplo são as seguintes: qualquer que seja a decisão tomada, sempre há riscos envolvidos, pois a informação de que dispomos é incompleta e imperfeita. E, assim, não é possível ter certeza de que estamos tomando a decisão correta. Para que a decisão seja a melhor possível, é necessário definir qual o erro mais temido, ou seja, que erro produz as consequências mais graves que deveriam ser evitadas; e, por fim, é necessário definir de antemão qual o risco máximo tolerado para cada tipo de erro de decisão que se pode cometer, pois esses limites ajudam a balizar as decisões a serem tomadas.</p>
</div>
</div>
</section>
</section>
<section id="distribuições-associadas-a-processos-de-poisson" class="level2">
<h2 class="anchored" data-anchor-id="distribuições-associadas-a-processos-de-poisson">Distribuições Associadas a Processos de Poisson</h2>
<p>Anteriormente, estudamos algumas distribuições associadas aos chamados processos de Bernoulli, formados por sequências de experimentos aleatórios independentes, para os quais há apenas dois resultados possíveis, rotulados “sucesso” e “fracasso”, de forma que a probabilidade de “sucesso” é a mesma para todos os experimentos. Estes processos aleatórios foram estudados por muitos matemáticos como Jakob Bernoulli I, Abraham de Moivre, entre muitos outros.</p>
<p>Na primeira metade do século XIX, o matemático francês Siméon-Denis Poisson, (1781-1840) analisou uma longa sequência de experimentos de Bernoulli (ou seja, em que <span class="math inline">\(n\)</span> é grande), para os quais a probabilidade <span class="math inline">\(p\)</span> de sucesso em cada experimento era muito pequena. Assim, encontrou uma forma limite para a distribuição Binomial que recebeu seu nome, ficando conhecida como distribuição de Poisson.</p>
<section id="uma-aproximação-para-a-distribuição-binomial" class="level3">
<h3 class="anchored" data-anchor-id="uma-aproximação-para-a-distribuição-binomial">Uma aproximação para a Distribuição Binomial</h3>
<p>Vamos considerar uma v.a. <span class="math inline">\(X\)</span> que tem distribuição Binomial com parâmetros <span class="math inline">\(n\)</span> e <span class="math inline">\(p\)</span>, tal que <span class="math inline">\(n\)</span> é muito grande ( <span class="math inline">\(n \rightarrow \infty\)</span> ) e <span class="math inline">\(p\)</span> muito pequeno ( <span class="math inline">\(p \rightarrow 0\)</span> ), de forma que o número esperado de sucessos <span class="math inline">\(\lambda = np\)</span>, seja constante.</p>
<p>Substituindo <span class="math inline">\(p\)</span> por <span class="math inline">\(\lambda/n\)</span>, é possível escrever a probabilidade de observar <span class="math inline">\(x\)</span> sucessos como segue:</p>
<p><span class="math display">\[\begin{align*}
  X \sim \mathit{Bin}(n, p): \quad P[X = x] &amp;= \frac{n!}{(n-x)!x!} p^x (1-p)^{n-x}\\
           &amp;= \frac{n!}{(n-x)!x!} \left(\frac{\lambda}{n}\right)^x \left(1-\frac{\lambda}{n}\right)^{n-x}\\
           &amp;= \frac{n(n-1)\ldots(n-x+1)}{n^x} \frac{\lambda^x}{x!} \frac{(1- \lambda/n)^n}{(1- \lambda/n)^x}\\
  \begin{array}{l}
    n \rightarrow \infty, \; p \rightarrow 0\\
    np \stackrel{n \rightarrow \infty}{\longrightarrow}\lambda = cte.
  \end{array}&amp;\longrightarrow \frac{\lambda^x}{x!}e^{-\lambda}\\\\
\end{align*}\]</span></p>
<p>Vamos analisar os termos da expressão para <span class="math inline">\(P[X=x]\)</span>, ao se manter <span class="math inline">\(x\)</span> e <span class="math inline">\(\lambda\)</span> constantes e fazendo <span class="math inline">\(n\)</span> tender ao infinito <span class="math inline">\(n\rightarrow \infty\)</span>:</p>
<ul>
<li>o termo <span class="math inline">\(n/n\)</span> é exatamente igual a 1;<br>
</li>
<li>cada um dos termos <span class="math inline">\(n-1/n\)</span>, <span class="math inline">\(n-2/n\)</span>, até <span class="math inline">\((n-x+1)/n\)</span> tende a 1;<br>
</li>
<li>o limite de <span class="math inline">\((1 - \lambda/n)^n\)</span> quando <span class="math inline">\(n \rightarrow \infty\)</span> é o limite exponencial fundamental e, portanto, este limite vai a <span class="math inline">\(e^{-\lambda}\)</span>; e, finalmente,</li>
<li>o denominador <span class="math inline">\((1 - \lambda/n)^x\)</span> tem limite igual a 1 quando <span class="math inline">\(n \rightarrow \infty\)</span>, já que <span class="math inline">\(\lambda\)</span> e <span class="math inline">\(x\)</span> são mantidos constantes.</li>
</ul>
<p>Portanto, a probabilidade de observar exatamente <span class="math inline">\(x\)</span> sucessos em uma longa sequência de experimentos de Bernoulli tende a <span class="math inline">\((\lambda^x/x!) e^{-\lambda}\)</span>. Esta é a chamada distribuição de Poisson. Note que ela depende apenas do produto <span class="math inline">\(\lambda = np\)</span>, não de <span class="math inline">\(n\)</span> e <span class="math inline">\(p\)</span>, separadamente. Esta aproximação é válida quando <span class="math inline">\(np \approx 5\)</span>, ou seja, quando <span class="math inline">\(n\geq 50\)</span> e <span class="math inline">\(p \leq 0.1\)</span>, ou <span class="math inline">\(n \geq 100\)</span> e <span class="math inline">\(p \leq 0.05\)</span>. Se estivermos diante de uma situação em que a probabilidade de sucesso é muito elevada, próxima de um, basta inverter os rótulos “sucesso” e “fracasso” e a aproximação continua sendo válida, claro!</p>
</section>
<section id="distribuição-de-poisson" class="level3">
<h3 class="anchored" data-anchor-id="distribuição-de-poisson">Distribuição de Poisson</h3>
<p>Uma v.a. <span class="math inline">\(X\)</span> com distribuição de Poisson com parâmetro <span class="math inline">\(\lambda &gt; 0\)</span> tem fdp dada por:</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Seja a v.a. <span class="math inline">\(X \sim Pois(\lambda)\)</span></p>
<p><span class="math inline">\(X =\)</span> no. de ocorrências em uma longa sequência de experimentos de Bernoulli.</p>
<p><span class="math display">\[\begin{align*}
  &amp;{} f_{X}(x) = \left\{
  \begin{array}{rl}
    \frac{\lambda^x}{x!} e^{-\lambda}, &amp; x = 0, 1, \ldots\\
    0,           &amp; c.c.
  \end{array}\right.
  \quad \lambda &gt; 0
  \\ \\
  &amp;{} E[X] = \lambda \qquad Var[X] = \lambda
\end{align*}\]</span></p>
</div>
</div>
</div>
<p>A v.a. de Poisson modela o número de sucessos em uma longa sequência de experimentos de Bernoulli, em que a chance de sucesso em cada experimento é muito pequena. Sendo assim, sua distribuição pode ser entendida como descrição do número de ocorrências de um evento raro, quando se submete a uma grande exposição ao fenômeno que produz tais eventos.</p>
<p>Como modela a contagem de um número de ocorrências, a v.a. <span class="math inline">\(X\)</span> pode assumir qualquer valor inteiro não negativo. A média, ou o número esperado de ocorrências, é dado pela constante <span class="math inline">\(\lambda\)</span>, que é o mesmo valor da variância desta v.a.</p>
<p>A distribuição de Poisson pode ser utilizada também para modelar os chamados “never events”, que consistem em erros médicos que nunca deveriam ocorrer, como por exemplo, realizar uma cirurgia na parte errada do corpo do paciente, ou trocar mãe e bebê em uma maternidade.</p>
<p>Esta distribuição foi desenvolvida por Poisson em 1837 em um livro que escreveu, mostrando o uso de teoria de probabilidades em aplicações jurídicas, embora o próprio Poisson nunca mais tenha apresentado este resultado em qualquer de suas numerosas publicações matemáticas.</p>
<p>A distribuição de Poisson começou a ganhar notoriedade apenas depois da publicação, em 1898, de um trabalho desenvolvido pelo estatístico russo Ladislaus Bortkiewicz (1868-1931), que mostrou pela primeira vez como esta distribuição poderia ser utilizada para explicar a regularidade estatística observada na ocorrência de certos eventos raros, como nós veremos no exemplo a seguir.</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 19</strong></span> <br> No final do século XIX, unidades de cavalaria estavam presentes em grande parte dos exércitos e, vez por outra, alguém em uma dessas unidades acabava morrendo como consequência de um coice de cavalo recebido. Bortkiewicz registrou as ocorrências de tais mortes para 14 unidades de cavalaria do exército prussiano durante o período de 20 anos de 1875 a 1894, obtendo um total de 280 observações, e analisou os dados estatisticamente.</p>
<p>A chance de um soldado ser morto por um coice de cavalo em um determinado ano era extremamente baixa, mas como o número de soldados nas unidades era muito grande, o número de mortes deveria seguir a distribuição de Poisson. Os dados coletados por Bortkiewicz são apresentados na tabela apresentada a seguir. A primeira coluna corresponde ao número de mortes observadas; a segunda coluna registra a frequência observada para cada quantidade de mortes. O total de mortes registrado é de 196 (que corresponde a <span class="math inline">\(91 \times 1 + 32 \times 2 + 11 \times 3 + 2 \times 4\)</span> ), portanto o número de mortes por unidade por ano é 196/280 = 0.7. Bortkiewicz utilizou esse valor como uma estimativa para <span class="math inline">\(\lambda\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/prussian-cavalry-horse-kick-table.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption>Fonte: Bortkewitsch, L (1898). <em>Das Gesetz der kleinen Zahlen</em>. In: Bulmer, MG. (1979) <em>Principles of Statistics</em>, Dover Publications.</figcaption>
</figure>
</div>
</div>
</div>
<p>A coluna com as frequências esperadas foi obtida utilizando <span class="math inline">\(\lambda = 0,7\)</span> no cálculo das probabilidades que seriam obtidas a partir da distribuição de Poisson (multiplicando cada valor por 280). Então, o valor 139 corresponde à probabilidade de não observar nenhuma morte (que vale aproximadamente 49,7%) vezes 280. Os outros valores são obtidos de maneira análoga. Você pode tentar realizar o exercício de calcular os outros valores da coluna. Se calcularmos a variância para os dados observados temos um valor igual a 0,75 (o que é compatível com a distribuição de Poisson). Note a semelhança entre os valores observados e os valores estimados utilizando o modelo matemático.</p>
<p>De fato, é possível testar a hipótese de que os dados seguem a distribuição de Poisson e chegar à conclusão de que não há diferença estatisticamente significativa entre os valores estimados e os valores observados. E isto foi feito por um dos grandes nomes da Estatística do século XX, Sir Ronald Fisher, que foi o primeiro a demonstrar quantitativamente a adequação do modelo probabilístico de Poisson a este conjunto de dados, utilizando o teste de aderência Qui-quadrado.</p>
</div>
</div>
</div>
</div>
<p>A distribuição de Poisson é uma das mais importantes na prática, devido à sua ampla aplicação nas mais diversas áreas científicas que incluem genética, astronomia, geologia, finanças e muitas outras, além de grande importância na análise de sistemas de filas, presentes em sistemas de produção, logística, transporte, comunicação, entre tantos outros. Alguns exemplos de situações que podem ser satisfatoriamente modeladas pela v.a. de Poisson incluem: o número de mensagens de email que chegam a um servidor; o número de pessoas que chegam a um estabelecimento comercial; o número de asteróides que atingem o planeta terra (pode ser analisado com relação ao domínio do tempo ou localização); o número de imperfeições em um material; a quantidade de organismos em uma quantidade de fluido, e assim, por diante.</p>
<p>Basicamente, cada uma dessas situações e inúmeras outras podem ser modeladas aproximadamente por uma distribuição de Poisson pelo mesmo motivo: o fato de a distribuição de Poisson ser uma aproximação para a distribuição Binomial.</p>
</section>
<section id="o-processo-de-poisson" class="level3">
<h3 class="anchored" data-anchor-id="o-processo-de-poisson">O Processo de Poisson</h3>
<p>A distribuição de Poisson também pode ser utilizada para modelar a contagem de “sucessos” ocorrendo em um outro tipo de processo aleatório, chamado Processo de Poisson. Diferentemente de um processo de Bernoulli, em que a contagem se dava em um domínio discreto, em um processo de Poisson as ocorrências se dão em um domínio contínuo (que pode ser tempo, comprimento, área, volume etc). Por conveniência (e sem perda de generalidade), vamos analisar o caso em que observamos certas ocorrências de um fenômeno de interesse no tempo.</p>
<p>Vamos ilustrar um processo de Poisson considerando a seguinte situação: Suponha que observamos a chegada de pessoas a um local onde se encontra um caminhão pipa que fornece água para famílias de uma certa localidade. Vamos registrar o número de famílias que chegam a esse posto num determinado período de tempo, que pode ser, por exemplo, um dia.</p>
<p>Historicamente, sabe-se que, <em>em média</em>, 10 famílias costumam buscar água neste local diariamente. O caminhão tem capacidade de abastecer no máximo 15 famílias. Então, se houver uma demanda superior a 15, as famílias excedentes terão que ser redirecionadas a outro local.</p>
<p><em>Qual a probabilidade de que, em um determinado dia, algumas famílias tenham que ser desviadas para outro posto?</em> Portanto, queremos determinar a probabilidade de que a demanda exceda a capacidade de atendimento do posto.</p>
<p>Então, estamos monitorando o processo de chegada de pessoas a este posto e podemos facilmente imaginar que esse processo não é completamente previsível. Podemos considerar que as famílias chegam ao local em instantes aleatórios, <span class="math inline">\(T_1, T_2, T_3 \ldots\)</span> , durante o intervalo de tempo <span class="math inline">\((0, t]\)</span> que, no nosso caso, corresponde ao período de operação diária do caminhão pipa. As ocorrências no tempo podem ser representadas da seguinte maneira:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="img/processo-poisson-tempo.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p>Vamos considerar uma <em>ocorrência</em> como sendo a chegada de uma família até o posto e vamos iniciar a contagem das ocorrências no instante <span class="math inline">\(t = 0\)</span>. O número de ocorrências <span class="math inline">\(N(t)\)</span> é um processo estocástico de contagem se satisfaz às condições apresentadas a seguir.</p>
<p>Se iniciamos a contagem de ocorrências no instante de tempo igual a 0, então o número <span class="math inline">\(N(t)\)</span> de ocorrências registradas no instante <span class="math inline">\(t\geq0\)</span> é o resultado de um processo aleatório <span class="math inline">\(\{N(t): t \geq 0\}\)</span>, tal que:</p>
<ul>
<li><span class="math inline">\(N(0) = 0\)</span><br>
</li>
<li><span class="math inline">\(N(t) \in \{0, 1, 2, \ldots\}\)</span><br>
</li>
<li><span class="math inline">\(u &lt; t \Rightarrow N(u) \leq N(t)\)</span></li>
</ul>
<p>Portanto, onúmero de ocorrências no instante inicial é igual a zero, o que, para o nosso exemplo, significa que não há famílias esperando no posto antes de iniciar o período de operação do caminhão pipa; o número de ocorrências em cada instante de tempo <span class="math inline">\(t\)</span> é um número inteiro não negativo; e para um determinado instante <span class="math inline">\(u\)</span> anterior ao instante <span class="math inline">\(t\)</span>, o número de ocorrências no instante <span class="math inline">\(u\)</span> será menor ou igual ao número de ocorrências no instante <span class="math inline">\(t\)</span>.</p>
<p>Sejam <span class="math inline">\(t, s &gt;0\)</span> instantes quaisquer após o instante inicial <span class="math inline">\(t_0 = 0\)</span>:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="img/processo-poisson-tempo-2.png" class="img-fluid figure-img" style="width:60.0%"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>o intervalo <span class="math inline">\((0,t]\)</span> tem comprimento <span class="math inline">\(t\)</span>;<br>
</li>
<li>o intervalo <span class="math inline">\((t, t+s]\)</span> tem comprimento <span class="math inline">\(s\)</span>; de forma que<br>
</li>
<li>o número de ocorrências entre os instantes <span class="math inline">\(t\)</span> e <span class="math inline">\(t+s\)</span> vale <span class="math inline">\(N(t+s) - N(t)\)</span>.</li>
</ul>
<p>Um processo estocástico de contagem apresenta incrementos independentes quando o número de ocorrências em intervalos disjuntos são independentes e apresenta incrementos estacionários quando o número de ocorrências em um intervalo só depende do comprimento do intervalo. Um dos processos estocásticos de contagem mais importantes é o <strong>Processo de Poisson</strong>, que apresenta as seguintes características:</p>
<ul>
<li><p><strong>(Homogeneidade, estacionariedade fraca)</strong> A probabilidade de exatamente uma ocorrência em um pequeno intervalo de comprimento <span class="math inline">\(h\)</span> é aproximadamente proporcional ao comprimento do intervalo: <span class="math display">\[P[N(h) = 1] = \lambda h + o(h); \qquad \lim_{h \rightarrow 0}  \frac{o(h)}{h} = 0\]</span></p></li>
<li><p>A probabilidade de <strong>mais de uma ocorrência</strong> em um pequeno intervalo de comprimento <span class="math inline">\(h\)</span> é desprezível: <span class="math display">\[P[N(h) &gt; 1] = o(h)\]</span></p></li>
<li><p><strong>(Independência, ausência de memória)</strong> O número de ocorrências em qualquer intervalo de comprimento <span class="math inline">\(h\)</span> é independente do histórico de ocorrências em outros instantes fora deste intervalo.</p></li>
</ul>
<p>Portanto, um processo de contagem aleatório é um Processo de Poisson se é possível assumir que:</p>
<ol type="i">
<li><p>a probabilidade de observar <em>exatamente uma ocorrência</em> em um pequeno intervalo de comprimento <span class="math inline">\(h\)</span> é aproximadamente proporcional ao comprimento desse intervalo, de forma que, para pequenos valores de <span class="math inline">\(h\)</span>, essa probabilidade vale <span class="math inline">\(\lambda h\)</span> mais algo que é muito menor se comparado a <span class="math inline">\(h\)</span> ( <span class="math inline">\(\lambda\)</span> é a constante de proporcionalidade, chamada de taxa do processo e a função <span class="math inline">\(o(h)\)</span> é uma função nula, que vai mais rapidamente para zero que <span class="math inline">\(h\)</span> );</p></li>
<li><p>a probabilidade de observar duas ou mais ocorrências em um pequeno intervalo é desprezível, o que significa que a probabilidade de duas ou mais ocorrências simultâneas é nula; e, finalmente,</p></li>
<li><p>as ocorrências se dão de maneira independente, de forma que o que quer que aconteça em determinado intervalo, isto não tem efeito probabilístico em outros intervalos não sobrepostos a este.</p></li>
</ol>
<p>Sob essas condições, precisamos determinar, para qualquer valor de <span class="math inline">\(k\)</span>, a probabilidade de <strong>exatamente</strong> <span class="math inline">\(k\)</span> ocorrências em um intervalo de comprimento <span class="math inline">\(t+h\)</span>:</p>
<p><span class="math display">\[P_k(t+h) = P[N(t+h) = k]\]</span></p>
<p>Façamos, então, para <span class="math inline">\(k=0\)</span>, <span class="math inline">\(k=1\)</span> e, assim, sucessivamente.</p>
<ul>
<li>Para <span class="math inline">\(k = 0\)</span>:</li>
</ul>
<p><span class="math display">\[\begin{align*}
  P_0(t+h) &amp;= P[\text{nenhuma ocorrência no intervalo } (0, t+h]]\\
           &amp;= P[\text{nenhuma ocorrência em } (0, t] \cap
                \text{nenhuma ocorrência em } (t, t+h] ]\\
  \stackrel{\text{(indep.)}}{}
           &amp;= P[\text{nenhuma ocorrência em } (0, t]] \cdot  
              P[\text{nenhuma ocorrência em }(t, t+h]]\\  
           &amp;= P_0(t) \cdot P_0(h)
\end{align*}\]</span></p>
<p>Mas,</p>
<p><span class="math display">\[\begin{align*}
  P_0(h)  &amp;= P[\text{nenhuma ocorrência no intervalo } (t, t+h]]\\
          &amp;= 1 - P [\text{pelo menos uma ocorrência em }(t, t+h]]\\
          &amp;= 1 - P[\text{exatamente uma ocorrência em } (t, t+h]] \\
          &amp; \phantom{= 1\;}- P[\text{pelo menos duas ocorrências em }(t, t+h]]\\
          &amp;= 1 - \lambda h - o(h) - o(h)
\end{align*}\]</span></p>
<p>Portanto,</p>
<p><span class="math display">\[\begin{align*}
  P_0(t+h) &amp;= P_0(t) \cdot P_0(h)  \\
           &amp;= P_0(t) \cdot (1 - \lambda h - o(h) - o(h))\\
           &amp;= P_0(t) - \lambda h P_0(t) - P_0(t) (o(h) + o(h))\\
\end{align*}\]</span></p>
<p>Dividindo toda a expressão por <span class="math inline">\(h\)</span>:</p>
<p><span class="math display">\[\frac{P_0(t+h) - P_0(t)}{h} = - \lambda P_0(t) - P_0(t) \frac{o(h) + o(h)}{h}\]</span></p>
<p>Tomando o limite quando <span class="math inline">\(h \rightarrow 0:\)</span></p>
<p><span class="math display">\[\lim_{h \rightarrow 0} \frac{P_0(t+h) - P_0(t)}{h} = - \lambda P_0(t)\]</span> Obtemos:</p>
<p><span class="math inline">\(P_0^\prime(t) = - \lambda P_0(t)\)</span></p>
<p>Sob a condição inicial <span class="math inline">\(P_0(0) = 1\)</span>, esta é uma equação diferencial cuja solução é:</p>
<p><span class="math display">\[P_0(t) = e^{-\lambda t}\]</span> Analogamente,</p>
<ul>
<li>Para <span class="math inline">\(k = 1\)</span>:</li>
</ul>
<p><span class="math display">\[\begin{align*}
  P_1(t+h) &amp;= P_1(t)\cdot P_0(h) + P_0(t)\cdot P_1(h)\\
           &amp;= P_1(t)(1 - \lambda h - o(h)) + P_0(t)(\lambda h + o(h))\\   
\end{align*}\]</span></p>
<p>Que leva à equação diferencial:</p>
<p><span class="math inline">\(P_1^\prime(t) = - \lambda P_1(t) + \lambda P_0(t)\)</span></p>
<p>Cuja solução, sob a condição inicial <span class="math inline">\(P_1(0) = 0\)</span>, é:</p>
<p><span class="math display">\[P_1(t) = (\lambda t) e^{-\lambda t}\]</span></p>
<p>É possível mostrar que:</p>
<p><span class="math inline">\(P_k^\prime(t) = - \lambda P_k(t) + \lambda P_{k-1}(t), \quad\)</span> para <span class="math inline">\(k = 2, 3, \ldots\)</span></p>
<p>Este sistema de equações diferenciais tem solução:</p>
<p><span class="math display">\[P_k(t) = \frac{(\lambda t)^k}{k!} e^{-\lambda t}\]</span></p>
<p>Se <span class="math inline">\(P[N(t)=k]:\)</span> probabilidade de exatamente <span class="math inline">\(k\)</span> ocorrências em um intervalo de tempo qualquer de comprimento <span class="math inline">\(t\geq 0\)</span></p>
<p>então: <span class="math display">\[\sum_{k=0}^\infty P[N(t)=k] = 1,\]</span> ou seja, em cada intervalo de comprimento <span class="math inline">\(t\)</span>, devemos ter exatamente ou 0, ou 1, ou 2 etc ocorrências.</p>
<p>Note que <span class="math inline">\(P[N(t)=k]\)</span> é fdp com relação a <span class="math inline">\(k\)</span>, mas não é fdp com relação a <span class="math inline">\(t\)</span>. Podemos garantir apenas que: <span class="math display">\[0 \leq \int_{t=0}^\infty P[N(t)=k] dt &lt; \infty\]</span></p>
<p>A distribuição de probabilidade para o número de ocorrências em um intervalo de tempo de comprimento <span class="math inline">\(t\)</span> é dada por:</p>
<p><span class="math display">\[P[X = k] = \frac{(\lambda t)^k}{k!} e^{-\lambda t}\]</span> Portanto, para o exemplo de motivação, definindo a v.a.</p>
<p><span class="math inline">\(X =\)</span> no. de famílias que chegam ao posto a uma taxa <span class="math inline">\(\lambda = 10\)</span>/dia; <span class="math inline">\(t=1\)</span> dia.</p>
<p>A probabilidade de que algumas famílias precisem ser desviadas para outro local é igual à probabilidade de que mais do que 15 famílias cheguem ao local em um dia. Utilizando o complementar, essa probabilidade é igual a 1 - a probabilidade de <span class="math inline">\(X \leq 15\)</span>, que vale aproximadamente 5%:</p>
<p><span class="math display">\[\begin{align*}
P[X &gt; 15] = 1 - P[X \leq 15] = 1 - \sum_{x=0}^{15}\frac{e^{-\lambda}}{x!}\lambda^x
          = 1 - 0,9513 = 0,0487 \approx 5\%
\end{align*}\]</span></p>
<p>Como acabamos de ver, um processo de Poisson consiste em um experimento em que ocorrências de um determinado fenômeno aleatório que possui certas características especiais se dão em um domínio contínuo. A v.a. de Poisson é utilizada para modelar o número dessas ocorrências.</p>
<p>Agora, suponha que uma dessas ocorrências tenha apenas sido observada. Por exemplo, uma família tenha acabado de chegar ao posto onde se encontra o caminhão pipa. O que podemos afirmar sobre o tempo de espera até a chegada da próxima família? Podemos perceber que se as chegadas acontecem de maneira aleatória, de forma que o instante dessas ocorrências é também uma variável aleatória. Portanto, resta determinar qual a distribuição do tempo de espera até observar a próxima ocorrência em um Processo de Poisson? Este aspecto do processo de Poisson é modelado pela distribuição Exponencial.</p>
</section>
</section>
<section id="distribuição-normal" class="level2">
<h2 class="anchored" data-anchor-id="distribuição-normal">Distribuição Normal</h2>
<p>Diferentemente das distribuições notáveis que estudamos até agora, a distribuição normal não foi construída como um modelo para uma situação aleatória bem definida; pelo contrário, trata-se de um modelo teórico, ou seja, consiste em uma abstração matemática. Ainda assim, a distribuição normal é uma das distribuições mais importantes para a Estatística, pois é útil para representar diversos fenômenos aleatórios que se manifestam no mundo real, além de modelar adequadamente a distribuição de probabilidades de estatísticas comumente utilizadas para realizar inferência.</p>
<section id="mais-uma-aproximação-para-a-distribuição-binomial" class="level3">
<h3 class="anchored" data-anchor-id="mais-uma-aproximação-para-a-distribuição-binomial">…(Mais) Uma Aproximação para a Distribuição Binomial</h3>
<p>Vimos anteriormente que perguntas do tipo “qual a probabilidade de obter <span class="math inline">\(k\)</span> resultados favoráveis em <span class="math inline">\(n\)</span> repetições de um experimento de Bernoulli”, poderiam ser respondidas utilizando a distribuição binomial, segundo a expressão matemática a seguir</p>
<p><span class="math display">\[P[X = k] = \frac{n!}{(n-k)!k!} p^k (1-p)^{n-k}\]</span></p>
<p>O problema é que quando o número <span class="math inline">\(n\)</span> de repetições do experimento de Bernoulli é grande, o cálculo dessa probabilidade torna-se proibitivamente intenso sem o auxílio de uma calculadora ou de outras ferramentas computacionais.</p>
<p>Abraham De Moivre (1667-1754) foi o primeiro a chegar à formulação matemática da distribuição normal, ainda no século XVIII. Com a revogação do Édito de Nantes em 1865 pelo rei Luis XIV, estima-se que cerca de 200 a 900 mil protestantes franceses tenham deixado o país nas duas décadas seguintes. Esta lei tinha sido promulgada quase um século antes e conferia liberdade religiosa aos huguenotes. Com o fim da garantia de liberdade religiosa na França, De Moivre se viu forçado a buscar exílio na Inglaterra onde, mesmo sendo um país protestante, não se viu livre de sofrer preconceito por causa de sua origem francesa. Por conta disso, embora fosse um matemático talentoso, além de ter conexões importantes (ele foi amigo pessoal de Edmond Halley, Isaac Newton e James Stirling), De Moivre nunca conseguiu um emprego permanente e ganhava a vida precariamente trabalhando como tutor de matemática e prestando consultoria aos apostadores que frequentavam os cafés de Londres. Estes jogadores geralmente estavam interessados em responder a perguntas do tipo “qual a probabilidade de obter 60 ou mais caras em 100 lançamentos de uma moeda honesta?”. Vimos que probabilidades deste tipo podem ser calculadas de maneira exata utilizando a distribuição binomial dada na expressão matemática apresentada acima. A ocupação de De Moivre exigia que ele frequentemente realizasse esses penosos cálculos de probabilidades envolvendo a distribuição binomial.</p>
<p>De Moivre notou que conforme o número <span class="math inline">\(n\)</span> de repetições do experimento Bernoulli aumentava, a distribuição do número total de sucessos se aproximava de uma curva suave.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="MB751_AULA02_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p>Se ele apenas fosse capaz de encontrar uma formulação matemática para esta curva, poderia calcular de maneira muito mais rápida as probabilidades de interesse. E foi exatamente isso o que ele fez em 1733, e a expressão matemática que desenvolveu para representar essa curva é o que hoje chamamos de <strong>distribuição Normal</strong>.</p>
<p>Uma v.a. <span class="math inline">\(X\)</span> com distribuição Normal com parâmetros <span class="math inline">\(\mu\)</span> e <span class="math inline">\(\sigma\)</span> tem fdp dada pela expressão abaixo:</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Seja a v.a. <span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span>:</p>
<p><span class="math display">\[\begin{align*}
  &amp; f_{X}(x) =  \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}, \begin{array}{rl} &amp; -\infty &lt; x  &lt; \infty\\
               &amp; \mu \in \mathcal{R}, \; \sigma &gt; 0.
  \end{array}
  \\ \\ \\
  &amp; E[X] = \mu \qquad Var[X] = \sigma^2
\end{align*}\]</span></p>
</div>
</div>
</div>
<p>Esta densidade define, na verdade, uma família de distribuições já que cada distribuição corresponde a uma das infinitas combinações possíveis de valores para os parâmetros <span class="math inline">\(\mu\)</span> e <span class="math inline">\(\sigma\)</span>. O valor esperado da distribuição normal é <span class="math inline">\(\mu\)</span> e a variância é e <span class="math inline">\(\sigma^2\)</span>, ou seja, temos uma distribuição completamente determinada pelo primeiro momento e o segundo momento central, que correspondem às duas medidas descritivas mais utilizadas: localização e dispersão.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="MB751_AULA02_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p>A família de distribuições normais é formada por curvas simétricas em forma de sino, cuja moda (a abcissa que corresponde ao ponto de máximo) coincide com a média e também com a mediana, que correspondem ao ponto de simetria da distribuição, <span class="math inline">\(\mu\)</span>.</p>
<p>A curva normal possui dois pontos de inflexão dados por <span class="math inline">\(\mu - \sigma\)</span> e <span class="math inline">\(\mu + \sigma\)</span>, ou seja, são os pontos que se encontram a uma distância de um desvio da média (na figura, esses pontos são representados pelas retas pontilhadas coloridas), que definem aproximadamente 2/3 da área sob cada uma das curvas.</p>
<p>A curva normal tende assintoticamente a zero conforme se afasta do valor médio, o que significa que valores próximos à média são observados com grande frequência e raramente ocorrem valores afastados do centro.</p>
<p>Como é uma fdp, a área total sob da curva normal vale 1. E o achatamento da curva depende do valor do parâmetro <span class="math inline">\(\sigma\)</span>; quanto maior o valor de <span class="math inline">\(\sigma\)</span>, maior o espalhamento e, assim, mais achatada é a curva.</p>
<p>Esta é, sem dúvida, a família de distribuições de probabilidades mais importante para a Estatística por vários motivos: primeiro, porque muitos fenômenos encontrados no mundo real tem comportamento aleatório pelo menos aproximadamente normal; segundo, e mais importante, devido às suas características matemáticas, grande parte da teoria de inferência estatística paramétrica se baseia na distribuição normal; muitas variáveis aleatórias de interesse, incluindo diversas estatísticas comumente utilizadas para realizar inferência possuem distribuições que podem ser aproximadas por uma curva normal.</p>
<p>De fato, uma das primeiras aplicações da distribuição normal foi na análise de erros de medidas em observações astronômicas, devidos a imperfeições dos instrumentos e também dos observadores. Ainda no século XVII, Galileu Galilei (1564-1642) notou que esses erros eram geralmente simétricos e que erros de pequena magnitude ocorriam com maior frequência que erros muito grandes. Esta conjectura levou ao desenvolvimento de inúmeras distribuições candidatas para representar o comportamento aleatório dos erros, mas foi somente no início do século XIX que Carl Friedrich Gauss (1777-1855) chegou independentemente à formulação matemática da distribuição normal, ao perceber que tais erros seguiam essa distribuição. No entanto, por não ter desenvolvido uma prova que considerasse válida, em 1809 Gauss publicou o resultado como uma nota de fim de capítulo de um livro sobre a teoria do movimento de corpos celestes (<em>Teoria Motus Corporum Celestium</em>). E assim a descoberta ficou por um tempo esquecida.</p>
<p>O resgate da distribuição normal deveu-se a Laplace, que demonstrou uma versão mais geral do resultado de De Moivre. Enquanto De Moivre tinha mostrado que o número de sucessos em um processo de Bernoulli de tamanho <span class="math inline">\(n\)</span> tinha distribuição aproximadamente normal, apoiando-se no resultado de Gauss, Laplace chegou em 1810 à mesma conclusão, com respeito ao total ou à media das observações, independentemente da distribuição dessas observações.</p>
<p>Em outras palavras, ele mostrou que mesmo que uma variável aleatória não seguisse a distribuição normal, as médias de amostras retiradas dessa população teriam distribuição aproximadamente normal e essa aproximação seria tão melhor quanto maior o tamanho da amostra. Este resultado, de extrema importância para a Estatística, é o chamado <em>Teorema do Limite central</em>, que estudaremos mais adiante. O Teorema do Limite central, por exemplo, fornece o alicerce teórico para a evidência empírica de que, na prática, muitos fenômenos aleatórios naturais seguem, pelo menos de maneira aproximada, a distribuição normal.</p>
<p>Devido às grandes contribuições de Gauss e Laplace para sua formulação matemática, a distribuição normal é também conhecida como distribuição Gaussiana ou distribuição de Gauss-Laplace. O termo “normal” seria cunhado por Karl Pearson apenas no início do século XX.</p>
</section>
<section id="cálculo-de-probabilidades" class="level3">
<h3 class="anchored" data-anchor-id="cálculo-de-probabilidades">Cálculo de Probabilidades</h3>
<p>Como a distribuição normal é contínua, podemos calcular probabilidades associadas a intervalos de valores que a v.a. pode assumir. Sendo assim,</p>
<p><span class="math display">\[P[x_1 &lt; X &lt; x_2] = \frac{1}{\sqrt{2\pi}\sigma} \int_{x_1}^{x_2} exp\left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right]dx\]</span></p>
<p>que corresponde à probabilidade de que <span class="math inline">\(X\)</span> assuma valores no intervalo que vai de <span class="math inline">\(x_1\)</span> a <span class="math inline">\(x_2\)</span> corresponde à área sombreada na figura abaixo, de forma que é necessário calcular a integral da fdp de <span class="math inline">\(X\)</span> de <span class="math inline">\(x_1\)</span> até <span class="math inline">\(x_2\)</span>. Lembre-se ainda que podemos calcular essa área como a diferença entre os valores da função distribuição acumulada nesses dois pontos.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="MB751_AULA02_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p>No entanto, as integrais da densidade normal não podem ser resolvidas analiticamente, de forma que os valores de probabilidade associados a essa distribuição podem ser obtidos de maneira aproximada, através de valores tabelados, ou, ainda podem ser facilmente calculados com o auxílio de pacotes estatísticos computacionais, como o R.</p>
</section>
<section id="padronização-1" class="level3">
<h3 class="anchored" data-anchor-id="padronização-1">Padronização</h3>
<p>Na impossibilidade de utilização de algum software estatístico, a padronização é um recurso importante para o cálculo de probabilidades envolvendo a distribuição Normal. A padronização consiste em uma transformação de escala e origem da variável aleatória, de forma que a v.a. transformada tem média zero e variância unitária. Assim, diz-se que a v.a. foi padronizada. A v.a. resultante é adimensional. Note que essa transformação pode ser aplicada a qualquer variável aleatória.</p>
<p>A v.a. <em>normal padronizada</em> tem distribuição normal com média zero e variância igual a 1 e é representada pela letra <span class="math inline">\(Z\)</span>. Para esta v.a., temos valores tabelados para sua distribuição, de forma a tornar possível calcular valores de probabilidade associados qualquer distribuição da família de distribuições normais.</p>
<p><span class="math display">\[\begin{align*}
  X \sim N(\mu, \sigma^2) \quad \Longrightarrow \quad
  &amp; Z = \frac{X - \mu}{\sigma} \sim N(\mu_Z = 0, \sigma_Z^2 = 1)\\
  &amp; \varphi(z) = f_Z (z) = \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}z^2}\\
  &amp; \Phi(z) = F_Z(z) = P[Z \leq z], \; \forall z \in \Re
\end{align*}\]</span></p>
<p>Utilizamos <span class="math inline">\(varphi(z)\)</span> e <span class="math inline">\(\Phi(z)\)</span> para representar, respectivamente, a fdp e a FDA da v.a. normal padronizada.</p>
<p>Como a distribuição normal é simétrica, as áreas nas extremidades dos quantis <span class="math inline">\(-z_\alpha\)</span> e <span class="math inline">\(z_\alpha\)</span> são iguais e valem <span class="math inline">\(\alpha\)</span>. Consequentemente, a área interior delimitada pelos quantis <span class="math inline">\(-z_\alpha/2\)</span> e <span class="math inline">\(z_\alpha/2\)</span> vale <span class="math inline">\(1 - \alpha\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="MB751_AULA02_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p>Da simetria:</p>
<ul>
<li><span class="math inline">\(P[X \leq -z_\alpha] = P[Z \geq z_\alpha] = \alpha\)</span><br>
</li>
<li><span class="math inline">\(P[-z_{\alpha/2} &lt; Z &lt; z_{\alpha/2}] = 1 - \alpha\)</span></li>
</ul>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 20</strong></span> <br> A tabela de distribuição normal nos dá as probabilidades acumuladas, ou seja, no miolo da tabela temos os valores de <span class="math inline">\(P[Z \leq z] = \Phi(z)\)</span>. Podemos utilizá-la para calcular valores de probabilidades:</p>
<ol type="a">
<li><span class="math inline">\(P[Z \leq 1.25] = \Phi(1.25)\)</span></li>
</ol>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="img/distr-normal-a.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p>Para determinar o valor desta probabilidade, procuro na vertical a unidade e a primeira casa decimal do quantil desejado (1,2) e na horizontal, o valor da segunda casa decimal (0,05). O valor na interseção de linha e coluna corresponde ao valor de probabilidade acumulada para esse quantil.</p>
<p>Essa probabilidade pode ser facilmente obtida utilizando o comando abaixo no software R.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="fl">1.25</span>)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.8943502</code></pre>
</div>
</div>
<ol start="2" type="a">
<li><span class="math inline">\(P[Z &gt; 1.25] = 1- P[Z \leq 1.25] = 1 - \Phi(1.25)\)</span></li>
</ol>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="img/distr-normal-b.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p>Precisamos calcular a área correspondente à cauda superior. Então, como a tabela dá a área acumulada, preciso calcular o complementar daquilo que nos é dado na tabela:</p>
<p><span class="math inline">\(P[Z &gt; 1.25] = 1 - P[Z ≤ 1.25] = 1 - \Phi(1.25) = 1 - 0.8944  = 0.1056\)</span></p>
<p>Podemos calcular essa probabilidade com o auxílio do software R, de acordo com o comando fornecido abaixo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="fl">1.25</span>)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1056498</code></pre>
</div>
</div>
<ol start="3" type="a">
<li><span class="math inline">\(P[Z \leq - 1.25] =  \Phi(-1.25) = 1 - \Phi(1.25)\)</span></li>
</ol>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="img/distr-normal-c.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p>Precisamos calcular a área correspondente à cauda inferior correspondente ao quantil -1,25. Mas, como as margens da tabela só me dão quantis positivos, é necessário utilizar-se da simetria da distribuição normal: sabemos que a área à esquerda do quantil -1,25 é igual à área à direita do quantil 1,25, portanto:</p>
<p><span class="math inline">\(P[Z ≤ -1.25] =  P[Z &gt; 1.25] = 1 - P[Z ≤ 1.25] = 1 - \Phi(1.25) = 0.1056\)</span> (igual ao mesmo valor de probabilidade do item anterior, claro!)</p>
<p>Novamente, é recomendável utilizar o software R para calcular essa probabilidade, de acordo com o comando fornecido abaixo.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">1.25</span>)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1056498</code></pre>
</div>
</div>
<ol start="4" type="a">
<li><span class="math inline">\(P[-0.38 \leq Z \leq 1.25] =  \Phi(1.25) - \Phi(-0.38) = \Phi(1.25) + \Phi(0.38) - 1\)</span></li>
</ol>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="img/distr-normal-d.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p>Finalmente, queremos a probabilidade de que <span class="math inline">\(Z\)</span> esteja no intervalo que vai de -0,38 a 1,25. Então, podemos subtrair as duas áreas acumuladas:</p>
<p><span class="math inline">\(P[Z ≤ 1.25] - P[Z ≤ -0.38]\)</span></p>
<p>Como não temos na tabela os quantis negativos, é necessário expressar <span class="math inline">\(P[Z ≤ -0.38]\)</span> em termos do quantil positivo 0,38, com base na simetria da distribuição.</p>
<p>Então,<br>
<span class="math inline">\(P[Z ≤ -0.38] = P[Z &gt; 0.38] = 1 - P[Z ≤ 0.38]\)</span></p>
<p>Portanto,</p>
<p><span class="math inline">\(P[-0.38 ≤ Z ≤ 1.25] = \Phi(1.25)  + \Phi(0.38) - 1\)</span></p>
<p>O software R novamente simplifica muito o cálculo desta probabilidade, bastando utilizar o comando dado abaixo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="fl">1.25</span>) <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">0.38</span>)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5423775</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="regra-empírica" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="regra-empírica">Regra Empírica</h3>
<p>Comumente estamos interessados em determinar a probabilidade de que uma v.a. assuma valores a uma certa distância de <span class="math inline">\(k\)</span> desvios-padrão de sua média. Tais limites são conhecidos como <em>limites de tolerância</em>.</p>
<p>Vimos anteriormente que a Desigualdade de Chebyshev nos permite determinar limites inferiores para esses valores de probabilidade, qualquer que seja a distribuição da v.a., quando conhecemos apenas o valor esperado e a variância da v.a.</p>
<p>Qualquer distribuição normal, independentemente dos valores assumidos por seus parâmetros <span class="math inline">\(\mu\)</span> e <span class="math inline">\(\sigma\)</span>, possui a mesma probabilidade a uma distância fixa, dada em termos de número de desvios de sua média.</p>
<p><span class="math display">\[\begin{align*}
  X \sim N(\mu, \sigma^2) \quad \Longrightarrow \quad
  &amp;Z \sim N(0,1):\\
  &amp;P[|X -\mu| \leq k\sigma] = P[|Z| \leq k], \quad \forall k&gt;0
\end{align*}\]</span></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/distr-normal-regra-empirica.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>Para a distribuição normal, 68% (ou seja aproximadamente 2/3) das observações encontram-se a uma distância de 1 desvio-padrão de sua média; 95% das observações se encontram dentro dos limites de aproximadamente -2 a +2 desvios da média e, finalmente 99,7% (ou quase a totalidade) das observações se encontra a uma distância de 3 desvios da média. Sendo assim, espera-se que apenas cerca de 0,3% de todos os valores se encontrem a uma distância da média superior a três desvios. Então, embora o suporte da distribuição normal seja toda a reta real, na prática, a largura da distribuição normal é seis sigma.</p>
<p>A associação dos valores de probabilidade 68, 95 e 99,7 da distribuição normal aos respectivos fatores-k é chamada de <em>Regra Empírica</em>, exatamente por causa da grande utilização da distribuição normal para representar a distribuição das observações obtidas empiricamente nas mais diversas aplicações práticas.</p>
<p>Como curiosidade, veja como esses limites se comparam com aqueles obtidos através da Desigualdade de Chebyshev, em que os mesmos valores de probabilidade são garantidos para intervalos muito mais largos.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/distr-normal-regra-empirica-tabela.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="coeficiente-de-variação" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="coeficiente-de-variação">Coeficiente de Variação</h3>
<p>A distribuição normal é frequentemente utilizada para modelar vas que assumem apenas valores positivos (como área, altura, peso, distância, entre outras). O problema é que o suporte da distribuição normal é a reta real, o que significa que a v.a. normalmente distribuída pode assumir qualquer valor real, positivo ou negativo.</p>
<p>Como podemos contornar essa dificuldade?</p>
<p>Precisamos garantir que a probabilidade de observar um valor negativo seja desprezível. A regra de bolso nos diz que isso ocorre quando o coeficiente de variação, dado pela razão entre o desvio-padrão e a média, <span class="math inline">\(\sigma\)</span> sobre <span class="math inline">\(\mu\)</span> é menor que 0,3.</p>
<p><span class="math display">\[CV = \frac{\sigma}{\mu} &lt;  0,3\]</span></p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 21</strong></span> <br></p>
<p>Peças em projeto aeronáutico comumente são unidas através de rebitagem. O cliente define a especificação do diâmetro dos rebites em 3,0 <span class="math inline">\(\pm\)</span> 0,01 mm. Qualquer rebite cujo diâmetro se encontre dentro da especificação será aceitável.</p>
<p>Considerando o diâmetro dos rebites uma v.a. normalmente distribuída com média <span class="math inline">\(\mu =\)</span> 3,0 e desvio-padrão <span class="math inline">\(\sigma =\)</span> 0,005, que proporção de rebites será rejeitada?</p>
<p><em>Solução:</em></p>
<p>São aceitáveis os rebites cujos diâmetros se encontram no intervalo (2,99; 3,01).<br>
Portanto, queremos a probabilidade de rejeitar um determinado rebite, dada por:<br>
1 - P[2,99 &lt; X &lt; 3,01]</p>
<p>Solução Manual:</p>
<ol type="1">
<li>Padronizar a v.a. para uso da tabela normal ( <span class="math inline">\(\mu=\)</span> 3 e <span class="math inline">\(\sigma =\)</span> 0,005):<br>
<span class="math inline">\(z_1\)</span> = (2,99 - µ)/σ = -2.0 <span class="math inline">\(\quad z_2\)</span> = (3,01 - µ)/σ = 2.0<br>
</li>
<li>Buscar na tabela valores de probabilidade:<br>
P[Z &lt; <span class="math inline">\(z_1\)</span> ] = 0,02275 e P[Z &lt; <span class="math inline">\(z_2\)</span> ] = 0,97725<br>
</li>
<li>Probabilidade desejada:<br>
1 - P[2,99 &lt; X &lt; 3,01] = 1 - P[-2 &lt; Z &lt; 2] = 1 - (0,97725 - 0,02275) = 0,0455 <span class="math inline">\(\quad \therefore \quad \approx\)</span> 4,55%</li>
</ol>
<p>Portanto, espera-se que em média 4,55% dos rebites sejam rejeitados.</p>
<p>No R, é possível calcular esta probabilidade utilizando o comando abaixo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> (<span class="fu">pnorm</span>(<span class="fl">3.01</span>, <span class="at">mean =</span> <span class="dv">3</span>, <span class="at">sd =</span> <span class="fl">0.005</span>) <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="fl">2.99</span>, <span class="at">mean =</span> <span class="dv">3</span>, <span class="at">sd =</span> <span class="fl">0.005</span>))</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.04550026</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="aproximação-para-distribuições-discretas" class="level2">
<h2 class="anchored" data-anchor-id="aproximação-para-distribuições-discretas">Aproximação para Distribuições Discretas</h2>
<p>A distribuição Normal comumente é utilizada para aproximar distribuições discretas simétricas. No entanto, como a distribuição normal é <em>contínua</em>, é necessário incluir uma correção para levar em conta a continuidade da distribuição. Essa correção é necessária toda as vezes que aproximamos uma população discreta por uma distribuição contínua.</p>
<p>Essa correção foi proposta por Augustus de Morgan em 1838, na tentativa de aperfeiçoar a aproximação de De Moivre para a distribuição Binomial, com base na ideia de que cada probabilidade binomial deveria ser interpretada como uma área de base unitária.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="MB751_AULA02_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p>Seja <span class="math inline">\(X \sim p_X(x)\)</span> a v.a. discreta de interesse. A distribuição de <span class="math inline">\(X\)</span> é representada pelo histograma.</p>
<p>Queremos calcular a probabilidade: <span class="math inline">\(P[i \leq X \leq j], \quad i &lt; j;\; i,j \in \mathcal{Z}\)</span></p>
<ol type="i">
<li><p>Do histograma, pode-se determinar esta probabilidade de maneira .stand-out[extata], calculando-se:<br>
<span class="math display">\[P[i \leq X \leq j] = \sum_{x=i}^j p_X(x)\]</span></p></li>
<li><p>Suponha <span class="math inline">\(f_X(x)\)</span> uma boa aproximação para <span class="math inline">\(p_X(x)\)</span>. A fim de calcular a probabilidade associada à v.a. discreta a partir da aproximação pela função contínua <span class="math inline">\(f_X(x)\)</span>, a área sob a curva contínua precisa ser obtida através da integral entre os limites <span class="math inline">\(i\)</span> e <span class="math inline">\(j\)</span> desejados, com o acréscimo de 1/2 (a metade da base) em cada direção:<br>
<span class="math display">\[P[i \leq X \leq j] = \int_{x=i-1/2}^{j+1/2} f_X(x) dx\]</span></p></li>
</ol>
<section id="aproximação-para-a-distribuição-binomial" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="aproximação-para-a-distribuição-binomial">Aproximação para a Distribuição Binomial</h3>
<p>Como De Moivre demonstrou, uma v.a. binomial com parâmetros <span class="math inline">\(n\)</span> e <span class="math inline">\(p\)</span> pode ter sua distribuição satisfatoriamente aproximada pela distribuição Normal para valores elevados de <span class="math inline">\(n\)</span>; isto é, para <span class="math inline">\(n ≥ 30\)</span> e quando ambos os produtos <span class="math inline">\(np\)</span> e <span class="math inline">\(nq\)</span> valem pelo menos 5:</p>
<p><span class="math inline">\(X \sim Bin (n, p)\)</span></p>
<p>Se <span class="math inline">\(n \geq 30; \; np \geq 5; \; nq \geq 5\)</span>:</p>
<p><span class="math display">\[X \sim Bin(n, p) \longrightarrow N(\mu = np, \sigma^2 = npq) \\ \frac{X - np}{\sqrt{npq}} \stackrel{\cdot}{\sim} N(0,1)\]</span></p>
<p>Nestas circunstâncias, a distribuição binomial apresenta forma de sino, com média <span class="math inline">\(pq\)</span> e variância <span class="math inline">\(npq\)</span>, de forma que, ao aplicar a transformação de padronização à v.a. <span class="math inline">\(X\)</span>, a distribuição da v.a. resultante é aproximadamente normal padronizada.</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 22</strong></span> <br> Companhias aéreas costumam praticar “overbooking”, vendendo um número de passagens superior ao número de assentos disponíveis na aeronave, a fim de maximizar seu retorno, já que existe a expectativa de que nem todos os passageiros se apresentem na hora do embarque. Tais passageiros são classificados como “no-show”.</p>
<p>Suponha que tenham sido emitidas 200 passagens para um voo com capacidade para 197 passageiros e que a taxa de “no-show” para este voo seja de 2%.</p>
<p>Qual a probabilidade de que haja <em>overbooking</em> para este voo, de forma que nem todos os passageiros que se apresentarem para embarque poderão viajar?</p>
<p><em>Solução:</em></p>
<p>Se considerarmos que os passageiros viajam sozinhos, sem acompanhantes, e que chegaram de maneira independente ao aeroporto, podemos modelar o número de “shows”, isto é, o número de passageiros que se apresentam para o embarque como uma v.a. com distribuição Binomial, com parâmetros <span class="math inline">\(n= 200\)</span> e <span class="math inline">\(p = 0.98\)</span>:</p>
<p><span class="math inline">\(X =\)</span> número de “shows” (passageiros que se apresentam para embarque)<br>
<span class="math inline">\(p =\)</span> probabilidade de “show” <span class="math inline">\(= 1 - 0,02 = 0,98\)</span></p>
<p>Portanto: <span class="math inline">\(X \sim Bin ( n = 200, p = 0,98 )\)</span></p>
<p>Queremos calcular a probabilidade de que o número de “shows” seja maior que a capacidade do voo, que vale 197: <span class="math inline">\(P[X &gt; 197]\)</span></p>
<p>Dadas as características do problema, podemos resolvê-lo de diferentes maneiras. Primeiro, vamos considerar a solução analítica exata, utilizando a distribuição Binomial.</p>
<p><strong>Cálculo exato utilizando a Distribuição Binomial:</strong></p>
<p>Neste caso, precisamos somar os valores de probabilidade binomial para valores de <span class="math inline">\(X\)</span> que vão de 198 a 200. Fazendo isto, chegamos à conclusão de que há aproximadamente 23,5% de chance de overbooking.</p>
<p><span class="math inline">\(P[X &gt; 197] = \sum_{x=198}^{200} Bin (x, n, p) = \sum_{x=198}^{200}  \frac{n!}{(n-x)!x!} p^x (1-p)^{n-x} = \ldots\)</span><br>
<span class="math inline">\(\approx 23.5\%\)</span></p>
<p>Os cálculos são facilmente realizados com o auxílio do software R, utilizando qualquer dos comandos alternativos dados abaixo.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">dbinom</span>(<span class="dv">198</span><span class="sc">:</span><span class="dv">200</span>, <span class="at">size =</span> <span class="dv">200</span>, <span class="at">prob =</span> <span class="fl">0.98</span>))  </span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2351481</code></pre>
</div>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pbinom</span>(<span class="dv">200</span>, <span class="dv">200</span>, <span class="fl">0.98</span>) <span class="sc">-</span> <span class="fu">pbinom</span>(<span class="dv">197</span>, <span class="dv">200</span>, <span class="fl">0.98</span>)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2351481</code></pre>
</div>
</div>
<p><strong>Utilizando a Aproximação Normal:</strong></p>
<p>Já que o número de passagens vendidas é elevado, podemos tentar utilizar a aproximação para uma distribuição Normal com média <span class="math inline">\(\mu = np = 196\)</span> e variância igual <span class="math inline">\(npq\)</span>:</p>
<p><span class="math inline">\(\mu = np = 200 \times 0.98 = 196\)</span><br>
<span class="math inline">\(\sigma = \sqrt{npq} = \sqrt{200 \times 0.98 \times 0.02} = 1.98\)</span></p>
<p>Para que a aproximação seja adequada, precisamos verificar as condições de que <span class="math inline">\(np\)</span> e <span class="math inline">\(nq\)</span> sejam ambos maiores que 5. Estas condições garantem que a distribuição binomial seja simétrica, com forma aproximada de sino:</p>
<p><span class="math inline">\(np = 200 \times 0.98 = 196; \quad nq = 200 \times 0.02 = 4\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="MB751_AULA02_files/figure-html/unnamed-chunk-21-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p>Para este exemplo, a distribuição binomial não é simétrica. Veja no gráfico, como a cauda da distribuição binomial (em cinza) é mais curta à direita. Ainda assim, prosseguiremos.</p>
<p>Ao aproximar a distribuição binomial (que é discreta) pela distribuição normal (que é contínua), precisamos realizar a correção para a continuidade.</p>
<p>Desejamos calcular a probabilidade <span class="math inline">\(P[X &gt; 197]\)</span> (sinalizada em azul no gráfico). Portanto, o quantil considerado para a aproximação normal deverá ser de <span class="math inline">\(197 + 1/2\)</span>. Padronizando este valor, temos o escore-z (que corresponde ao quantil da distribuição normal padronizada) dado por <span class="math inline">\(z_2\)</span>:</p>
<p><span class="math inline">\(x_2 = 197 + 0.5 = 197.5 \\ \Rightarrow \; Z \sim N(0, 1): \qquad z_2 = \frac{(197.5 - 196)}{1.98} = 0.7576\)</span></p>
<p>Portanto,<br>
<span class="math display">\[P[X &gt; 197] \approx P[Z &gt; z_1] = 1 - \Phi(z_1)  \approx 22.4\%,\]</span></p>
<p>ou seja, a probabilidade desejada vale aproximadamente 22,4% e pode ser obtida numericamente no software R utilizando o comando fornecido abaixo.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="fl">197.5</span>, <span class="at">mean =</span> <span class="dv">196</span>, <span class="at">sd =</span> <span class="fl">1.98</span>)  <span class="co"># com correção para continuidade</span></span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2243525</code></pre>
</div>
</div>
<p>Esta aproximação apresenta erro da ordem de 1 ponto percentual com relação ao valor exato calculado a partir da distribuição Binomial, devido à inadequação do ajuste.</p>
<p><strong>Utilizando a Aproximação de Poisson:</strong></p>
<p>Podemos também aproximar a distribuição Binomial pela distribuição de Poisson quando <span class="math inline">\(n\)</span> é grande e <span class="math inline">\(p\)</span> é pequeno. Neste caso, vamos aproximar a distribuição do número de passageiros que não se apresentam para o embarque, que será representado pela v.a. <span class="math inline">\(Y\)</span>. Para cada passageiro, esta probabilidade é <span class="math inline">\(q\)</span> e vale 0,02. Portanto, o parâmetro da distribuição de Poisson correspondente é <span class="math inline">\(\lambda = nq = 4\)</span>:</p>
<ul>
<li><span class="math inline">\(Y \sim Pois(\lambda)\)</span>: número de “no-shows”</li>
<li>Condição: <span class="math inline">\(\lambda = nq = 200 \times 0.02 = 4\)</span></li>
</ul>
<p>Sendo assim, para que haja <em>overbooking</em>, o número de “no-shows” deve ser menor ou igual a 2 e, portanto, a probabilidade desejada segundo a aproximação de Poisson vale cerca de 23,8%, conforme mostram os cálculos abaixo.</p>
<p><span class="math inline">\(P[X &gt; 197] \approx P[Y \leq 2] = \sum_{x=0}^{2} Pois (x, \lambda = nq) =\ldots \approx 23.8\%\)</span></p>
<p>Este valor de probabilidade é obtido utilizando o software R através do seguinte comando:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">dpois</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">lambda =</span> <span class="dv">4</span>))</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2381033</code></pre>
</div>
</div>
<p>Veja graficamente a semelhança das duas distribuições. Neste exemplo, a distribuição de Poisson se mostrou uma aproximação mais adequada que a distribuição Normal. A área sombreada em azul, representa a probabilidade de interesse calculada.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="MB751_AULA02_files/figure-html/unnamed-chunk-24-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p><strong>Utilizando Simulação:</strong></p>
<p>Podemos ainda estimar essa probabilidade via simulação. Para isso, basta gerar uma grande quantidade de realizações da v.a. Binomial, com parâmetros <span class="math inline">\(n = 200\)</span> e <span class="math inline">\(p = 0,98\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>Nsim <span class="ot">&lt;-</span> <span class="dv">1000</span> <span class="co"># no. de voos simulados</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>Nrep <span class="ot">&lt;-</span> <span class="dv">100</span>  <span class="co"># no. de replicações</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>simula_voo <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rbinom</span>(Nsim<span class="sc">*</span>Nrep, <span class="at">size =</span> <span class="dv">200</span>, <span class="at">prob =</span> <span class="fl">0.98</span>),</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>                     <span class="at">ncol =</span> Nrep)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>              <span class="co"># cada coluna armazena uma replicação de</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>              <span class="co"># 'Nsim' voos simulados</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="co"># condição de overbooking:</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>overbook <span class="ot">&lt;-</span> simula_voo <span class="sc">&gt;</span> <span class="dv">197</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a><span class="co"># calcula freq. de overbooking observada</span></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a><span class="co"># para cada replicação de 'Nsim' voos simulados</span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>frel_overbook <span class="ot">&lt;-</span> <span class="fu">colMeans</span>(overbook) </span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Histograma com as estimativas para P[X &gt; 197]</span></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(frel_overbook, <span class="at">freq=</span><span class="cn">FALSE</span>,</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>     <span class="at">density =</span> <span class="dv">25</span>,</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>     <span class="at">yaxt =</span> <span class="st">"n"</span>,</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Freq. relativa de 'overbooking'"</span>, </span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">""</span>, <span class="at">ylab =</span> <span class="st">""</span>,</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>     <span class="at">col=</span><span class="st">"gray"</span>)</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">mean</span>(frel_overbook), <span class="at">col =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="st">"dashed"</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Os valores simulados são organizados na matriz <code>simula_voo</code>, tal que cada coluna corresponde a uma replicação da simulação de <code>Nsim</code> voos simulados. Há portanto, um total de <code>Nsim</code> linhas e <code>Nrep</code> colunas.</p>
<p>Cada elemento de <code>simula_voo</code> corresponde ao número de passageiros que se apresentaram para o embarque em um voo simulado. Verificamos se cada um desses voos resultou em <em>overbooking</em> e registramos a frequência relativa de <em>overbooking</em> em cada coluna, isto é, em cada replicação da simulação. Cada frequência relativa calculada corresponde a uma estimativa para a probabilidade de <span class="math inline">\(X &gt; 197\)</span>. Com isso, obtemos um número igual a <code>Nrep</code> estimativas para esta probabilidade. O histograma representa a distribuição das frequências relativas de <em>overbooking</em> observadas nas <code>Nrep</code> replicações. Veja que o centro da distribuição amostral é bem próximo do valor de probabilidade que desejamos calcular.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="MB751_AULA02_files/figure-html/unnamed-chunk-26-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="métodos-descritivos-para-avaliar-normalidade" class="level2">
<h2 class="anchored" data-anchor-id="métodos-descritivos-para-avaliar-normalidade">Métodos Descritivos para Avaliar Normalidade</h2>
<p>Embora não seja a melhor maneira de fazer isso, podemos avaliar a normalidade dos dados observando o <strong>histograma</strong> ou <strong>gráfico de frequência relativa</strong>. Se os dados forem aproximadamente normalmente distribuídos, espera-se que o histograma seja unimodal em torno da média, simétrico, com caudas curtas.</p>
<p>É importante verificar a <strong>amplitude interquartis</strong> e também o desvio-padrão amostral para os dados. Para dados com distribuição aproximadamente Normal, a razão entre a amplitude interquartis e o desvio padrão amostral deve estar em torno de 1,3.</p>
<p>E finalmente, o método descritivo mais utilizado para avaliar normalidade é o <strong>gráfico de quantis</strong>, que compara os quantos amostrais com os teóricos da distribuição normal correspondente. Se os dados tem distribuição aproximadamente normal, os pontos no gráfico de quantis estão dispostos em uma linha reta.</p>
<p>Vejamos a aplicação desses métodos em um conjunto de dados.</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Exemplo 23</strong></span> <br> Os dados se referem a 100 medidas de consumo de combustível de um tipo de automóvel de passeio. O primeiro passo consiste em carregar os dados e analisar o resumo numérico.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># carrega dados</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>consumo <span class="ot">&lt;-</span> <span class="fu">scan</span>(<span class="st">"data/CONSUMO.txt"</span>)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="co"># produz resumo numérico dos dados</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(consumo)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  12.76   15.17   15.73   15.73   16.29   19.09 </code></pre>
</div>
</div>
<p>Como uma primeira verificação de normalidade, vamos examinar o histograma que representa a distribuição dos valores de consumo de combustível registrados. A curva normal correspondente é sobreposta ao histograma. Claramente, a distribuição dos dados de consumo de combustível é unimodal em torno da média (que vale 15.73, conforme mostra o resumo numérico dos dados); além disso, a distribuição é aparentemente simétrica (a média é igual à mediana) com formato aproximado de sino.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># constroi histograma de freq. relativa</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(consumo, <span class="at">freq =</span> <span class="cn">FALSE</span>,  <span class="at">main =</span> <span class="st">""</span>, </span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Freq. Relativa"</span>, <span class="at">xlab =</span> <span class="st">"km/l"</span>)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>  m <span class="ot">&lt;-</span> <span class="fu">mean</span>(consumo)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>  s <span class="ot">&lt;-</span> <span class="fu">sd</span>(consumo)</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">curve</span>(<span class="fu">dnorm</span>(x, m, s), <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="MB751_AULA02_files/figure-html/unnamed-chunk-29-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># calcula amplitude interquartis</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>IQR <span class="ot">&lt;-</span> <span class="fu">diff</span>(<span class="fu">quantile</span>(consumo, <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.25</span>, <span class="fl">0.75</span>))) </span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="co"># razão entre amplitude interquartis e desvio-padrão amostral</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>IQR<span class="sc">/</span><span class="fu">sd</span>(consumo)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     75% 
1.092566 </code></pre>
</div>
</div>
<p>A razão entre a amplitude interquartis e o desvio-padrão amostral é um pouco menor que 1.3; isso significa que a distribuição amostral é um pouco menos espalhada que a distribuição normal.</p>
<p>Por fim, analisemos o gráfico de quantis, também chamado de gráfico de probabilidades.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># produz gráfico de quantis</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(consumo, </span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>       <span class="at">main =</span> <span class="st">""</span>, </span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="co"># adiciona reta de referência</span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(consumo, <span class="at">col =</span> <span class="st">"red"</span>)</span></code><button title="Copiar para a área de transferência" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="MB751_AULA02_files/figure-html/unnamed-chunk-32-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%"></p>
</figure>
</div>
</div>
</div>
<p>Em um gráfico de quantis, o eixo vertical corresponde às observações do conjunto ordenadas do menor ao maior valor; no eixo horizontal temos os escores-z esperados das observações, sob a hipótese de normalidade. Quando os dados têm distribuição aproximadamente normal, os valores observados serão próximos dos valores esperados. Desta forma, quando o gráfico que quantis evidencia pontos dispostos em uma linha reta; desvios significativos de uma tendência linear indicam não-normalidade.</p>
<p>Esses métodos de verificação apresentados são bastante simples e, no entanto, poderosos, mas têm natureza simplesmente descritiva. Isso significa que não conferem validade estatística aos achados. Sendo assim, embora pouco provável, é possível que os dados sejam oriundos de uma distribuição não normal, mesmo que os resultados dessas técnicas descritivas apontem para uma aparente normalidade. Portanto, não podemos afirmar que os dados são, de fato, normalmente distribuídos com base no emprego de métodos descritivos; podemos apenas afirmar que parece razoável crer que os dados são normalmente distribuídos.</p>
<p>Existem métodos formais, baseados em testes de hipóteses, para avaliar a significância estatística dessa inferência. No entanto, testes de normalidade tendem a ser muito sensíveis a pequenos desvios de normalidade, o que quer dizer que eles tendem a rejeitar a hipótese de normalidade para qualquer distribuição que não seja perfeitamente simétrica e unimodal, especialmente quando muitas observações estão disponíveis.</p>
</div>
</div>
</div>
</div>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiada");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiada");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>